<html>
<head>
<title>PyTorch JIT and TorchScript</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch JIT和TorchScript</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pytorch-jit-and-torchscript-c2a77bac0fff?source=collection_archive---------1-----------------------#2020-11-10">https://towardsdatascience.com/pytorch-jit-and-torchscript-c2a77bac0fff?source=collection_archive---------1-----------------------#2020-11-10</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="5089" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">PyTorch模型的生产之路</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/70a0259c57765a57db1953a99aa27236.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nwO2BKUshyxsbXNzxU-5OA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><a class="ae kv" href="https://unsplash.com/photos/D-FI-GHZeVc?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditShareLink" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="c8fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们都喜欢PyTorch的动态性和易用性。但是当涉及到部署时，这些品质不如性能和可移植性那样令人满意。</p><p id="e439" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在过去，部署需要迁移到不同的框架。从研究到生产的转变需要两个拥有不同技能的独立团队来实现。随着TorchScript的引入，这一过程发生了变化。</p><p id="0cba" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">PyTorch旨在通过TorchScript创建一个从研究到生产的统一框架。TorchScript会将您的PyTorch模块作为输入，并将其转换为适合生产的格式。</p><p id="aaae" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它将更快地运行您的模型，并且独立于Python运行时。</p><h1 id="4323" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">PyTorch生态系统</h1><p id="0725" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">PyTorch支持两种不同的模式来处理研究和生产环境。</p><p id="4bf2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">首先是<strong class="ky ir"> <em class="mp">急切模式。</em> </strong>它是为了更快的原型制作、训练和实验而建造的<strong class="ky ir"> <em class="mp"> </em> </strong>。</p><p id="b2b3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">其次是<strong class="ky ir"> <em class="mp">脚本模式。</em> </strong>它专注于生产用例。它有两个组件<strong class="ky ir"> <em class="mp"> PyTorch JIT </em> </strong>和<strong class="ky ir"><em class="mp">torch script</em></strong><em class="mp">。</em></p><h2 id="a216" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">为什么我们需要脚本模式？</h2><p id="816d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">一句话，它摆脱了Python的GIL和对Python运行时的依赖。一个微妙的解释如下</p><ol class=""><li id="fcde" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated"><strong class="ky ir"> <em class="mp">可移植性</em> </strong> <br/> <em class="mp">可移植性</em>允许模型部署在多线程推理服务器、手机和汽车中，这对于Python来说是很困难的。为了实现这一点，PyTorch模型需要与任何特定的运行时解耦。</li><li id="03e5" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><strong class="ky ir"> <em class="mp">性能</em> </strong> <br/> PyTorch JIT是一款针对PyTorch的优化JIT编译器。它使用运行时信息来优化TorchScript模块。它可以自动优化，如层融合，量化，稀疏化。</li></ol><h1 id="cfe9" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">脚本模式</h1><p id="11a9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">脚本模式创建PyTorch Eager模块的中间表示(IR)(通过<code class="fe nq nr ns nt b">torch.jit.trace/torch.jit.script</code>)。IR经过内部优化，并在运行时利用PyTorch JIT编译。PyTorch JIT编译器使用运行时信息来优化IR。这个IR与Python运行时是分离的。</p><p id="5f93" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">脚本模式通过利用PyTorch JIT和TorchScript来工作。</p><h2 id="d680" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">PyTorch JIT是什么？</h2><p id="11e9" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">PyTorch JIT是一个为PyTorch程序优化的编译器。</p><ol class=""><li id="becd" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">它是一个轻量级的线程安全解释器</li><li id="db21" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">支持易于编写的自定义转换</li><li id="7eee" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">这不仅仅是为了推断，因为它有自动差异支持</li></ol><h2 id="fb64" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">TorchScript是什么？</h2><p id="4536" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">TorchScript是Python语言的静态高性能子集，专门用于ML应用程序。它支持</p><ol class=""><li id="aa8e" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr nh ni nj nk bi translated">复杂的控制流</li><li id="3825" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">公共数据结构</li><li id="1cd9" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated">用户定义的类</li></ol><p id="7ed9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们已经介绍了PyTorch JIT、TorchScript和脚本模式。<br/>我们讨论了它们是什么，以及我们为什么需要它们？在下面的片段中，我们将了解如何使用它们？</p><p id="ade1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">脚本模式由<code class="fe nq nr ns nt b">torch.jit.trace</code>或<code class="fe nq nr ns nt b">torch.jit.script</code>调用。</p><h2 id="c3c0" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">JIT跟踪</h2><p id="8464" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><code class="fe nq nr ns nt b">torch.jit.trace</code>取一个数据实例和你训练好的eager模块作为输入。tracer运行提供的模块并记录执行的张量运算。这段录音被转换成一个TorchScript模块。</p><blockquote class="nu nv nw"><p id="1c36" class="kw kx mp ky b kz la jr lb lc ld ju le nx lg lh li ny lk ll lm nz lo lp lq lr ij bi translated"><em class="iq">跳到示例1，查看它的运行情况</em></p></blockquote><p id="a8af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它可以重用现有的eager模型代码，并且可以处理几乎任何具有独占torch张量/操作的程序。</p><p id="abea" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它的主要缺点是省略了所有的控制流、数据结构和python结构。它也可以在没有任何警告的情况下产生不忠实的陈述。总是检查它的IR，看它是否正确地解析了PyTorch模型的结构。</p><h2 id="92a6" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">JIT脚本</h2><p id="837d" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated"><code class="fe nq nr ns nt b">torch.jit.script</code>允许你直接将代码写入TorchScript。它更加冗长，但是更加通用，稍加调整就可以支持大多数PyTorch模型。</p><p id="76fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与跟踪模式相反，你只需要将你的模型/模块的一个实例传递给<code class="fe nq nr ns nt b">torch.jit.script.</code>，而不需要数据样本。</p><blockquote class="nu nv nw"><p id="f9c9" class="kw kx mp ky b kz la jr lb lc ld ju le nx lg lh li ny lk ll lm nz lo lp lq lr ij bi translated"><em class="iq">跳到实例2的实际应用</em></p></blockquote><p id="29d4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它保留了控制流和其他python结构，看起来更像Python。它对列表/字典有一流的支持。</p><p id="f64f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">它省略了常量值，并且需要类型转换。如果没有提供类型，则默认为张量</p></div><div class="ab cl oa ob hu oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="ij ik il im in"><p id="69f2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于一次会议来说，这是太多的理论了，让我们转到代码上，看看运行中的跟踪/脚本。</p><h1 id="aae3" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">例子1:伯特</h1><p id="b043" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">BERT(来自变压器的双向编码器表示)是由谷歌人工智能的研究人员开发的。在下面的例子中，我们利用了HuggingFace提供的transformer库中的BERT。</p><p id="47f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该示例分为3个部分</p><ul class=""><li id="3142" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr oh ni nj nk bi translated">第1部分<br/>初始化BERT模型/记号化器，并创建一个用于推理的样本数据</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第1部分:实例化BERT/Tokenizers</p></figure><ul class=""><li id="b30a" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr oh ni nj nk bi translated">第2部分:<br/>为CPU/GPU上的推理准备PyTorch模型。</li></ul><blockquote class="nu nv nw"><p id="8bd0" class="kw kx mp ky b kz la jr lb lc ld ju le nx lg lh li ny lk ll lm nz lo lp lq lr ij bi translated">模型/数据应该在同一设备上，以便进行训练/推理。<code class="fe nq nr ns nt b">cuda()</code>将模型/数据从CPU传输到GPU。</p></blockquote><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第2部分:在CPU/GPU上对PyTorch模型进行基准测试</p></figure><ul class=""><li id="660c" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr oh ni nj nk bi translated">步骤3: <br/>准备TorchScript模块，以便在CPU/GPU上进行推理</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">第3部分:CPU/GPU上TorchScript模块的基准测试</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/bc88e7a7159fd18626c3f6db2aed67fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:950/format:webp/1*lrRh2DAzedekbvVXb5p8RA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">伯特的PyTorch vs TorchScript</p></figure><p id="ef90" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在CPU上运行时间相似，但在GPU上TorchScript明显优于PyTorch。</p><p id="2885" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TorchScript创建PyTorch模型的IR，可以在运行时由PyTorch JIT进行优化编译。可以使用<code class="fe nq nr ns nt b">traced_model.code</code>查看该红外图像。</p></div><div class="ab cl oa ob hu oc" role="separator"><span class="od bw bk oe of og"/><span class="od bw bk oe of og"/><span class="od bw bk oe of"/></div><div class="ij ik il im in"><h1 id="e178" class="ls lt iq bd lu lv ol lx ly lz om mb mc jw on jx me jz oo ka mg kc op kd mi mj bi translated">示例2: ResNet</h1><p id="305a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">ResNet是残差网络的缩写，是一种经典的神经网络，用作许多计算机视觉任务的主干。这款车型是2015年ImageNet挑战赛的冠军。</p><p id="d47e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">以下示例有两个部分</p><ul class=""><li id="bbe8" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr oh ni nj nk bi translated">示例1.1 / 1.2: <br/> PyTorch ResNet在CPU/GPU上的初始化和推理</li><li id="e2ef" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">示例2.1/2.2:<code class="fe nq nr ns nt b"><br/>torch.jit.script</code>CPU/GPU上的初始化和推理</li></ul><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="oi oj l"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">PyTorch和脚本的ResNet示例</p></figure><p id="e297" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TorchScript明显优于PyTorch在GPU上的实现。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/a370a9296055ee8d9880f226c8215525.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*9OQaSUVR8XMygkQjvgpB_w.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">PyTorch vs的TorchScript</p></figure><h1 id="e9eb" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">辅助部件</h1><h2 id="6a7e" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">如何保存/加载TorchScript模块？</h2><p id="1b22" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">TorchScript将模块保存/加载为归档格式。这个档案是模型的独立表示，可以加载到一个完全独立的进程中。</p><ul class=""><li id="f358" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr oh ni nj nk bi translated">保存模块<code class="fe nq nr ns nt b">torch.jit.save(traced_model,’traced_bert.pt’)</code></li><li id="ec1c" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">加载模块<code class="fe nq nr ns nt b">loaded = torch.jit.load('traced_bert.pt')</code></li></ul><h2 id="8015" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">如何查看TorchScript捕捉到的PyTorch IR？</h2><ul class=""><li id="fd9f" class="nc nd iq ky b kz mk lc ml lf or lj os ln ot lr oh ni nj nk bi translated">示例1:使用<code class="fe nq nr ns nt b">traced_model.code</code>查看PyTorch IR <br/>跳过这一步，因为它非常冗长</li><li id="4814" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">示例2:使用<code class="fe nq nr ns nt b">script_cell_gpu.code</code>查看PyTorch IR</li></ul><pre class="kg kh ki kj gt ou nt ov ow aw ox bi"><span id="d429" class="mq lt iq nt b gy oy oz l pa pb">def forward(self,<br/>    input: Tensor) -&gt; Tensor:<br/>  _0 = self.fc<br/>  _1 = self.avgpool<br/>  _2 = self.layer4<br/>  _3 = self.layer3<br/>  _4 = self.layer2<br/>  _5 = self.layer1<br/>  _6 = self.maxpool<br/>  _7 = self.relu<br/>  _8 = (self.bn1).forward((self.conv1).forward(input, ), )<br/>  _9 = (_5).forward((_6).forward((_7).forward(_8, ), ), )<br/>  _10 = (_2).forward((_3).forward((_4).forward(_9, ), ), )<br/>  input0 = torch.flatten((_1).forward(_10, ), 1, -1)<br/>  return (_0).forward(input0, )</span></pre><h2 id="d96a" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">结合跟踪和脚本</h2><p id="39ba" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">torch.jit.trace和torch.jit.script可以结合起来弥补各自的不足。看这个<a class="ae kv" href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#mixing-scripting-and-tracing" rel="noopener ugc nofollow" target="_blank">官方举例</a>。他们通过内嵌代码来做到这一点。</p><h2 id="9e3c" class="mq lt iq bd lu mr ms dn ly mt mu dp mc lf mv mw me lj mx my mg ln mz na mi nb bi translated">其他好处</h2><p id="b540" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">除了改进推理时间，使用TorchScript还有其他好处</p><ul class=""><li id="6b98" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr oh ni nj nk bi translated">TorchScript将您的模型从任何运行时环境中分离出来。它摆脱了Python的GIL，这是多线程推理的一个主要瓶颈。</li><li id="065b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">TorchScript专注于整个程序的优化。</li><li id="71b3" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">TorchScript自动优化神经网络中的常见模式，以改善延迟和吞吐量。</li><li id="686d" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">TorchScript模块可以导出到各种环境中，从C++服务器到移动设备。</li></ul><h1 id="3b30" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">摘要</h1><p id="1f0f" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">这个博客引入了脚本模式。从功能上来说，脚本模式提供了将您的研究模型投入生产的工具，同时仍然处于PyTorch生态系统中。</p><p id="12a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">重申一下，这是模型开发和部署的典型路径。</p><ul class=""><li id="234c" class="nc nd iq ky b kz la lc ld lf ne lj nf ln ng lr oh ni nj nk bi translated">步骤0:开发你的模型，最好是在PyTorch渴望模式下</li><li id="ca76" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">步骤1:在PyTorch模型上使用<code class="fe nq nr ns nt b">torch.jit.trace</code>或/和<code class="fe nq nr ns nt b">torch.jit.script</code>创建TorchScript模块</li><li id="204e" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">步骤2:使用这种格式的<code class="fe nq nr ns nt b">torch.jit.save/torch.jit.load.</code>将这些模块转移到生产环境中，它们可以在从服务器到边缘设备的任何地方运行</li><li id="4141" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr oh ni nj nk bi translated">步骤3:使用PyTorch JIT编译器在推理时优化这些程序，以最小的努力享受更快的推理。</li></ul><h1 id="c698" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">参考</h1><ol class=""><li id="c96c" class="nc nd iq ky b kz mk lc ml lf or lj os ln ot lr nh ni nj nk bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=2awmrMRf0dA" rel="noopener ugc nofollow" target="_blank"> Torchscript + PyTorch JIT </a></li><li id="7b3b" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://www.youtube.com/watch?v=St3gdHJzic0" rel="noopener ugc nofollow" target="_blank">从研究到生产</a></li><li id="1dd0" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://pytorch.org/tutorials/beginner/Intro_to_TorchScript_tutorial.html#saving-and-loading-models" rel="noopener ugc nofollow" target="_blank"> PyTorch文档</a></li><li id="b374" class="nc nd iq ky b kz nl lc nm lf nn lj no ln np lr nh ni nj nk bi translated"><a class="ae kv" href="https://huggingface.co/transformers/serialization.html" rel="noopener ugc nofollow" target="_blank">为变压器模型使用TorchScript】</a></li></ol></div></div>    
</body>
</html>