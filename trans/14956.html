<html>
<head>
<title>Fast experimentation with Transformers for Data Scientists in a rush</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">数据科学家匆忙进行变压器快速实验</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/fast-experimentation-with-transformers-for-data-scientists-in-a-rush-da0f5240dce3?source=collection_archive---------34-----------------------#2020-10-14">https://towardsdatascience.com/fast-experimentation-with-transformers-for-data-scientists-in-a-rush-da0f5240dce3?source=collection_archive---------34-----------------------#2020-10-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="f0bb" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">用huggingface/transformers repo创建低代码、有用的实验管道比你想象的要容易</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/0968728c8a2c9f1f39192084eebad479.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*qibfWhCVDy4I3sXf"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">杰克·吉文斯在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="40da" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">用NLP快速实验让你产生很多价值</h1><p id="c358" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">如果你正在读这篇文章，你可能在某个时候遇到了和我一样的问题:你有一个NLP数据集和任务要解决，需要执行快速实验来产生价值，并把一个模型投入生产。</p><p id="ea6e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">你打开了拥抱脸/变形金刚，看到了很多例子——它们都起作用了。当它适应你自己的数据集和任务时，代码太长，太具体，不能用于你的目的。</p><p id="07d2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">这篇文章将帮助你利用HuggingFace预训练转换器和库，为你自己的NLP任务和数据集创建低代码、有用且易于适应的管道。今天我们将集中讨论分类，但是，如果你们都喜欢这个帖子，我可以继续这个系列的任务，如问答、翻译等…</p><p id="35a7" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">所以让我们把手放上去！</p><h1 id="a83b" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">开始之前</h1><p id="dd12" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在你开始之前，确保你有所有的要求，在<a class="ae kv" href="https://github.com/piEsposito/transformers-low-code-experiments" rel="noopener ugc nofollow" target="_blank">我们的回购</a>上声明。我们将使用Kaggle 的数据集<a class="ae kv" href="https://www.kaggle.com/team-ai/spam-text-message-classification" rel="noopener ugc nofollow" target="_blank">，其中包含被标记为垃圾邮件或非垃圾邮件的电子邮件。为了对它进行预处理，我将csv文件作为Pandas dataframe导入，重命名列并将它分成两个csv文件，用于训练和测试目的。</a></p><p id="caa3" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我已经为您预处理过了，所以您可以在<a class="ae kv" href="https://github.com/piEsposito/transformers-low-code-experiments/tree/main/classification" rel="noopener ugc nofollow" target="_blank"> repo </a>上访问它。无论如何，如果你愿意，这里是我对数据集做的操作:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="8841" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">为了运行我们将在这里构建的脚本，请确保将text列命名为“sentence ”,将labels列命名为“label”。</p><p id="c4c0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们现在准备出发了。</p><h1 id="a1bd" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">实施路线图</h1><p id="4835" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">对于本文，我们的实施路线图将是:</p><ul class=""><li id="7bdb" class="mr ms iq lq b lr mk lu ml lx mt mb mu mf mv mj mw mx my mz bi translated">导入我们将在这里使用的每个库，并解释我们为什么要使用它；</li><li id="4f8f" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">在hugging face/transformers auto model类的顶部创建一个多标签序列分类器；</li><li id="2cfe" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">创建一个辅助函数来标记文本数据集；</li><li id="f3f6" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">从已训练的模型中创建辅助函数来训练、预测和度量；</li><li id="08c4" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">创建一个optuna目标函数来帮助自动超参数调整；</li><li id="b2c3" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">将其包装成一个可参数化、可重用的脚本，以便在不同的NLP任务上进行快速实验。</li></ul><h2 id="7171" class="nf kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">进口</h2><p id="9183" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">以下是我们今天使用的进口产品:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="a5dc" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">现在，我们如何使用它们:</p><ul class=""><li id="768a" class="mr ms iq lq b lr mk lu ml lx mt mb mu mf mv mj mw mx my mz bi translated">所有PyTorch导入都与创建数据加载器、操纵张量、创建可训练模型和损失函数有关。</li><li id="338d" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">我们从Transformers导入AutoModel、优化器、标记器和配置，以便能够从它们的repo加载任何预先训练的语言模型。这意味着我们可以使用不同的语言和数据集，只要文件符合我们之前所做的预处理。</li><li id="9e57" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">我们导入nlp，HuggingFace的另一个包来创建数据集。csv文件。</li><li id="ec63" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">Optuna用于自动优化超参数，帮助我们实现更好的模型指标。</li><li id="2471" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">Sklearn.metrics和Numpy是用来度量计算的，tqdm只是用来把东西变漂亮的。</li></ul><h2 id="957d" class="nf kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">扩展用于多类分类的转换器</h2><p id="85ac" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">HuggingFace Transformers内置了AutoModelForSequenceClassification(FYI，这是实际名称)，但它只支持二进制分类。因为我们想把它扩展到更多的类，我们必须自己创建这个模型。</p><p id="cada" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">那不会很难。正如你在下面看到的，我们将创建一个<code class="fe nr ns nt nu b">nn.Module</code>对象，它创建一个自动模型基础，然后是一个Dropout和线性层，带有所需数量的输出节点。请注意，我们仅使用预训练模型的名称和标签数量对其进行参数化:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><h2 id="e5d9" class="nf kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">创建令牌化函数</h2><p id="8fcb" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">使用训练模型的相同键(名称)，我们可以从HuggingFace repo导入一个标记化器。我们现在将创建一个函数，根据给定的标记器对数据集进行标记。稍后，我们将使用map方法将这种标记化应用于整个数据集。</p><p id="877f" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">就这么简单:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><h2 id="1b24" class="nf kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">培训、评估和度量功能</h2><p id="2789" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">我们现在进入了本帖最重要的部分:训练和评估功能。</p><p id="62db" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">为此，给定数据集，我们使用一个非常简单的向前训练函数，只对huggingface/nlp数据集对象做了一些修改:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="ea02" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">请注意，我们在每个训练时段创建数据加载器，它是一个生成器，并且我们为每个批次获得这个<code class="fe nr ns nt nu b">input_ids</code>。这就是数据集的符号化，必须将其转换为LongTensor，然后放入我们正在进行训练的设备中。</p><p id="e77a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们将评估该模型，并分两步获取指标。首先，我们将整个测试数据集通过模型并获得其预测，将一个张量和相应的张量保存在一边:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="354a" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">在我们得到标签和预测张量进行比较之后，我们就可以得到度量。在这个函数中，我决定让用户决定要计算的指标。请注意，在后面的内容中，我们将设置optuna来调整这个特定指标的超参数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="2ea2" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我们决定支持所有标签评估的准确性和平均精度，并支持二进制化+ f1，以及要调整的特定标签的召回和精度指标。</p><p id="623c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">当我们将所有这些构建部分放在一起时，我们可以创建optuna目标函数。为了让您理解，这是一个使用一些超参数执行训练并获得客观指标的函数。Optuna将使用此目标函数，根据我们想要的度量找到最佳超参数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="3f90" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">由于我们将使用上面设置的所有函数，我们将根据数据集的特性使其可参数化。这保证了你能够用你自己的数据集来测试我们正在构建的脚本。</p><h2 id="9a84" class="nf kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">参数化脚本</h2><p id="6644" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在创建我们的主脚本之前，我们将使用<code class="fe nr ns nt nu b">argparse</code>为它的运行设置参数。这意味着通过命令行上的一些标志，你可以用你自己的文本分类数据集进行实验。让我们看看:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="31e0" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">所以这里我们参数化为:</p><ul class=""><li id="5740" class="mr ms iq lq b lr mk lu ml lx mt mb mu mf mv mj mw mx my mz bi translated">模型名称，因此我们可以从HuggingFace预训练模型库中获取任何模型；</li><li id="4c77" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">训练和测试数据路径，只是为了决定文件的名称和路径；</li><li id="8c06" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">最大序列长度，所以我们不会浪费内存，如果工作与小文本大小；</li><li id="cf96" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">指标名称optuna将优化，支持准确性、average_precision_score、f1_score、precision_score、recall_score(最后三个上的标签相对于reference-class二进制化)；和</li><li id="fd5a" class="mr ms iq lq b lr na lu nb lx nc mb nd mf ne mj mw mx my mz bi translated">标签号，这样我们就可以设置模型的输出节点数。</li></ul><h2 id="ee71" class="nf kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">最后，主要功能</h2><p id="a48e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">设置好之后，我们就可以编写主函数了。它创建数据集和目标函数，从optuna设置一个研究来优化超参数，以最大化所选的度量。</p><p id="d95b" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">使用默认参数，如果你喜欢使用它，你可以适应谷歌Collab的GPU，它应该产生大约0.9的F1分数。这是:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="mp mq l"/></div></figure><p id="0a71" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">注意，我们使用HuggingFace的nlp库创建数据集，然后将编码数据集函数映射到整个数据集。这就创建了<code class="fe nr ns nt nu b">input_ids</code>属性，我们用它在训练和推理中获得标记化的文本。</p><h2 id="1d83" class="nf kx iq bd ky ng nh dn lc ni nj dp lg lx nk nl li mb nm nn lk mf no np lm nq bi translated">结论</h2><p id="d992" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">正如你所看到的，利用HuggingFace预训练的transformers库和库，创建一个可重复的、可参数化的脚本是非常可能的。有了正确形状上的数据，您可以用简单、易懂和易读的代码，以非常快速的方式运行实验并调整超参数和指标。</p><p id="6104" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">我希望post和script能帮助你快速地用NLP创造价值，产生良好可靠的结果，并在许多语言中使用最先进的预训练模型。</p><p id="fc3c" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果这篇文章对你有所帮助，如果你能<a class="ae kv" href="https://github.com/piEsposito/transformers-low-code-experiments" rel="noopener ugc nofollow" target="_blank">在Github </a>上发起回购，我会非常高兴，如果能让更多人看到并帮助消息传递给更多人。</p><p id="2027" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">如果你有任何评论、批评或者只是想谈谈NLP、深度学习或者甚至和我一起写这个系列，<a class="ae kv" href="https://www.linkedin.com/in/piesposito/" rel="noopener ugc nofollow" target="_blank">在LinkedIn </a>上联系我，以便我们可以交谈。</p><p id="012e" class="pw-post-body-paragraph lo lp iq lq b lr mk jr lt lu ml ju lw lx mm lz ma mb mn md me mf mo mh mi mj ij bi translated">谢谢你的时间，我希望我已经帮助了你。</p><h1 id="1066" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">参考</h1><div class="nv nw gp gr nx ny"><a href="https://github.com/piEsposito/transformers-low-code-experiments" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">piEsposito/变压器-低代码-实验</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">低代码预建管道，用于数据科学家匆忙进行的huggingface/transformers实验。这个…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">github.com</p></div></div><div class="oh l"><div class="oi l oj ok ol oh om kp ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://www.linkedin.com/posts/thomas-wolf-a056857_nlp-ai-opensource-activity-6702500587939868672-YLmC/" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">LinkedIn上的Thomas Wolf:# NLP # ai # open source | 49条评论</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">我们正在考虑添加非常明确和简单的例子🤗像这样的变形金刚。只有45行……</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">www.linkedin.com</p></div></div><div class="oh l"><div class="on l oj ok ol oh om kp ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://github.com/huggingface/transformers" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">拥抱脸/变形金刚</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">PyTorch和TensorFlow 2.0的最新自然语言处理技术🤗变形金刚提供了成千上万的…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">github.com</p></div></div><div class="oh l"><div class="oo l oj ok ol oh om kp ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://www.kaggle.com/team-ai/spam-text-message-classification" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">垃圾短信分类</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">让我们用数据科学与恼人的垃圾邮件制造者战斗。</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">www.kaggle.com</p></div></div><div class="oh l"><div class="op l oj ok ol oh om kp ny"/></div></div></a></div><div class="nv nw gp gr nx ny"><a href="https://optuna.org/" rel="noopener  ugc nofollow" target="_blank"><div class="nz ab fo"><div class="oa ab ob cl cj oc"><h2 class="bd ir gy z fp od fr fs oe fu fw ip bi translated">Optuna -超参数优化框架</h2><div class="of l"><h3 class="bd b gy z fp od fr fs oe fu fw dk translated">Optuna是一个自动超参数优化软件框架，专门为机器学习而设计。它…</h3></div><div class="og l"><p class="bd b dl z fp od fr fs oe fu fw dk translated">optuna.org</p></div></div><div class="oh l"><div class="oq l oj ok ol oh om kp ny"/></div></div></a></div></div></div>    
</body>
</html>