<html>
<head>
<title>Pandas on the Cloud with Dask</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">和达斯克一起在云上的熊猫</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/pandas-on-the-cloud-with-dask-9451199b0226?source=collection_archive---------26-----------------------#2020-09-23">https://towardsdatascience.com/pandas-on-the-cloud-with-dask-9451199b0226?source=collection_archive---------26-----------------------#2020-09-23</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="284a" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用Dask将Pythonic数据科学和机器学习扩展到云。所有这些都来自您自己的笔记本电脑。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/5fabe0c84c4008a99a00640a1cd41494.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ZudEZUM97toUkEs7"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Elena Mozhvilo 在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="713d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在进行数据科学和/或机器学习时，需要将分析扩大到更大的数据集变得越来越常见。</p><p id="63e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Python和PyData生态系统中工作时，Dask是一个流行的工具。原因有很多，其中之一是Dask可以很好地与所有PyData工具兼容。这是一个简单的系统，旨在并行化任何PyData库。</p><p id="25ab" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当开始处理更大的数据集时，您首先会希望<em class="ls">扩展</em>您的分析，以利用单个工作站的所有内核。</p><p id="00c2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这之后，你可能需要<em class="ls">横向扩展</em>你的计算来利用云上的集群(例如，AWS、Azure或Google云平台)。</p><p id="63ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本帖中，我们</p><ul class=""><li id="7512" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">使用熊猫演示数据科学工作流中的常见模式，</li><li id="782d" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">展示我们如何使用Dask来利用单个工作站的内核，并</li><li id="b2ae" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">展示我们如何使用<a class="ae kv" href="http://cloud.coiled.io/" rel="noopener ugc nofollow" target="_blank">盘绕云</a>将其扩展至云。有许多向外扩展到云的解决方案，但我对Coiled特别感兴趣，因为我们刚刚发布了我们的云产品。</li></ul><p id="1a83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">你也可以在Github 上找到所有的代码<a class="ae kv" href="https://github.com/coiled/data-science-at-scale/blob/master/01-data-analysis-at-scale.ipynb" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="dc04" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">注意:你应该总是试着思考你是否真的需要扩展你的计算。例如，在这样做之前，也许你可以让你的熊猫代码更有效。如果你在做机器学习，画出学习曲线，以确保包含更多的数据将真正导致改善你的模型。</p><h1 id="b374" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">熊猫:数据科学中的一种常见模式</h1><p id="bbb6" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">在这里，我们介绍数据科学中的一个常见模式，并展示如何在内存数据集上使用pandas来执行它。我们将检查纽约出租车数据集的700MB子集(总共约10 GB)。</p><p id="8ebe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们读入数据，并使用groupby DataFrame方法检查平均小费金额，作为乘客人数的函数:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="131f" class="nj mi iq nf b gy nk nl l nm nn"># Import pandas and read in beginning of 1st file <br/>import pandas as pd <br/>df = pd.read_csv("data_taxi/yellow_tripdata_2019-01.csv") </span><span id="fac4" class="nj mi iq nf b gy no nl l nm nn"># Compute average tip as a function of the number of passengers df.groupby("passenger_count").tip_amount.mean()</span></pre><p id="120f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这在我的笔记本电脑上花了大约15秒，在我愿意等待我的分析的容忍时间内。</p><p id="f7cf" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来，我想对整个数据集执行完全相同的分析。</p><h1 id="d53f" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">DASK:扩展您的数据科学</h1><p id="8da6" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">回想一下，整个数据集大约有10GB，这超过了我笔记本电脑上的可用RAM，这意味着我无法将它存储在内存中。</p><p id="664c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我可以写一个for循环:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="464e" class="nj mi iq nf b gy nk nl l nm nn">for filename in glob("~/data_taxi/yellow_tripdata_2019-*.csv"):<br/>    df = pd.read_csv(filename)<br/>    df.groupby("passenger_count").tip_amount.mean()</span></pre><p id="2a5d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这没有利用我的笔记本电脑上的多个内核，也不是特别优雅。输入Dask表示单机并行度。</p><p id="6322" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们导入Dask的几个部分，启动一个本地集群并实例化一个Dask客户端:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="f6dc" class="nj mi iq nf b gy nk nl l nm nn">from dask.distributed import LocalCluster, Client <br/>cluster = LocalCluster(n_workers=4) <br/>client = Client(cluster) <br/>client</span></pre><p id="e4ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们导入Dask DataFrame，读入所有数据(延迟)，并计算相同的groupby，就像上面我们对pandas所做的那样。</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="3e7d" class="nj mi iq nf b gy nk nl l nm nn">import dask.dataframe as dd<br/><br/>df = dd.read_csv(<br/>    "data_taxi/yellow_tripdata_2019-*.csv",<br/>    dtype={'RatecodeID': 'float64',<br/>       'VendorID': 'float64',<br/>       'passenger_count': 'float64',<br/>       'payment_type': 'float64'}<br/>)<br/><br/>mean_amount = df.groupby("passenger_count").tip_amount.mean().compute()</span></pre><p id="71fe" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这在我的笔记本电脑上需要大约3.5分钟，这是可以忍受的。我想是的。然而，如果你想做任何稍微复杂一点的事情(提示:你通常会做)，这个时间会很快结束。</p><p id="ee36" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，如果我能够访问云上的集群，使用它将是一个好主意！</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi np"><img src="../Images/235293f183b234e68eb493304558e9e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QaE67MzUabPaIk_D7zlwEw.png"/></div></div></figure><p id="c229" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在此之前，让我们注意一下我们刚刚完成的几个方面:</p><ul class=""><li id="3e22" class="lt lu iq ky b kz la lc ld lf lv lj lw ln lx lr ly lz ma mb bi translated">我们使用了Dask数据帧，它本质上是一个大的虚拟数据帧，沿着索引分成多个Pandas数据帧。</li><li id="1f45" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">我们正在研究一个本地集群，包括</li><li id="f2d7" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">一个<em class="ls">调度器</em>(它管理并发送工作/任务给工人)和</li><li id="146c" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated"><em class="ls">工人</em>，他们计算任务。</li><li id="8f23" class="lt lu iq ky b kz mc lc md lf me lj mf ln mg lr ly lz ma mb bi translated">我们实例化了一个Dask客户端，“集群用户面向用户的入口点。”</li></ul><p id="7bc9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这意味着，无论你在哪里编写Python代码，客户机都在那里，客户机与调度程序对话，把任务传递给调度程序。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nq"><img src="../Images/9157c8c27007efef02499b6efb3632e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7garhAWY2yhNJEk1"/></div></div></figure><h1 id="397d" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">盘绕:横向扩展您的数据科学</h1><p id="07bc" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">现在是时候奔向云了。如果您能够访问云资源(比如AWS ),并且知道如何配置Kubernetes和Docker容器，那么您就可以在云中运行Dask集群。然而，这仍然需要大量的时间。</p><p id="fb9a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">另一种方法是使用线圈，我们将在这里介绍。为此，我还登录了<a class="ae kv" href="http://beta.coiled.io/" rel="noopener ugc nofollow" target="_blank">盘绕云</a>，安装了盘绕pip，并通过了身份验证。如果您想继续学习，可以在终端中自己完成这项工作</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="73c9" class="nj mi iq nf b gy nk nl l nm nn">pip install coiled --upgrade<br/>coiled login  # redirects you to authenticate with github or google</span></pre><p id="0673" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后，我们执行必要的导入，启动一个集群(大约需要一分钟)，并实例化我们的客户端:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="defd" class="nj mi iq nf b gy nk nl l nm nn">import coiled<br/>from dask.distributed import LocalCluster, Client<br/>cluster = coiled.Cluster(n_workers=10)<br/>client = Client(cluster)</span></pre><p id="e141" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">然后我们可以导入我们的数据(这次是从s3 ),并按以下方式执行分组:</p><pre class="kg kh ki kj gt ne nf ng nh aw ni bi"><span id="c1cb" class="nj mi iq nf b gy nk nl l nm nn">import dask.dataframe as dd<br/><br/># Read data into a Dask DataFrame<br/>df = dd.read_csv(<br/>    "s3://nyc-tlc/trip data/yellow_tripdata_2019-*.csv",<br/>    dtype={<br/>        'RatecodeID': 'float64',<br/>       'VendorID': 'float64',<br/>       'passenger_count': 'float64',<br/>       'payment_type': 'float64'<br/>    },<br/>    storage_options={"anon":True}<br/>mean_amount = df.groupby("passenger_count").tip_amount.mean().compute()</span></pre><p id="8614" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在Coiled Cloud上，这一切只花了不到30秒的时间，比我在笔记本电脑上花的时间少了一个数量级，即使对于这个相对简单的分析也是如此。</p><p id="f56e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">请注意能够在单个工作流程中完成这组分析的强大功能。没有必要转换上下文或环境。最重要的是，在Coiled中，当我们完成后，可以直接在我的本地工作站或pandas上使用Dask。云计算在必要时很棒，但在不必要时会成为负担。</p><h1 id="9907" class="mh mi iq bd mj mk ml mm mn mo mp mq mr jw ms jx mt jz mu ka mv kc mw kd mx my bi translated">你需要更快的数据科学吗？</h1><p id="5c3d" class="pw-post-body-paragraph kw kx iq ky b kz mz jr lb lc na ju le lf nb lh li lj nc ll lm ln nd lp lq lr ij bi translated">您也可以立即开始使用盘绕式集群。Coiled还处理安全性、conda/docker环境和团队管理，因此您可以继续研究数据科学。今天就在<a class="ae kv" href="https://cloud.coiled.io/" rel="noopener ugc nofollow" target="_blank">卷云</a>上免费开始吧。</p></div><div class="ab cl nr ns hu nt" role="separator"><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw nx"/><span class="nu bw bk nv nw"/></div><div class="ij ik il im in"><p id="70ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><em class="ls">原载于2020年9月23日</em><a class="ae kv" href="https://coiled.io/blog/dask-in-the-cloud/" rel="noopener ugc nofollow" target="_blank"><em class="ls">https://coiled . io</em></a><em class="ls">。</em></p></div></div>    
</body>
</html>