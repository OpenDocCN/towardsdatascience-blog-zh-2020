<html>
<head>
<title>Covid-19 and Pneumonia Detection with Transfer Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用迁移学习进行新冠肺炎和肺炎检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/covid-19-and-pneumonia-detection-with-transfer-learning-400a8150268?source=collection_archive---------33-----------------------#2020-11-03">https://towardsdatascience.com/covid-19-and-pneumonia-detection-with-transfer-learning-400a8150268?source=collection_archive---------33-----------------------#2020-11-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0402" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">用于新冠肺炎和肺炎检测的具有网格搜索优化参数的ResNet50转移学习</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/3796309be03cc442da79b159dcdb82c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*x-_tnxKpD3wZBcdia5ATbQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">来自pixabay的Img通过<a class="ae ku" href="https://pixabay.com/photos/easter-eggs-virus-covid-19-4978337/" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="de70" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在以前的帖子中，我们为商业问题创建了几个CNN网络，从时尚设计，癌症检测，到动物检测等等。在本帖中，我们将重温CNN的话题。但是，我们将使用迁移学习，并在著名的CNN架构ResNet50上构建网络，而不是从头开始创建模型。</p><blockquote class="lr"><p id="fe5b" class="ls lt it bd lu lv lw lx ly lz ma lq dk translated">"如果说我看得更远，那是因为我站在巨人的肩膀上."艾萨克·牛顿在1675年</p></blockquote><p id="bbf0" class="pw-post-body-paragraph kv kw it kx b ky mb ju la lb mc jx ld le md lg lh li me lk ll lm mf lo lp lq im bi translated">像平常一样，拆分成如下:</p><ol class=""><li id="d521" class="mg mh it kx b ky kz lb lc le mi li mj lm mk lq ml mm mn mo bi translated"><strong class="kx iu">背景&amp;问题</strong></li><li id="760d" class="mg mh it kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated"><strong class="kx iu"> ResNet概述</strong></li><li id="39a7" class="mg mh it kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated"><strong class="kx iu">数据审核</strong></li><li id="4a66" class="mg mh it kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated"><strong class="kx iu">列车型号</strong></li><li id="b4b8" class="mg mh it kx b ky mp lb mq le mr li ms lm mt lq ml mm mn mo bi translated"><strong class="kx iu">外卖</strong></li></ol><p id="6e84" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们开始旅程吧🏃‍♀️🏃‍♂️!</p><p id="daa7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 1。背景&amp;问题</strong></p><p id="1d4c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">人工智能和人工智能已经彻底改变了医疗保健和医药行业。根据发表在《自然》杂志上的一项研究，在从乳房x光片中诊断乳腺癌方面，人工智能比医生更准确。最近，来自谷歌健康和伦敦帝国理工学院的研究人员根据近29000名女性的x光图像训练了一个模型。该算法在阅读乳房x光片方面胜过六名放射科医生👏👏。</p><p id="21df" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这里，我们的目标是自动检测和分类胸部疾病的过程，并减少检测的成本和时间。</p><p id="e10a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 2。ResNet概述</strong></p><p id="fb0a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">ResNet50是何等人在他们2015年的论文<a class="ae ku" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank">图像识别的深度残差学习</a>中介绍的一种50层深度残差网络。它以剩余学习为基础，与ResNet101和ResNet152等公司使用的架构相同。</p><p id="ba2d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">那么，什么是剩余学习呢？通常，在创建神经网络时，“越深越好”。随着图层越来越多，网络往往会学习到更多具有更好的泛化能力的要素。然而，这是有限度的。随着模型的深入，神经网络的训练变得困难，模型性能开始饱和甚至下降。这主要是由臭名昭著的消失梯度问题造成的。当梯度反向传播到更早的层时，导数的重复乘法使得梯度无限小，这使得不可能更新更早的层的权重。剩余学习是解决这一问题的突破口之一。</p><p id="bbb6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">与学习输入图像特征的CNN相反，残差学习学习“残差”(这不是很明显吗？🤭🤭).好吧，如果不是，残差可以理解为从输入图像中减去特征。ResNet通过引入所谓的“<strong class="kx iu">标识快捷连接</strong>来实现这一点，它跳过了一个或多个中间层。换句话说，如图1所示，早期层的输出被提供给更深的层，而没有任何转换</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/ddc8ed7d4d2754b66afe31b6cbcd928b.png" data-original-src="https://miro.medium.com/v2/resize:fit:538/format:webp/1*FmMks9joSvhHJ0-NYCkkPA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图1剩余框图(图片由作者提供)</p></figure><p id="955a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">使用捷径连接，期望的映射是<strong class="kx iu"> <em class="mv"> F(X) + X </em> </strong>。所以，残差块只需要专注于残差学习<strong class="kx iu"> <em class="mv"> F(X) </em> </strong>，因为它至少可以通过强制<strong class="kx iu"> <em class="mv"> F(X) </em> </strong>为零来学习X。跳过连接背后的直觉是，它比任何其他直接映射更容易学习残差。这驱使更深层去学习不同于输入已经编码的东西。同时，它允许训练非常深的网络，而不用担心退化问题。</p><p id="c0a9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">ResNet架构包含两种剩余块:<strong class="kx iu">身份块和</strong>conv块。图2示出了身份块。主分支有一个卷积层，后面是批量归一化和一个激活层，通常使用<em class="mv"> ReLu </em>。在这之后，另一个单位的卷积层，批量标准化和激活层。然后，我们添加第三卷积层和批量标准化。激活前，批量定额的输出与原始输入相加。当输入X的形状与主分支的输出相同时，恒等块工作良好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/084c59d2b32a6eb6bc67cb6b683b49cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*ENugSirwXSM4Riy7d3dTlQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图2身份框图(图片由作者提供)</p></figure><p id="1bb6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">第二种类型是Conv块，如图3所示。唯一的区别是在快捷路径中添加了卷积层和批量归一化，以匹配主分支的输出形状。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="mx my di mz bf na"><div class="gh gi ki"><img src="../Images/0cff7ebfc79eba5bf386f43ecfe5de56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*dVANz5gz29o-SRPAY2Zsww.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图3 Conv框图(图片由作者提供)</p></figure><p id="765b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">总之，ResNet50架构包括4个Conv块和12个身份块，以及1个正常卷积层和1个密集层。</p><p id="72a2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 3。数据回顾</strong></p><p id="7495" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">每一类给我们133张图片:健康的；新冠肺炎；细菌性肺炎；病毒性肺炎。图像保存在本地驱动器中，所以我们将使用Keras的<em class="mv"> flow_from_directory() </em>方法来读取图像。具体来说，</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="6abb" class="ng nh it nc b gy ni nj l nk nl">image_generator = ImageDataGenerator(rescale = 1./255, validation_split= 0.2)</span><span id="810a" class="ng nh it nc b gy nm nj l nk nl">train_gen = image_generator.flow_from_directory(batch_size = 8,directory= train_data_dir,shuffle = True,target_size = (256, 256), class_mode = ‘categorical’,subset= ‘training’)</span><span id="9bba" class="ng nh it nc b gy nm nj l nk nl">validation_gen = image_generator.flow_from_directory(batch_size = 8,directory= train_data_dir,shuffle = True,target_size = (256, 256),class_mode = ‘categorical’, subset= ‘validation’)</span></pre><p id="73a6" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们来接触一下各个班级的形象。图4显示了灰度图像。像我这样的人一点也看不出他们的区别😭😭。但是不用担心😎😎！这是模特的工作。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/3f14fc4ed6db06a9b9ec183df2fbf00e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*iGZ6bFR95_rAu8QMUn7Ntw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图4数据样本图像</p></figure><p id="cf77" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 4。列车型号</strong></p><p id="643a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">如前所述，我们将从预先训练的ResNet50模型进行迁移学习。它是在ImageNet数据集上训练的，该数据集包含1100万张图像和11000个类别，与我们在这里获得的数据集相比是巨大的。</p><p id="8492" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">4.1负载模型</p><p id="53ca" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">首先，让我们加载模型，并指定如何根据我们的目的使用它。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="b820" class="ng nh it nc b gy ni nj l nk nl">basemodel = ResNet50(weights = ‘imagenet’, include_top = False, input_tensor = Input(shape = (256, 256, 3)))</span></pre><p id="eead" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">注意，我们没有包括顶级分类层，因为我们将创建自己的分类器头。我们将输入张量形状定义为与图像生成器中的相同。</p><p id="a6ac" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">一般来说，迁移学习有不同的策略。如果预训练数据集和新数据集相似，并且数据集很小，我们可以冻结早期的层并训练其余的层。如果您的任务是处理大型数据集，您可能需要使用预训练模型中初始化的权重来重新训练整个模型。</p><p id="e1db" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在我们的例子中，我们的数据集非常小，允许我们冻结早期的层。所以，</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="a8eb" class="ng nh it nc b gy ni nj l nk nl">for layer in basemodel.layers[: -10]:<br/>    layer.trainable = False</span></pre><p id="fb31" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">4.2创建和训练模型</p><p id="9820" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我认为这一节是有趣的部分，因为你将看到如何“站在巨人的肩膀上”。</p><p id="c5f4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">仔细看下面的建筑。我们将ResNet50模型输出作为其后续层的输入。在为输出添加最后一个密集层之前，我们堆叠了3个带有dropout的密集层。</p><p id="6277" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">包括神经元数量和辍学率在内的参数在网格搜索中进行了实验，以显示最佳结果，尽管这里没有详细说明。</p><p id="51c2" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">另请注意，我们使用两个指标来评估培训:F1得分和准确性。根据我的大量实验，该模型在某种程度上倾向于将细菌性肺炎错误分类。因此，使用F1分数将使我们有一个平衡的模型性能。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="29b6" class="ng nh it nc b gy ni nj l nk nl">headmodel = basemodel.output<br/>headmodel = AveragePooling2D(pool_size = (4,4))(headmodel)<br/>headmodel = Flatten(name= ‘flatten’)(headmodel)<br/>headmodel = Dense(256, activation = “relu”)(headmodel)<br/>headmodel = Dropout(0.4)(headmodel)<br/>headmodel = Dense(128, activation = “relu”)(headmodel)<br/>headmodel = Dropout(0.4)(headmodel)<br/>headmodel = Dense(64, activation = “relu”)(headmodel)<br/>headmodel = Dropout(0.4)(headmodel)<br/>headmodel = Dense(4, activation = ‘softmax’)(headmodel)</span><span id="f9d4" class="ng nh it nc b gy nm nj l nk nl">model = Model(inputs = basemodel.input, outputs = headmodel)</span><span id="9590" class="ng nh it nc b gy nm nj l nk nl">model.compile(loss = ‘categorical_crossentropy’,optimizer = optimizers.RMSprop(lr = 1e-4, decay = 1e-6),metrics = [f1, ‘accuracy’])</span></pre><p id="59c3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">此外，我们使用早期停止来监控进度，并使用检查点来保存权重文件。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="1837" class="ng nh it nc b gy ni nj l nk nl">earlystopping = EarlyStopping(monitor = ‘val_loss’, mode = ‘min’, patience = 10)<br/>checkpointer = ModelCheckpoint(filepath = ‘weights.hdfs’, verbose = 1, save_best_only=True)</span></pre><p id="66a4" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">太好了。时段数(20)和批次大小(8)经过优化，可产生最佳结果。为了训练这个模型，</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="c1db" class="ng nh it nc b gy ni nj l nk nl">history = model.fit_generator(<br/>train_generator, steps_per_epoch= train_generator.n//8, <br/>epochs = 20, validation_data= val_generator, <br/>validation_steps= val_generator.n//8, callbacks=[checkpointer, earlystopping])</span></pre><p id="dbda" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">4.3评估模型</p><p id="0a74" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图5示出了模型精度逐渐增加到大约0.75，并且损失减少到大约0.65。还有一点就是训练过程是稳定的，没有突兀的波峰或波谷。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/1b9ab8ffe475441f6396dce79a50c5ee.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*fLto5YnEqGEcRr4ouFhcVw.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图5训练过程中的模型损失和精度曲线</p></figure><p id="0301" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图6显示了验证过程中的模型精度。该模型达到了大约0.65到0.7的验证精度，表明轻微的过度拟合。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi no"><img src="../Images/98c7ef1ef4a78237a5bf3724c50e5d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:692/format:webp/1*IjK-951SviznqpId7_w9AQ.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图6验证期间的模型精度曲线</p></figure><p id="104a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，让我们看看测试数据集上的模型性能。</p><pre class="kj kk kl km gt nb nc nd ne aw nf bi"><span id="498c" class="ng nh it nc b gy ni nj l nk nl">evaluate=model.evaluate_generator(test_generator,steps=test_generator.n//4, verbose = 1)</span></pre><p id="e8bb" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">图7示出了15幅图像的预测和实际类别。该模型对新冠肺炎的预测非常准确。如图8所示的分类报告表明，对于✨✨.，该模型对新冠肺炎的召回率为100%这意味着在10幅新冠肺炎图像中，它成功地全部预测正确。对于肺炎，回忆并不理想，大约有50%到60%的预测正确。当然，这种模式还有改进的空间。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/6c5d311561d11ac63b0a1fe8d4aea948.png" data-original-src="https://miro.medium.com/v2/resize:fit:1204/format:webp/1*d2LfUOSfen0RHBvD5qo8PA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图7标有实际和预测类别的模型预测</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi np"><img src="../Images/45952767f4e6973ef8ed8111a9b7a068.png" data-original-src="https://miro.medium.com/v2/resize:fit:884/format:webp/1*MTx6jZbrCK38_GF7Eh2QzA.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图8模型分类报告</p></figure><p id="3279" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu"> 5。外卖</strong></p><p id="92b7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们演示了如何使用迁移学习来创建新冠肺炎/肺炎预测的定制模型。只有大约500张图像，我们设法取得了不错的结果，特别是在新冠肺炎检测上。</p><p id="1cde" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">接下来有趣的是，如果你想弄脏你的手，只在正常和新冠肺炎图像上改装模型。创造一个新冠肺炎探测模型将是一件美妙的小事，我们可以为对抗它做出贡献。</p><p id="8617" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">太好了！这是所有的旅程。希望你喜欢它。如果你需要代码，请访问我的Github <a class="ae ku" href="https://github.com/luke4u/CNN-Image-Classification" rel="noopener ugc nofollow" target="_blank"> repos </a>💕💕。</p></div></div>    
</body>
</html>