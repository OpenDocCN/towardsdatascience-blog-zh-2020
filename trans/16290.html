<html>
<head>
<title>Variational Autoencoders as Generative Models with Keras</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Keras作为生成模型的可变自动编码器</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/variational-autoencoders-as-generative-models-with-keras-e0c79415a7eb?source=collection_archive---------8-----------------------#2020-11-10">https://towardsdatascience.com/variational-autoencoders-as-generative-models-with-keras-e0c79415a7eb?source=collection_archive---------8-----------------------#2020-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/74cd20631a58b7c81a7047b743e0e4f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*MuqvVG-7DuztaDOC.jpg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用Keras的可变自动编码器和图像生成|图片由<a class="ae jg" href="https://unsplash.com/@bamagal" rel="noopener ugc nofollow" target="_blank">“我的镜头生活”</a>来自Unsplash | <a class="ae jg" href="https://unsplash.com/photos/bq31L0jQAjU" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure><h2 id="82bd" class="jh ji jj bd b dl jk jl jm jn jo jp dk jq translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="1b97" class="pw-subtitle-paragraph kp js jj bd b kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg dk translated">引入变分自动编码器和使用Keras生成图像</h2></div><h2 id="6c45" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">概观</h2><p id="828a" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">本文旨在让读者对变型自动编码器有一些基本的了解，并解释它们在机器学习和人工智能方面与普通自动编码器的不同之处。不同于普通的自动编码器(如稀疏自动编码器、去噪自动编码器。etc)，变分自动编码器(VAEs)是类似GANs ( <a class="ae jg" href="https://en.wikipedia.org/wiki/Generative_adversarial_network" rel="noopener ugc nofollow" target="_blank">生成对抗网络</a>)的生成模型。这篇文章主要集中在变化的自动编码器上，我将很快在我即将发布的帖子中写关于生成敌对网络的内容。</p><p id="59ba" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">在本教程中，我们将讨论如何从头开始用Keras(TensorFlow，Python)训练一个变分自动编码器(VAE)。我们将以一个简单VAE的生成能力的演示来结束我们的研究。</p><p id="aa3d" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">本教程的其余内容可分为以下几类-</p><ol class=""><li id="ea8b" class="na nb jj me b mf mv mi mw lq nc lu nd ly ne mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">背景:变分自动编码器</em> </strong></li><li id="012b" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">在喀拉斯建造VAE</em></strong></li><li id="9fc0" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">在MNIST数据集上训练VAE</em></strong></li><li id="0677" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">结果</em> </strong></li><li id="1623" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">图像生成能力</em> </strong></li><li id="d88c" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">汇总</em> </strong></li><li id="8c3a" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">延伸阅读和资源</em> </strong></li></ol></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="1bf6" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">1.变分自动编码器</h1><h2 id="cfb4" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">背景</h2><p id="d1b5" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">自动编码器基本上是一种神经网络，它将高维数据点作为输入，将其转换为低维特征向量(即潜在向量)，并且稍后仅利用潜在向量表示来重构原始输入样本，而不会丢失有价值的信息。任何给定的自动编码器都由以下两部分组成——编码器和解码器。模型的编码器部分获取输入数据样本，并将其压缩成潜在向量。而解码器部分负责从学习的(由编码器在训练期间学习的)潜在表示中重建原始输入样本。要了解更多基础知识，请查看我关于Keras中的<a class="ae jg" href="https://dropsofai.com/autoencoders-in-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">自动编码器和深度学习</a>的文章。</p><blockquote class="oh"><p id="c6b8" class="oi oj jj bd ok ol om on oo op oq mu dk translated">让我们继续考虑，直到现在我们都在同一页上。</p></blockquote><p id="705d" class="pw-post-body-paragraph mc md jj me b mf or kt mh mi os kw mk lq ot mm mn lu ou mp mq ly ov ms mt mu im bi translated">普通自动编码器的一个问题是它们独立地编码每个输入样本。这意味着属于同一类的样本(或属于同一分布的样本)可能学习到非常不同的(潜在空间中的远距离编码)潜在嵌入。理想情况下，同类的潜在特征应该有些相似(或者潜在空间上更接近)。这是因为我们没有明确强制神经网络学习输入数据集的分布。由于这个问题，我们的网络可能不太擅长重建相关的看不见的数据样本(或不太可归纳)。</p><p id="d5bf" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">在过去关于Keras中的<a class="ae jg" href="https://dropsofai.com/autoencoders-in-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">自动编码器和深度学习</a>的教程中，我们训练了一个普通的自动编码器，并学习了MNIST手写数字图像的潜在特征。当我们在具有相应标签的潜在空间中绘制这些嵌入时，我们发现相同类别的学习嵌入有时出现相当随机，并且在不同类别的嵌入聚类之间没有清晰可见的边界。下图显示了分布情况-</p><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/86a3dda1ff9b422698e5080f2d2cc298.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/1*h3UL52-1eq5_axJM0KWN2Q.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用Keras的可变自动编码器和图像生成|作者图片| <a class="ae jg" href="https://dropsofai.com/autoencoders-in-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">图片来源</a></p></figure></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="7c0d" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">可变自动编码器</h2><p id="1060" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">变分自动编码器本质上略有不同。它不是直接从输入样本中学习潜在特征，而是实际学习潜在特征的分布。假设输入数据的潜在特征遵循标准正态分布。这意味着学习到的潜在向量应该是以零为中心的，并且它们可以用两个统计量来表示——均值和方差(因为标准正态分布可以仅用这两个统计量来表示)。</p><p id="6c00" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">因此，变分自动编码器(vae)计算每个样本的潜在向量的均值和方差(而不是直接学习潜在特征),并迫使它们遵循标准的正态分布。因此，网络的瓶颈部分用于学习每个样本的均值和方差，我们将定义两个不同的全连接(FC)层来计算这两个值。VAEs确保潜在空间中彼此非常接近的点代表非常相似的数据样本(相似的数据类别)。我们将在本教程中证明这一事实。</p><p id="0dd0" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">在进入实现细节之前，让我们首先了解一下KL-divergence，它将被用作我们模型中的两个优化度量之一。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="1510" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">库尔贝克-莱布勒(KL)散度</h2><p id="c1ec" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">在上一节中，我们讨论了对输入数据集的潜在要素实施标准正态分布。这可以使用KL-散度统计来实现。<a class="ae jg" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence" rel="noopener ugc nofollow" target="_blank"> KL-divergence </a>是两个概率分布之间差异的统计度量。因此，我们将利用KL-散度值作为目标函数(连同重建损失),以确保学习分布非常类似于真实分布，我们已经假设真实分布是标准正态分布。</p><p id="2f61" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">在这种情况下，最终目标可以写成-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="3671" class="lh li jj pc b gy pg ph l pi pj"><em class="nj">Objective = Reconstruction Loss + KL-Loss</em></span></pre><p id="4f63" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这里，重建损失项将鼓励模型学习正确重建原始图像(如果不完全相同，则为同一类别的图像)所需的重要潜在特征。而KL散度损失项将确保学习的分布类似于真实分布(标准正态分布)。这进一步意味着分布以零为中心，并且在空间中分布均匀。我们将在教程的后半部分证明这一点。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="f856" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">2.在喀拉斯建造VAE</h1><p id="2d59" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">最后一节解释了机器学习(ML)和人工智能(AI)中可变自动编码器(VAEs)背后的基本思想。在这一节中，我们将使用Python中的Keras构建一个卷积变分自动编码器。该网络将在Keras数据集中可用的MNIST手写数字数据集上进行训练。</p><p id="f593" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">为逐步理解和简化起见，本节可分为以下几个部分</p><ol class=""><li id="887a" class="na nb jj me b mf mv mi mw lq nc lu nd ly ne mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">数据准备</em> </strong></li><li id="8866" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">建筑编码器</em> </strong></li><li id="471b" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">潜在分布和采样</em> </strong></li><li id="7722" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">建筑解码器</em> </strong></li><li id="8b04" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">建筑VAE </em> </strong></li><li id="c1ef" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><strong class="me jt"> <em class="nj">损失</em> </strong></li></ol></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="6bc1" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">数据准备</h2><p id="1712" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">在本节中，我们将下载MNIST手写数字数据集并将其加载到我们的Python笔记本中，以开始准备数据。</p><p id="8cca" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这是预先加载的依赖项-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="789d" class="lh li jj pc b gy pg ph l pi pj"><strong class="pc jt">import</strong> <!-- -->numpy as np<br/><strong class="pc jt">import</strong> <!-- -->matplotlib.pyplot as plt<br/><strong class="pc jt">import</strong> <!-- -->pandas as pd<br/><strong class="pc jt">import</strong> <!-- -->seaborn as sns<br/><strong class="pc jt">import</strong> <!-- -->warnings</span><span id="570a" class="lh li jj pc b gy pk ph l pi pj">warnings.filterwarnings('ignore')<br/><strong class="pc jt">%</strong>matplotlib inline</span></pre><p id="198f" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">以下python代码可用于下载MNIST手写数字数据集。下面还显示了一些示例图像-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="8393" class="lh li jj pc b gy pg ph l pi pj"><strong class="pc jt">from</strong> <!-- -->tensorflow.keras.datasets <strong class="pc jt">import</strong> <!-- -->mnist</span><span id="e90f" class="lh li jj pc b gy pk ph l pi pj">(trainX, trainy), (testX, testy) <strong class="pc jt">=</strong> <!-- -->mnist.load_data()</span><span id="55a7" class="lh li jj pc b gy pk ph l pi pj">print('Training data shapes: X=%s, y=%s'<!-- --> <strong class="pc jt">%</strong> <!-- -->(trainX.shape, trainy.shape))</span><span id="5237" class="lh li jj pc b gy pk ph l pi pj">print('Testing data shapes: X=%s, y=%s'<!-- --> <strong class="pc jt">%</strong> <!-- -->(testX.shape, testy.shape))</span><span id="fe77" class="lh li jj pc b gy pk ph l pi pj"><strong class="pc jt">for</strong> <!-- -->j <strong class="pc jt">in</strong> <!-- -->range(5):<br/>    i <strong class="pc jt">=</strong> <!-- -->np.random.randint(0, 10000)<br/>    plt.subplot(550<!-- --> <strong class="pc jt">+</strong> <!-- -->1<!-- --> <strong class="pc jt">+</strong> <!-- -->j)<br/>    plt.imshow(trainX[i], cmap<strong class="pc jt">=</strong>'gray')<br/>    plt.title(trainy[i])<br/>plt.show()</span></pre><p id="0609" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">数据集已经分为定型集和测试集。训练数据集具有分辨率为28*28的60K手写数字图像。尽管测试数据集由具有相似尺寸的10K手写数字图像组成</p><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pl"><img src="../Images/e270f7e73aa36dc754eab0acfdda38c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*xJ2H-k4RBXaWs4VQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">MNIST数据集|使用Keras的可变自动编码器和图像生成</p></figure><p id="dd75" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">数据集中的每个图像都是一个2D矩阵，表示从0到255的像素强度。我们将首先归一化像素值(使它们在0和1之间)，然后为图像通道添加一个额外的维度(由Keras的Conv2D层支持)。以下是python中的预处理代码-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="5bec" class="lh li jj pc b gy pg ph l pi pj">train_data <strong class="pc jt">=</strong> <!-- -->trainX.astype('float32')<strong class="pc jt">/</strong>255<br/>test_data <strong class="pc jt">=</strong> <!-- -->testX.astype('float32')<strong class="pc jt">/</strong>255</span><span id="fb05" class="lh li jj pc b gy pk ph l pi pj">train_data <strong class="pc jt">=</strong> <!-- -->np.reshape(train_data, (60000, 28, 28, 1))<br/>test_data <strong class="pc jt">=</strong> <!-- -->np.reshape(test_data, (10000, 28, 28, 1))</span><span id="e54c" class="lh li jj pc b gy pk ph l pi pj">print<!-- --> <!-- -->(train_data.shape, test_data.shape)</span><span id="6f0d" class="lh li jj pc b gy pk ph l pi pj">Out[1]: (60000, 28, 28, 1) (10000, 28, 28, 1)</span></pre></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="9380" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">建筑编码器</h2><p id="d3df" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">在这一节中，我们将定义VAE模型的编码器部分。当输入数据类型是图像时，自动编码器的编码器部分通常包括多个重复的卷积层，然后是池层。变型自动编码器的编码器部分也非常相似，只是瓶颈部分与上面讨论的略有不同。</p><p id="d4c2" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这里是编码器部分的python实现，带有Keras-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="fe87" class="lh li jj pc b gy pg ph l pi pj"><strong class="pc jt">import</strong> <!-- -->tensorflow</span><span id="ae81" class="lh li jj pc b gy pk ph l pi pj">input_data <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.Input(shape<strong class="pc jt">=</strong>(28, 28, 1))</span><span id="f9a5" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.Conv2D(64, (5,5), activation<strong class="pc jt">=</strong>'relu')(input_data)</span><span id="8b2f" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.MaxPooling2D((2,2))(encoder)</span><span id="2f4d" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.Conv2D(64, (3,3), activation<strong class="pc jt">=</strong>'relu')(encoder)</span><span id="efee" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.MaxPooling2D((2,2))(encoder)</span><span id="4c8f" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.Conv2D(32, (3,3), activation<strong class="pc jt">=</strong>'relu')(encoder)</span><span id="3b05" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.MaxPooling2D((2,2))(encoder)</span><span id="6af0" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.Flatten()(encoder)</span><span id="7a1c" class="lh li jj pc b gy pk ph l pi pj">encoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.layers.Dense(16)(encoder)</span></pre><p id="3dd6" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">上面的片段压缩了图像输入，并将其降低到16值特征向量，但这些不是最终的潜在特征。下一节将通过添加潜在特征计算逻辑来完成编码器部分。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="a14b" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">潜在分布和抽样</h2><p id="4ae1" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">该部分负责从上一部分中提取复杂的特征，并计算潜在特征的平均值和对数方差(因为我们已经假设潜在特征遵循标准正态分布，并且该分布可以用平均值和方差统计值来表示)。两个独立的全连接(FC层)层用于计算给定数据集的输入样本的平均值和对数方差。</p><p id="dba9" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">标准正态分布(SND)的这些属性(平均值和对数方差)随后用于估计相应输入数据点的潜在编码。下面定义的函数<em class="nj"> sample_latent_features </em>取这两个统计值并返回一个潜在编码向量。该潜在编码被传递给解码器作为图像重建目的的输入。</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="571e" class="lh li jj pc b gy pg ph l pi pj">def sample_latent_features(distribution):<br/>    distribution_mean, distribution_variance = distribution<br/>    batch_size = tensorflow.shape(distribution_variance)[0]<br/>    random = tensorflow.keras.backend.random_normal(shape=(batch_size, tensorflow.shape(distribution_variance)[1]))<br/>    return distribution_mean + tensorflow.exp(0.5 * distribution_variance) * random<br/> <br/>distribution_mean = tensorflow.keras.layers.Dense(2, name='mean')(encoder)</span><span id="8b43" class="lh li jj pc b gy pk ph l pi pj">distribution_variance = tensorflow.keras.layers.Dense(2, name='log_variance')(encoder)</span><span id="65df" class="lh li jj pc b gy pk ph l pi pj">latent_encoding = tensorflow.keras.layers.Lambda(sample_latent_features)([distribution_mean, distribution_variance])</span></pre><p id="b625" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这些潜在特征(从学习的分布计算)实际上完成了模型的编码器部分。现在编码器模型可以定义如下</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="3d05" class="lh li jj pc b gy pg ph l pi pj">encoder_model <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.Model(input_data, latent_encoding)</span><span id="aaaf" class="lh li jj pc b gy pk ph l pi pj">encoder_model.summary()</span></pre><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pm"><img src="../Images/66a9fe840319b2a4d7115347726cb759.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8ho-vL0hsaFcKLcVawyWgQ.png"/></div></div></figure><p id="7a34" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">编码器非常简单，只有大约57K个可训练参数。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="3358" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">建筑解码器</h2><p id="3265" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">该模型的编码器部分将图像作为输入，并将该图像的潜在编码向量作为输出，该输出是从输入数据集的学习分布中采样的。解码器的工作是将该嵌入向量作为输入，并重新创建原始图像(或与原始图像属于相似类别的图像)。由于潜在向量是特征的非常压缩的表示，解码器部分由多对去卷积层和上采样层组成。去卷积层基本上与卷积层相反。上采样层用于恢复图像的原始分辨率。通过这种方式，它可以重建原始尺寸的图像。</p><p id="ada4" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">下面是用TensorFlow的Keras API实现的解码器部分的python实现</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="d4b3" class="lh li jj pc b gy pg ph l pi pj">decoder_input = tensorflow.keras.layers.Input(shape=(2))<br/>decoder = tensorflow.keras.layers.Dense(64)(decoder_input)<br/>decoder = tensorflow.keras.layers.Reshape((1, 1, 64))(decoder)<br/>decoder = tensorflow.keras.layers.Conv2DTranspose(64, (3,3), activation='relu')(decoder)<br/> <br/>decoder = tensorflow.keras.layers.Conv2DTranspose(64, (3,3), activation='relu')(decoder)<br/>decoder = tensorflow.keras.layers.UpSampling2D((2,2))(decoder)<br/> <br/>decoder = tensorflow.keras.layers.Conv2DTranspose(64, (3,3), activation='relu')(decoder)<br/>decoder = tensorflow.keras.layers.UpSampling2D((2,2))(decoder)<br/> <br/>decoder_output = tensorflow.keras.layers.Conv2DTranspose(1, (5,5), activation='relu')(decoder)</span></pre><p id="5508" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">解码器模型对象可以定义如下</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="41ef" class="lh li jj pc b gy pg ph l pi pj">decoder_model <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.Model(decoder_input, decoder_output)</span><span id="045c" class="lh li jj pc b gy pk ph l pi pj">decoder_model.summary()</span></pre><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pn"><img src="../Images/d7f4f8eebb61819d6a4df616f650b1a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3Ve5Y977W-qe0KcV9lHUzQ.png"/></div></div></figure><p id="3c5a" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">解码器同样简单，具有112K可训练参数。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="f0ef" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">构建VAE(可变自动编码器)</h2><p id="4a47" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">最后，可以通过组合编码器和解码器部分来定义变分自动编码器(VAE)。下面是你如何通过在编码器后面粘贴解码器来创建VAE模型对象。</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="e706" class="lh li jj pc b gy pg ph l pi pj">encoded <strong class="pc jt">=</strong> <!-- -->encoder_model(input_data)</span><span id="4ffa" class="lh li jj pc b gy pk ph l pi pj">decoded <strong class="pc jt">=</strong> <!-- -->decoder_model(encoded)</span><span id="cf98" class="lh li jj pc b gy pk ph l pi pj">autoencoder <strong class="pc jt">=</strong> <!-- -->tensorflow.keras.models.Model(input_data, decoded)</span><span id="3234" class="lh li jj pc b gy pk ph l pi pj">autoencoder.summary()</span></pre><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi po"><img src="../Images/c3f63e69c335516c47a7e333be64a9ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-DsD-l_d1kNt3MVNehBWvA.png"/></div></div></figure><p id="39d4" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">整个设置非常简单，只有170，000个可训练模型参数。写目标(或优化函数)函数的时间。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="a535" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">失败</h2><p id="3633" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">如前所述，变分自动编码器(VAE)的最终目标(或损失)函数是数据重建损失和KL损失的组合。在本节中，我们将通过结合这两个统计数据来定义我们的自定义损失。</p><p id="8771" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated"><em class="nj"> get_loss </em>函数的以下实现返回一个<em class="nj"> total_loss </em>函数，它是重建损失和KL-loss的组合，定义如下</p><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pp"><img src="../Images/1796141e73b79cea6e88165317828478.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RKfSj0JQ5jqUfTy74ODuyg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated"><a class="ae jg" href="https://github.com/kartikgill/Autoencoders" rel="noopener ugc nofollow" target="_blank"> Github链接</a></p></figure><p id="720f" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">最后，让我们编译模型，为培训做好准备-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="330f" class="lh li jj pc b gy pg ph l pi pj">autoencoder.compile(loss=get_loss(distribution_mean, distribution_variance), optimizer='adam')</span></pre></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="3ba6" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">3.训练VAE(可变自动编码器)</h1><p id="bc88" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">就像普通的自动编码器一样，我们将通过输入和输出完全相同的图像来训练它。该模型被训练20个时期，批次大小为64。</p><p id="74ce" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这是训练总结-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="08f2" class="lh li jj pc b gy pg ph l pi pj">autoencoder.fit(train_data, train_data, epochs=20, batch_size=64, validation_data=(test_data, test_data))</span></pre><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pq"><img src="../Images/e92a9687ed9873f90d2c34082685a81e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v453kCn2U_fFfIlBEDFZIg.png"/></div></div></figure><p id="1e4c" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">我希望它可以被训练得更好一点，但这是验证损失没有太大变化的地方，我继续进行。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="0a53" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">4.结果</h1><p id="6319" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">在本节中，我们将在测试图像上看到我们的模型的重建能力。以下python脚本将从测试数据集中选取9幅图像，我们将为它们绘制相应的重建图像。</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="a259" class="lh li jj pc b gy pg ph l pi pj">offset<strong class="pc jt">=</strong>400<br/>print<!-- --> <!-- -->("Real Test Images")</span><span id="4338" class="lh li jj pc b gy pk ph l pi pj"># Real Images</span><span id="10f2" class="lh li jj pc b gy pk ph l pi pj"><strong class="pc jt">for</strong> <!-- -->i <strong class="pc jt">in</strong> <!-- -->range(9):<br/>    plt.subplot(330<!-- --> <strong class="pc jt">+</strong> <!-- -->1<!-- --> <strong class="pc jt">+</strong> <!-- -->i)<br/>    plt.imshow(test_data[i<strong class="pc jt">+</strong>offset,:,:, <strong class="pc jt">-</strong>1], cmap<strong class="pc jt">=</strong>'gray')<br/>plt.show()</span><span id="db5c" class="lh li jj pc b gy pk ph l pi pj"># Reconstructed Images</span><span id="9d6f" class="lh li jj pc b gy pk ph l pi pj">print<!-- --> <!-- -->("Reconstructed Images with Variational Autoencoder")</span><span id="c5cb" class="lh li jj pc b gy pk ph l pi pj"><strong class="pc jt">for</strong> <!-- -->i <strong class="pc jt">in</strong> <!-- -->range(9):<br/>    plt.subplot(330<!-- --> <strong class="pc jt">+</strong> <!-- -->1<!-- --> <strong class="pc jt">+</strong> <!-- -->i)<br/>    output <strong class="pc jt">=</strong> <!-- -->autoencoder.predict(np.array([test_data[i<strong class="pc jt">+</strong>offset]]))<br/>    op_image <strong class="pc jt">=</strong> <!-- -->np.reshape(output[0]<strong class="pc jt">*</strong>255, (28, 28))<br/>    plt.imshow(op_image, cmap<strong class="pc jt">=</strong>'gray')<br/>plt.show()</span></pre><p id="79fd" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这是输出-</p><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pr"><img src="../Images/5ad22247f78ee4a73425ee2a2c048c8b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FBSGd8VP0LjVaMvI.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">结果|使用Keras的可变自动编码器和图像生成</p></figure><p id="3521" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">上述结果证实了该模型能够以相当高的效率重建数字图像。然而，这里要注意的一件重要事情是，一些重建图像在外观上与原始图像非常不同，而类别(或数字)总是相同的。发生这种情况是因为重建不仅仅依赖于输入图像，它是已经学习的分布。并且这种学习到的分布是模型输出中引入变化的原因。这很有趣，不是吗！</p><p id="fd57" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">这里要注意的第二件事是输出图像有点模糊。这是变化的自动编码器的常见情况，由于潜在向量(瓶颈)非常小，并且如前所述，存在学习潜在特征的单独过程，它们经常产生有噪声的(或质量差的)输出。变分自动编码器(vae)实际上不是为了重建图像而设计的，真正的目的是学习分布(这给了他们生成假数据的超能力，我们将在后面的帖子中看到)。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h2 id="3fb6" class="lh li jj bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb jp bi translated">潜在特征聚类</h2><p id="dcdb" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">如前所述，变分自动编码器(vae)学习潜在特征的潜在分布，这基本上意味着属于同一类的样本的潜在编码在潜在空间中不应彼此相距太远。其次，总体分布应该是标准正态的，应该是以零为中心。</p><p id="a69b" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">让我们为所有的测试图像生成潜在嵌入，并绘制它们(相同的颜色代表属于相同类别的数字，取自地面真实标签)。这是python代码-</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="9d81" class="lh li jj pc b gy pg ph l pi pj">x = []<br/>y = []<br/>z = []</span><span id="1162" class="lh li jj pc b gy pk ph l pi pj">for i in range(10000):<br/>    z.append(testy[i])<br/>    op = encoder_model.predict(np.array([test_data[i]]))<br/>    x.append(op[0][0])<br/>    y.append(op[0][1])</span><span id="d72c" class="lh li jj pc b gy pk ph l pi pj">df = pd.DataFrame()<br/>df['x'] = x<br/>df['y'] = y<br/>df['z'] = ["digit-"+str(k) for k in z]</span><span id="4886" class="lh li jj pc b gy pk ph l pi pj">plt.figure(figsize=(8, 6))<br/>sns.scatterplot(x='x', y='y', hue='z', data=df)<br/>plt.show()</span></pre><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div class="gh gi ps"><img src="../Images/3c84dce3586cbe721b18ed270751c0d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*Cll02L0PWWU1GvKJ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">基于Keras的变分自动编码器和图像生成</p></figure><p id="9044" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">上图显示分布以零为中心。相同类别数字的嵌入在潜在空间中更接近。数字分离边界也可以很容易地画出来。这正是我们想要从可变自动编码器中实现的。让我们跳到最后一部分，测试我们模型的生成能力。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="8511" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">5.伪图像生成</h1><p id="98ab" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">可变自动编码器可以用作生成模型。前面的部分显示了输入数据的潜在编码遵循标准的正态分布，并且对于不同类别的数字存在明显的界限。</p><p id="5af3" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">请想一想——如果我们已经知道，空间的哪一部分用于哪个类，我们甚至不需要输入图像来重建图像。这意味着我们实际上可以通过从空间(潜在分布空间)传递随机点来生成与训练数据集具有相似特征的数字图像。以这种方式，变分自动编码器可以用作生成模型，以便生成假数据。</p><p id="7cda" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">正如我们所看到的，潜在编码的范围在[-3到3之间，在x轴上也是-3到3]。让我们用只属于这个范围的随机潜在编码生成一串数字。</p><pre class="ox oy oz pa gt pb pc pd pe aw pf bi"><span id="d34f" class="lh li jj pc b gy pg ph l pi pj">generator_model <strong class="pc jt">=</strong> <!-- -->decoder_model</span><span id="2dca" class="lh li jj pc b gy pk ph l pi pj">x_values <strong class="pc jt">=</strong> <!-- -->np.linspace(<strong class="pc jt">-</strong>3, 3, 30)<br/>y_values <strong class="pc jt">=</strong> <!-- -->np.linspace(<strong class="pc jt">-</strong>3, 3, 30)</span><span id="af66" class="lh li jj pc b gy pk ph l pi pj">figure <strong class="pc jt">=</strong> <!-- -->np.zeros((28<!-- --> <strong class="pc jt">*</strong> <!-- -->30, 28<!-- --> <strong class="pc jt">*</strong> <!-- -->30))</span><span id="a58b" class="lh li jj pc b gy pk ph l pi pj"><strong class="pc jt">for</strong> <!-- -->ix, x <strong class="pc jt">in</strong> <!-- -->enumerate(x_values):<br/>    <strong class="pc jt">for</strong> <!-- -->iy, y <strong class="pc jt">in</strong> <!-- -->enumerate(y_values):<br/>        latent_point <strong class="pc jt">=</strong> <!-- -->np.array([[x, y]])<br/>        generated_image <strong class="pc jt">=</strong> <!-- -->generator_model.predict(latent_point)[0]<br/>        figure[ix<strong class="pc jt">*</strong>28:(ix<strong class="pc jt">+</strong>1)<strong class="pc jt">*</strong>28, iy<strong class="pc jt">*</strong>28:(iy<strong class="pc jt">+</strong>1)<strong class="pc jt">*</strong>28,] <strong class="pc jt">= </strong>generated_image[:,:,<strong class="pc jt">-</strong>1]</span><span id="76b4" class="lh li jj pc b gy pk ph l pi pj">plt.figure(figsize<strong class="pc jt">=</strong>(15, 15))<br/>plt.imshow(figure, cmap<strong class="pc jt">=</strong>'gray', extent<strong class="pc jt">=</strong>[3,<strong class="pc jt">-</strong>3,3,<strong class="pc jt">-</strong>3])<br/>plt.show()</span></pre><figure class="ox oy oz pa gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pt"><img src="../Images/aed214eba3f60dd383a574d8227fceda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_T6BRJlENSCTdSHw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">生成的数据|使用Keras的可变自动编码器和图像生成</p></figure><p id="f038" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">你可以在上面的图像矩阵中找到所有的数字(从0到9 ),因为我们试图从潜在空间的所有部分生成图像。生成变化的笔迹的能力是不是太棒了！</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="cb7d" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">6.摘要</h1><p id="088a" class="pw-post-body-paragraph mc md jj me b mf mg kt mh mi mj kw mk lq ml mm mn lu mo mp mq ly mr ms mt mu im bi translated">本教程解释了深度学习和人工智能中的可变自动编码器。通过一个基本的介绍，展示了如何用python中的Keras和TensorFlow实现VAE。在MNIST手写数字数据集上进一步训练该模型，并给出重建结果。</p><p id="f6b8" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">我们已经看到，潜在的编码遵循标准的正态分布(全部归功于KL-divergence ),以及如何将模型的训练解码器部分用作生成模型。我们已经通过仅使用模型的解码器部分生成假数字来证明了这一说法。</p><blockquote class="pu pv pw"><p id="1a4e" class="mc md nj me b mf mv kt mh mi mw kw mk px mx mm mn py my mp mq pz mz ms mt mu im bi translated">如果你有兴趣阅读我关于去噪自动编码器的文章</p><p id="dab4" class="mc md nj me b mf mv kt mh mi mw kw mk px mx mm mn py my mp mq pz mz ms mt mu im bi translated"><a class="ae jg" href="https://dropsofai.com/convolutional-denoising-autoencoders-for-image-noise-reduction/" rel="noopener ugc nofollow" target="_blank"> <em class="jj">卷积去噪图像降噪自动编码器</em> </a></p></blockquote><p id="8110" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated"><strong class="me jt"> <em class="nj"> Github代码链接:</em></strong><a class="ae jg" href="https://github.com/kartikgill/Autoencoders" rel="noopener ugc nofollow" target="_blank">https://github.com/kartikgill/Autoencoders</a></p><p id="d637" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">原载于<a class="ae jg" href="https://dropsofai.com/variational-autoencoders-and-image-generation-with-keras/" rel="noopener ugc nofollow" target="_blank"> <strong class="me jt">滴艾</strong> </a> <strong class="me jt">。</strong></p><p id="21ed" class="pw-post-body-paragraph mc md jj me b mf mv kt mh mi mw kw mk lq mx mm mn lu my mp mq ly mz ms mt mu im bi translated">感谢阅读！希望这对你有帮助。请在下面评论，让我知道你的反馈。下一篇文章再见。</p></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="410b" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">阅读下一篇&gt;&gt;&gt;</h1><ol class=""><li id="f475" class="na nb jj me b mf mg mi mj lq qa lu qb ly qc mu nf ng nh ni bi translated"><a class="ae jg" href="https://dropsofai.com/autoencoders-in-keras-and-deep-learning/" rel="noopener ugc nofollow" target="_blank">Keras和深度学习中的自动编码器</a>(简介)</li><li id="bc53" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="https://dropsofai.com/optimizers-explained-for-training-neural-networks/" rel="noopener ugc nofollow" target="_blank">优化者解释训练神经网络</a></li><li id="3032" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="https://dropsofai.com/optimizing-tensorflow-models-with-quantization-techniques/" rel="noopener ugc nofollow" target="_blank">用量化技术优化张量流模型</a></li><li id="9055" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="https://dropsofai.com/deep-learning-with-pytorch-introduction/" rel="noopener ugc nofollow" target="_blank">用PyTorch进行深度学习:简介</a></li><li id="775f" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="https://dropsofai.com/deep-learning-with-pytorch-first-neural-network/" rel="noopener ugc nofollow" target="_blank">用PyTorch进行深度学习:第一个神经网络</a></li></ol></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="8c1d" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">参考</h1><ol class=""><li id="4f85" class="na nb jj me b mf mg mi mj lq qa lu qb ly qc mu nf ng nh ni bi translated"><a class="ae jg" href="https://blog.paperspace.com/how-to-build-variational-autoencoder-keras/" rel="noopener ugc nofollow" target="_blank">如何在Keras中构建一个可变的自动编码器</a></li><li id="66bc" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="https://www.jeremyjordan.me/variational-autoencoders/" rel="noopener ugc nofollow" target="_blank">变型自动编码器</a></li><li id="599d" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated">【https://keras.io/examples/generative/vae/ T4】</li></ol></div><div class="ab cl np nq hx nr" role="separator"><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu nv"/><span class="ns bw bk nt nu"/></div><div class="im in io ip iq"><h1 id="ccf5" class="nw li jj bd lj nx ny nz lm oa ob oc lp ky od kz lt lb oe lc lx le of lf mb og bi translated">相关研究论文</h1><ol class=""><li id="8392" class="na nb jj me b mf mg mi mj lq qa lu qb ly qc mu nf ng nh ni bi translated"><a class="ae jg" href="https://arxiv.org/abs/1703.01925" rel="noopener ugc nofollow" target="_blank">语法变分自动编码器</a></li><li id="680f" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="https://arxiv.org/abs/1802.04364" rel="noopener ugc nofollow" target="_blank">用于分子图生成的连接树变分自动编码器</a></li><li id="9bc1" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="http://papers.nips.cc/paper/6528-variational-autoencoder-for-deep-learning-of-images-labels-and-captions" rel="noopener ugc nofollow" target="_blank">图像、标签、字幕深度学习的变分自动编码器</a></li><li id="a837" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="http://dm.snu.ac.kr/static/docs/TR/SNUDM-TR-2015-03.pdf" rel="noopener ugc nofollow" target="_blank">使用重构概率的基于变分自动编码器的异常检测</a></li><li id="dfcb" class="na nb jj me b mf nk mi nl lq nm lu nn ly no mu nf ng nh ni bi translated"><a class="ae jg" href="https://arxiv.org/abs/1702.02390" rel="noopener ugc nofollow" target="_blank">用于文本生成的混合卷积变分自动编码器</a></li></ol></div></div>    
</body>
</html>