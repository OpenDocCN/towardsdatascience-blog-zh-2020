<html>
<head>
<title>How to Systematically Fool an Image Recognition Neural Network</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何系统地愚弄一个图像识别神经网络</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d?source=collection_archive---------17-----------------------#2020-09-23">https://towardsdatascience.com/how-to-systematically-fool-an-image-recognition-neural-network-7b2ac157375d?source=collection_archive---------17-----------------------#2020-09-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/60d1b477c698c2471a40bf6c3ee04a92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*HzNS_mRhuF5YnGfb5ktrhw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">来源:<a class="ae jg" href="https://unsplash.com/photos/1X8VQsDEyVU" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><div class=""/><div class=""><h2 id="5f30" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">以及为什么它很重要</h2></div><p id="9ea0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">卷积神经网络(CNN)构成了图像识别的基础，这无疑是深度学习最重要的应用之一。不幸的是，深度学习的许多研究都是在数据集的“完美世界”约束下进行的，以追求几个百分点的准确性。因此，我们开发的架构在理论测试中表现非常好，但在现实世界中不一定如此。</p><p id="8033" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对抗性的例子或输入(想想<em class="lu">对手</em> : <em class="lu">敌人</em>)对于人眼来说无法与常规图像区分开来，但完全可以骗过各种图像识别架构。显然，敌对输入的部署会带来许多令人不安和危险的影响，特别是当AI被赋予更多权力为自己做决定的时候。</p><p id="0379" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，理解和解决系统地产生对抗性输入的方法——应用于深度学习的道德黑客攻击——是很重要的。</p><p id="c13d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Goodfellow等人介绍了一种简单的系统生成对抗输入的方法，称为“快速梯度符号方法”。</p><p id="8d5c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑:</p><ul class=""><li id="963b" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">一个输入向量<em class="lu"> x </em>(这是输入信息——图像——但是把它想象成一个一维列表)</li><li id="15f7" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">对抗性输入<em class="lu"> x </em> -hat(与<em class="lu"> x </em>形状相同，但数值有所改变)</li><li id="134a" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">一个对抗矢量<em class="lu">η</em>(‘eta’被加到输入矢量上以产生对抗输入矢量)</li></ul><p id="4e5f" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了执行逐个元素的乘法和求和(例如<code class="fe mj mk ml mm b">[1,2,3] × [1,2,3] = 1+4+9 = 14</code>)，我们将第一个向量的转置与第二个向量相乘。这将被称为“加权和”。</p><figure class="mn mo mp mq gt iv"><div class="bz fp l di"><div class="mr ms l"/></div></figure><p id="093d" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们在这里有两个目标，我们必须都实现，以生成对抗性输入:</p><ul class=""><li id="a405" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">我们希望最大化原始输入向量的加权和与被扰乱(改变)的敌对输入的加权和之间的差异。这将改变激活状态，并打乱模型的决策过程。</li><li id="ffca" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">我们希望使对立向量<em class="lu"> η </em>的每个单独值尽可能小，以使整个图像在人眼看来不变。</li></ul><p id="e839" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Goodfellow等人提出的解决方案是双管齐下的——而且非常聪明，原因如下。</p><p id="1beb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu"> η </em>设置为sign( <em class="lu"> w </em>)，其中sign函数返回-1表示负值，1表示正值(0表示0)。如果权重为负，则乘以负一得到正和；如果权重为正，则乘以正1，不变。</p><p id="5f34" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">例如，如果权重向量是<code class="fe mj mk ml mm b">[3,-5,7]</code>，<em class="lu"> η </em>将是<code class="fe mj mk ml mm b">[1,-1,1]</code>。加权和为<code class="fe mj mk ml mm b">3+5+7=15</code>。请注意，执行此操作本质上是将否定转化为肯定，并保留肯定(<code class="fe mj mk ml mm b">abs()</code>功能)。这意味着每个数字都是尽可能大的，如果权重在区间<code class="fe mj mk ml mm b">[-1, 1]</code>内，则是可能的最高加权和。</p><p id="f46e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">考虑下面的一些“图片”。虽然它们是二维的，但把它们想象成一维向量。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mt"><img src="../Images/f8fac61ad4e482346573cd5053492eb8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ODoJfBR8VhI4Lv3rt3DACA.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由作者创建。</p></figure><p id="8cdd" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最终的和是10，这与最初的输出-7有很大的不同。当然，这将会打乱网络的预测。</p><p id="985e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这实现了做出大的改变的目标，但是它一点也不谨慎。毕竟，当我们扰乱它时，我们的形象已经发生了显著的变化:</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi mu"><img src="../Images/ae19e7577c0a9a1525d3b574fe5fc89a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1viUvPv6qmwYZ-UrC8ivkQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由作者创建。</p></figure><p id="afc3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请记住，我们之前将最终总和表示为<em class="lu">w</em>(<em class="lu">x</em>)+<em class="lu">w</em>(<em class="lu">η</em>)，其中<em class="lu"> w </em>()是加权总和，<em class="lu"> η </em>是概率向量，这实际上是对<em class="lu">w</em>(<em class="lu">x</em>+<em class="lu">η</em>)的扩展。我们想稍微改变每个像素的值。虽然总效果必须最大化，但是<em class="lu"> η </em>的每个元素必须足够小以至于不被注意到。</p><p id="767a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在对抗输入的实际产生中，像素数<code class="fe mj mk ml mm b"><em class="lu">j</em></code>被定义为<em class="lu"> x </em>的第<code class="fe mj mk ml mm b"><em class="lu">j</em></code>个值加上<em class="lu"> η的第<code class="fe mj mk ml mm b"><em class="lu">j</em></code>个值。</em>首先介绍的符号采取了一点捷径来演示<em class="lu"> η </em>的目的，就是大幅增加<em class="lu">集体总和</em>，不一定是单个像素值。</p><p id="3e43" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><em class="lu"> η </em>的每个元素都相当大:+1或-1，这对适当缩放的数据影响很大。为了解决这个问题，我们将把<em class="lu"> η </em>的每个元素乘以一个带符号的ϵ，其中ϵ是传感器检测到的最小数值单位(或者更小)。对于8位颜色，这个数字是256，因此ϵ = 1/255。</p><p id="226b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因为ϵ是“不可探测的”(或者说几乎不可探测)，所以从视觉上看，它对图像没有影响。但是，每个变化都是按照符号函数构建的，以使加权和的变化最大化。</p><p id="fa00" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">因此，我们将-ϵ或+ϵ添加到输入向量的每个元素，这是一个足够小的变化，因此它是不可检测的，但用符号函数构造，使得变化最大化。</p><blockquote class="mv"><p id="a2a3" class="mw mx jj bd my mz na nb nc nd ne lt dk translated">许多小组件加起来可能会非常大，尤其是如果它们是以智能方式构建的话。</p></blockquote><p id="be5d" class="pw-post-body-paragraph ky kz jj la b lb nf kk ld le ng kn lg lh nh lj lk ll ni ln lo lp nj lr ls lt im bi translated">让我们考虑一下这对我们之前的ϵ=0.2.例子的影响我们能够产生3个单位的差异(总和为-4)。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nk"><img src="../Images/13b796e8f9321f4173e3bba945ab6f35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uGjoQkDNfJpaogV9RB28iQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由作者创建</p></figure><p id="ed88" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这是相当可观的，尤其是考虑到置换向量对原始输入向量的微小改变。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nl"><img src="../Images/d83b37918069a2e2c93bb754d4cd6bb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_lvgigrcFXiFG96d9-gRLw.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由作者创建</p></figure><p id="83a6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果权重向量有<em class="lu"> n </em>维，一个元素的平均绝对值是<em class="lu"> m </em>，那么激活值将增长ϵ <em class="lu"> nm </em>。在高维图像(比如256乘256乘3)中，<em class="lu"> n </em>的值是196608。m和ϵ可能非常小，但仍会对输出产生重大影响。</p><p id="4e13" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这种方法非常快，因为它只改变+ϵ或-ϵ:的输入，但它这样做的方式非常有效，它完全欺骗了神经网络。</p><figure class="mn mo mp mq gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi nm"><img src="../Images/104d3471af643405eb5e8f2e50c59583.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NzsPpuRCHy5Gsa8yYanETg.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">这里，0.007的ϵ对应于在GoogLeNet转换成实数之后8位图像编码的最小位的幅度。来源:<a class="ae jg" href="https://arxiv.org/pdf/1412.6572.pdf" rel="noopener ugc nofollow" target="_blank">古德费勒等人</a></p></figure><p id="28c9" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Goodfellow等人在应用FGSM时发现了有趣的结果:</p><ul class=""><li id="a20a" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">ϵ=0.25导致浅层SoftMax分类器具有99.9%的错误率，在MNIST上的平均置信度为<em class="lu"> 79.3% </em>。</li><li id="3a3c" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">对于预处理的CIFAR-10上的不正确预测，ϵ=0.1导致CNN具有87.15%的错误率，平均置信度为<em class="lu"> 96.6% </em>。</li></ul><p id="8fd4" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">显然，这些对抗性的输入会导致严重的错误率，但更令人担心的可能是高置信度。这些网络不仅预测错误；他们对自己不正确的输出很有信心。这显然是有问题的:想象一下，在教一个犹豫地回答2×4=6的学生和一个自豪地宣布答案的学生时会有什么不同。</p><p id="4787" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这些对立的输入/示例可以被解释为高维点积的一个属性:当有大量像素要在其中分配和时，加权和可以更大，并且每个单独像素的变化更小。</p><p id="ca24" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">事实上，对立的例子是网络过于线性的结果。毕竟，这种变化对(比如说)一个由sigmoid函数组成的网络几乎没有影响，因为在大多数地方，perbutations的影响是递减的。具有讽刺意味的是，正是这种特性——死亡梯度——导致了ReLU和其他倾向于敌对输入的无界函数的兴起。</p><p id="e8d6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">文件中阐述的其他要点包括:</p><ul class=""><li id="651c" class="lv lw jj la b lb lc le lf lh lx ll ly lp lz lt ma mb mc md bi translated">最重要的是传播的方向，而不是空间中的某一点。模型在多维空间中不存在“弱点”的口袋；相反，在对抗性输入的构建中，决定性的方向才是最重要的。</li><li id="72b2" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">因为方向是最重要的，所以对立结构是广义的。由于寻找对立的输入并不归属于探索模型的预测空间，因此可以将构造方法推广到几种不同类型和架构的模型。</li><li id="6e33" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><em class="lu">对抗性训练可以导致正规化；甚至超过了退学</em>。训练网络识别敌对输入是一种有效的正规化形式，也许比辍学更有效。对抗性训练的正则化效果不能用例如重量衰减或简单增加来复制。</li><li id="8a92" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><em class="lu">容易优化的模型也容易扰动</em>。如果找到一个最佳梯度是简单的，那么计算一个有效的对抗输入也是简单的。</li><li id="c25f" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated">线性模型、为模拟输入分布而训练的模型和集成对对抗性输入没有抵抗力。RBF网络<em class="lu">是抗</em>的。具有隐藏层的体系结构可以被训练成以不同程度的成功识别对立的输入。</li></ul><p id="02f3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">越来越重要的是，走出数据集的有限和完美世界，进入不那么有序的真实世界。通过发现欺骗我们的图像识别模型的有效策略，我们可以在它们被用于更恶意的目的之前防御它们。</p><h2 id="6ed3" class="nn no jj bd np nq nr dn ns nt nu dp nv lh nw nx ny ll nz oa ob lp oc od oe of bi translated">推荐阅读</h2><ul class=""><li id="504c" class="lv lw jj la b lb og le oh lh oi ll oj lp ok lt ma mb mc md bi translated"><a class="ae jg" href="https://arxiv.org/pdf/1412.6572.pdf" rel="noopener ugc nofollow" target="_blank">解释和利用对立的例子(Goodfellow et al.) </a> <br/>以比本文更严格的数学方式介绍FGSM，深入研究实证结果，并讨论理论解释和含义。</li><li id="b856" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><a class="ae jg" href="https://arxiv.org/pdf/1706.06083.pdf" rel="noopener ugc nofollow" target="_blank">走向抗对抗性攻击的深度学习模型(Madry et al.) </a>在FGSM的工作基础上，开发了更复杂的对抗性示例生成方法。</li><li id="a38a" class="lv lw jj la b lb me le mf lh mg ll mh lp mi lt ma mb mc md bi translated"><a class="ae jg" href="https://www.tensorflow.org/tutorials/generative/adversarial_fgsm" rel="noopener ugc nofollow" target="_blank"> TensorFlow教程:与FGSM对立的例子</a>。在TensorFlow中实现FGSM的代码教程。</li></ul><p id="e12a" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">感谢阅读！</p></div></div>    
</body>
</html>