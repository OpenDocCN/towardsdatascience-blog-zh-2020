<html>
<head>
<title>Employees’ Attrition — How Catboost and Shap can help you understand it!</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">员工流失Catboost和Shap如何帮助您了解它！</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/employees-attrition-how-catboost-and-shap-can-help-you-understand-it-814f9bfd7df4?source=collection_archive---------24-----------------------#2020-10-29">https://towardsdatascience.com/employees-attrition-how-catboost-and-shap-can-help-you-understand-it-814f9bfd7df4?source=collection_archive---------24-----------------------#2020-10-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="0f27" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解Scikit和Catboost模型的使用如何帮助您处理不平衡的数据集，以及为什么SHAP是解释人工智能预测的伟大工具。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/9f1bca98e0741eee0e601c62ac9b8ab7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*4EFRtx_Er-x58OzL"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">劳拉·戴维森在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="1c4d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如何同时探索和解决两个关键问题？</p><ul class=""><li id="3904" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">第一种和就业一样古老:人们决定离开他们的雇主去寻找更好的工作。)工作。</li><li id="c046" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">第二个出现在过去几年:能够以一种可以理解的方式解释极其复杂的人工智能模型是如何做出预测的。</li></ul><p id="c5f6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了探究这两个问题，我们需要一些工具和数据:</p><ul class=""><li id="5ff1" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">由于没有公开共享的关于员工辞职的真实数据集，我们将使用IBM数据科学团队创建的数据集来推广Watson。<a class="ae ky" href="https://www.kaggle.com/pavansubhasht/ibm-hr-analytics-attrition-dataset" rel="noopener ugc nofollow" target="_blank">在Kaggle </a>这里有。</li><li id="b811" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">本文使用的代码和笔记本(文末链接)是用<a class="ae ky" href="https://colab.research.google.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Google Colab </strong> </a>创建的。这对开发人员来说是一个很好的资源，免费提供GPU和TPU访问，以及最新的Python库和在需要时安装“外来”包的可能性。</li><li id="6c41" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">Google Colab确实嵌入了很多Python包，但是我们需要安装<a class="ae ky" href="https://catboost.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> CatBoost </strong> </a>(我们的分类器)和<a class="ae ky" href="https://github.com/slundberg/shap" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> SHAP </strong> </a>(我们的解释器):</li></ul><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="d491" class="mo mp it mk b gy mq mr l ms mt">!pip install shap<br/>!pip install catboost</span></pre><h1 id="d814" class="mu mp it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">数据探索</h1><p id="c367" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">在导入这个用例所需的库之后，我们可以观察到数据集由1470个条目组成，其中有9个分类特征和25个数字特征。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="e10d" class="mo mp it mk b gy mq mr l ms mt">import pandas as pd</span><span id="07ae" class="mo mp it mk b gy nq mr l ms mt">from imblearn.under_sampling import ClusterCentroids<br/>from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import confusion_matrix</span><span id="33be" class="mo mp it mk b gy nq mr l ms mt">from catboost import CatBoostClassifier</span><span id="ee70" class="mo mp it mk b gy nq mr l ms mt">import shap</span><span id="463b" class="mo mp it mk b gy nq mr l ms mt"># The following lines should be used only on Google Colab<br/># to connect to your Google Drive</span><span id="9a89" class="mo mp it mk b gy nq mr l ms mt">from google.colab import drive<br/>drive.mount('/content/drive')</span></pre><p id="7665" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第9列“EmployeeNumber”对于每个雇员都是唯一的，因此我们将使用它作为我们的Pandas数据框架的索引。在读取CSV文件时，由于“index_col=9 ”,此指令得以通过:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="4d66" class="mo mp it mk b gy mq mr l ms mt">df = pd.read_csv("./WA_Fn-UseC_-HR-Employee-Attrition.csv", <strong class="mk iu">index_col=9</strong>)</span><span id="4245" class="mo mp it mk b gy nq mr l ms mt">df.info()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/d207e0f0b664c07d19169e7689608435.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Sx2twUXZkHAvC_JuzFRDfg.png"/></div></div></figure><p id="f4c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">整个数据集中没有缺失的信息…这显然是一个合成的数据😅。</p><p id="6501" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们进入建模阶段之前，我建议做一些改进:</p><ol class=""><li id="276b" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ns mb mc md bi translated">让我们创建两个字典，根据它们的基数(0，1，2)将“是/否”列转换为“0/1”和旅行频率类别。</li></ol><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="1163" class="mo mp it mk b gy mq mr l ms mt">yes_no_to_0_1_dict = {"Yes": 1, "No": 0}<br/>business_travel_dict = {"Non-Travel": 0,<br/>                        "Travel_Rarely": 1,<br/>                        "Travel_Frequently": 2}</span><span id="a28f" class="mo mp it mk b gy nq mr l ms mt">df = df.replace({"Attrition":yes_no_to_0_1_dict})<br/>df = df.replace({"OverTime":yes_no_to_0_1_dict})<br/>df = df.replace({"BusinessTravel":business_travel_dict})</span></pre><p id="2b63" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2)“employee count”、“StandardHours”和“Over18”列是稳定的(即列中有一个唯一值)，我们可以简单地删除它们，因为它们不会给模型带来任何有用的信息。</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="b513" class="mo mp it mk b gy mq mr l ms mt">df.columns[df.nunique()==1]</span><span id="4747" class="mo mp it mk b gy nq mr l ms mt"><strong class="mk iu">Index(['EmployeeCount', 'Over18', 'StandardHours'], dtype='object')</strong></span><span id="672a" class="mo mp it mk b gy nq mr l ms mt">df = df.drop(["EmployeeCount","StandardHours","Over18"], axis=1)</span></pre><p id="9178" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">机器学习算法无法处理分类特征，因此我们还需要借助<strong class="lb iu"> pd.get_dummies() </strong>指令将它们转换为数值向量:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="4f93" class="mo mp it mk b gy mq mr l ms mt">df = pd.get_dummies(df)</span><span id="9087" class="mo mp it mk b gy nq mr l ms mt"># This instruction can be used before and after the use of<br/># get_dummies to see changes on the dataset<br/>df.filter(like="Marital").sample(10, random_state=22)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/d258a4793b0668b06826c781b41c2745.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5KQiYjw5-ntH1TRgNhM8mQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">"<strong class="bd nu"> df.filter的结果(like = " Marital ")。sample(10，random_state=22) </strong>【前后】<strong class="bd nu">PD . get _ dummies()</strong></p></figure><p id="285e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数员工会在雇主那里呆一段时间，辞职率很低，但结果是，在收集减员数据时，你会比离职者获得更多关于员工的信息…</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="efaa" class="mo mp it mk b gy mq mr l ms mt">df["Attrition"].value_counts()</span><span id="9ce3" class="mo mp it mk b gy nq mr l ms mt">Attrition<br/>0    1233<br/>1     237<br/>Name: Attrition, dtype: int64</span></pre><p id="1bb9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">只有16%的数据集对应于已经离开公司的员工，这显然是一种“不平衡”的情况。为什么这是一个问题？</p><blockquote class="nv"><p id="a6d7" class="nw nx it bd ny nz oa ob oc od oe lu dk translated">这里的主要风险是，算法更有可能推断出从多数类继承的模式，而感兴趣的类通常是较小的一个(例如:癌症诊断、垃圾邮件或欺诈检测、员工流失等。).</p></blockquote><p id="12d5" class="pw-post-body-paragraph kz la it lb b lc of ju le lf og jx lh li oh lk ll lm oi lo lp lq oj ls lt lu im bi translated">分类器的默认优化度量通常默认设置为“<strong class="lb iu">准确性</strong>”(=正确预测/总预测)，但是，对于不平衡的数据集，无用的模型仍然可以实现非常高的准确率。</p><p id="d32c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，让我们考虑一个用不平衡数据集(10 000封邮件中的100封垃圾邮件)训练的垃圾邮件检测系统。如果该模型试图最大限度地提高其准确性，它最终可以预测所有的电子邮件为“非垃圾邮件”，这将导致99%的准确性…但您将无法检测到任何垃圾邮件！</p><p id="d557" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对于此用例，建议考虑的优化指标是“召回”,因为它将评估对人群中实际上已经辞职(真阳性)的人的检测:</p><blockquote class="nv"><p id="9675" class="nw nx it bd ny nz oa ob oc od oe lu dk translated">回忆=真阳性/(真阳性+假阴性)</p></blockquote><h1 id="b724" class="mu mp it bd mv mw mx my mz na nb nc nd jz ok ka nf kc ol kd nh kf om kg nj nk bi translated">模型培训—第一轮</h1><p id="4d60" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">创建我们的训练和测试数据集后:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="d5a4" class="mo mp it mk b gy mq mr l ms mt">X = df.drop("Attrition", axis=1)<br/>y = df["Attrition"]</span><span id="5a63" class="mo mp it mk b gy nq mr l ms mt">X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22)</span></pre><p id="431e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们训练我们的模型，而没有关于不平衡情况的任何特定预防措施:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="8ebf" class="mo mp it mk b gy mq mr l ms mt">model = CatBoostClassifier(iterations=500,<br/>                           verbose=100,<br/>                           eval_metric="Recall")</span><span id="611f" class="mo mp it mk b gy nq mr l ms mt">model.fit(X_train, y_train)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/e7ebc48e1bc52e8d003a69dc137fa7a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MlVoTP-Ixiv-Y14TUidZFQ.png"/></div></div></figure><p id="33bb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们显示培训和测试阶段的困惑矩阵:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="oo op l"/></div></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oq"><img src="../Images/354643253289afd78d523d1abcb89798.png" data-original-src="https://miro.medium.com/v2/resize:fit:1042/format:webp/1*s81s1c1z4CjJd54kqzDUzg.png"/></div></figure><p id="76bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们可以观察到召回率的真正下降，在训练和测试阶段之间从90%下降到19%!</p><h1 id="8844" class="mu mp it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">模型训练—第二轮(使用班级权重)</h1><p id="b5c9" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">向模型“教导”它需要更加关注少数群体的一种方式是引入“类权重”。</p><p id="fb9b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">由于这种方法，当模型未能检测到真正的肯定(离开者)时，我们可以给模型分配更强的惩罚。因此，我们指定1:5的比率，这意味着错误的辞职检测惩罚将比错误的员工检测惩罚重5倍:</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="f530" class="mo mp it mk b gy mq mr l ms mt">class_weights = dict({0:1, 1:5})</span><span id="f339" class="mo mp it mk b gy nq mr l ms mt">model = CatBoostClassifier(iterations=500,<br/>                           verbose=100,<br/>                           eval_metric="Recall",<br/>                           class_weights=class_weights)</span><span id="4e19" class="mo mp it mk b gy nq mr l ms mt">model.fit(X_train,y_train);</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi or"><img src="../Images/d8d893018cbbd24c47178b966546e727.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PELVZMQ2lGnB1SFyy6kb8w.png"/></div></div></figure><p id="ebba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再次使用混淆矩阵，我们可以看到模型预测的真正改进，因为测试数据集上的召回分数从19%增加到39%，而准确性保持稳定:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/bad3208acc85437b8d8a73709d9315a3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*ebJhAQzT5B26ag9hZpN4zA.png"/></div></figure><h1 id="d561" class="mu mp it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">模型训练—第3轮(使用欠采样)</h1><p id="0c20" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">另外两种方法可以完成类权重的使用:</p><p id="7d1c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1/过采样少数类</strong></p><p id="e242" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">第一种方法依赖于诸如SMOT(合成少数过采样技术)之类的技术，其中基于现有的少数类生成新数据。</p><p id="6370" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，在一个非常简化和“一维”的方式，SMOT创造了新的个人，把他们放在少数阶级点之间的“连接线”上。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/58f031120e6bf8a4c510183a371d5ae8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iqgR1kgdb7VJnfXrOPT2gQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SMOT方法:初始不平衡人口</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/36ebda8d3c632140223f64166c82d9f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QgZCn-yr8oIEzlpgiZShUA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">SMOT方法:新生成数据的表示</p></figure><p id="4423" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2/欠采样多数类</strong></p><p id="1189" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设许多员工都有相同的个人资料(例如:已婚男性，在会计部门工作20年以上，辞职率极低)。减少他们代表的数量来帮助模型理解辞职的真正影响参数是否有意思？当然！这正是欠采样技术所能提供的。</p><p id="c7be" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本例中，我们将使用“ClusterCentroids”方法，该方法将:</p><p id="ce12" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">1 -在多数类中创建聚类，其中个体具有相似或相近的属性</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/d03c60ae8807365773393efb55a9a0b0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fpj6sHghXPP7XbGCdckeDg.png"/></div></div></figure><p id="c84d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2 -用相应的质心替换每个聚类的个体。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ot"><img src="../Images/b2c32cdceca37d96abb72b19de1a0a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l8EdF5myj8x-FJj-QXK_Vg.png"/></div></div></figure><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="c1e4" class="mo mp it mk b gy mq mr l ms mt">cc = ClusterCentroids()</span><span id="88bb" class="mo mp it mk b gy nq mr l ms mt">X_cc, y_cc = cc.fit_resample(X, y)</span><span id="e7eb" class="mo mp it mk b gy nq mr l ms mt">X_train, X_test, y_train, y_test = train_test_split(X_cc, y_cc)</span></pre><p id="a025" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">再次使用混淆矩阵，我们可以观察到训练和测试阶段的召回率现在都是100%,这意味着在多数类中有许多具有相同特征的个体，现在被他们的质心所代替:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ou"><img src="../Images/d550d6937d9ef51ad107e48ef50725d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*EzHXU2aHUCIQb_I783-kcA.png"/></div></figure><p id="5720" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="ov">注意:该模型的“卓越”表现是由于我们正在处理合成数据，这些数据比真实数据随机性更小。</em></p><h1 id="8da6" class="mu mp it bd mv mw mx my mz na nb nc nd jz ne ka nf kc ng kd nh kf ni kg nj nk bi translated">用SHAP解释预测</h1><p id="04ed" class="pw-post-body-paragraph kz la it lb b lc nl ju le lf nm jx lh li nn lk ll lm no lo lp lq np ls lt lu im bi translated">现在我们有了一个关于真阳性检测的健壮模型，从人力资源的角度来看，理解为什么模型认为一个雇员有很大的可能性辞职或不辞职将是有趣的。</p><p id="8bb5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">定型模型上的“feature_importances_”属性是在宏观级别上了解哪些参数对预测起着重要作用的最直接的方法。</p><p id="1778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如<a class="ae ky" href="https://scikit-learn.org/stable/index.html" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu"> Scikit学习文档</strong> </a>所述:“一个特性的重要性被计算为该特性所带来的标准的(标准化)总缩减。这也被称为基尼系数。”</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="fe2c" class="mo mp it mk b gy mq mr l ms mt">feat_imp = pd.DataFrame(model.feature_importances_, index=X.columns, columns=["Importance"])</span><span id="cbad" class="mo mp it mk b gy nq mr l ms mt">feat_imp.sort_values(by="Importance", ascending=False).head(15)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ow"><img src="../Images/5e07c31005107921394f950550f0d3e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1164/format:webp/1*KSN_s8-2LySuOtk0RnsujQ.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型的15个mot影响参数</p></figure><p id="c64f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，它并没有指出每个参数对估计概率有正面还是负面的影响…这种影响也可能因每个样本的特征而异。</p><p id="1c2b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这就是最初创作于2017年的SHAP(SHapley Additive explaints)进入游戏的地方！</p><p id="f9cc" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">SHAP已经被设计，使用博弈论，以确定什么是模型中每个功能的边际贡献。如果您想进一步研究其计算机制，<a class="ae ky" rel="noopener" target="_blank" href="/search?q=SHAP">快速搜索数据科学</a>将回答您的所有问题。</p><p id="dc29" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">他们在使用SHAP时有许多好处，这里举几个:</p><p id="bdf7" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 1/你可以为每一个人找出在预测中起最重要作用的参数:</strong></p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="9be3" class="mo mp it mk b gy mq mr l ms mt"># Overall calculation of the SHAP model and values<br/>shap_explainer = shap.TreeExplainer(model)<br/>shap_values = shap_explainer.shap_values(X)</span><span id="b5ad" class="mo mp it mk b gy nq mr l ms mt">#<br/>Employee_ID = 1</span><span id="7c0e" class="mo mp it mk b gy nq mr l ms mt">shap.initjs()<br/>index_choice = df.index.get_loc(Employee_ID)<br/>shap.force_plot(shap_explainer.expected_value, shap_values[index_choice], X.iloc[index_choice])</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ox"><img src="../Images/705cdd14f26ceea870255abbc971f7fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lmAMVPIlfWgHUHJbZHcVUw.png"/></div></div></figure><p id="590d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上图中显示的重要信息有:</p><ul class=""><li id="533f" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">基值(3.362) </strong>代表员工辞职的平均概率。这是模型中所有参数的平均贡献。我们可以把它当作一个基线。</li><li id="d573" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">个体值(5.31) </strong>代表员工#1离开公司的概率，高于基线(又名“基础值”)。</li><li id="4bd9" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">红色参数</strong>显示哪些特征使员工更有可能离职:没有股票期权计划、定期加班、单身等。参数离单个值越近，它们在预测中的作用就越大(图表上每个参数的宽度也提供了这种“重要性”信息)。</li><li id="8480" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated"><strong class="lb iu">蓝色参数</strong>解释了她档案中的哪些元素降低了辞职的可能性:在当前职位上4年，与同一位经理共事5年，等等。</li></ul><p id="6757" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们看看员工2。由于高绩效评级、股票期权计划以及在同一位经理手下工作了7年，他的辞职概率“低于平均水平”(<strong class="lb iu"> 3.10 </strong>)。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oy"><img src="../Images/1ea761a91320310a23870d5f97acbd36.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kHYZqT55I-4AS1gxtK7gGA.png"/></div></div></figure><p id="a083" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 2/您可以显示整个群体</strong>(按个人相似度、辞职概率或原始排序排序)</p><pre class="kj kk kl km gt mj mk ml mm aw mn bi"><span id="e890" class="mo mp it mk b gy mq mr l ms mt">shap.initjs()<br/>shap.force_plot(shap_explainer.expected_value, shap_values, X)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oz"><img src="../Images/cbbef3bdb232b1c86bb148545f482eff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*17Vs1WeTR-rx-MTXLee5xA.gif"/></div></div></figure><p id="0524" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 3/你可以专注于某个具体特征的影响</strong>。下面的图表显示，年轻确实增加了辞职的可能性，直到一个人到了40岁，年龄开始发挥相反的作用。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pa"><img src="../Images/ae9b94e407a30c3b32b6779d6d4393e2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3bK0-0_n6ZfaduecQAMNSQ.png"/></div></div></figure><p id="76db" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu"> 4/并且明显地比较所有参数的各自贡献:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pb"><img src="../Images/289fdbe313b764aad7005e9037d2315b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T_ANGgx1SC2IHdv43QGrIg.png"/></div></div></figure><p id="e05f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在我们结束这篇文章之前，有一些评论:</p><ul class=""><li id="fb9e" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">像往常一样，模型的稳健性将高度依赖于输入数据的质量。掌握相关的、最新的、有背景的员工信息将有助于你更好地理解辞职因素。</li><li id="9a35" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">第3轮中的完美回忆分数是由于员工的档案是通过公式和算法创建的，这使得他们很容易预测另一种算法！即使我们可以确定员工离职的趋势，这仍然是每个人的复杂决策过程，可能没有数据集可以完全捕捉到！</li></ul><p id="cf5a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><strong class="lb iu">那都是乡亲们！😀</strong></p><p id="c6e3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">使用过的完整笔记本储存在<a class="ae ky" href="https://colab.research.google.com/drive/1cSDBBSctTHJ7bO-33JfnmfnOZaVBQkpD?usp=sharing" rel="noopener ugc nofollow" target="_blank">这里</a>的Google Colab/Drive上。</p><div class="pc pd gp gr pe pf"><a href="https://pl-bescond.medium.com/pierre-louis-besconds-articles-on-medium-f6632a6895ad" rel="noopener follow" target="_blank"><div class="pg ab fo"><div class="ph ab pi cl cj pj"><h2 class="bd iu gy z fp pk fr fs pl fu fw is bi translated">皮埃尔-路易·贝斯康德关于媒介的文章</h2><div class="pm l"><h3 class="bd b gy z fp pk fr fs pl fu fw dk translated">数据科学、机器学习和创新</h3></div><div class="pn l"><p class="bd b dl z fp pk fr fs pl fu fw dk translated">pl-bescond.medium.com</p></div></div><div class="po l"><div class="pp l pq pr ps po pt ks pf"/></div></div></a></div></div></div>    
</body>
</html>