<html>
<head>
<title>A Parallel Implementation of Bayesian Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">贝叶斯优化的并行实现</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-parallel-implementation-of-bayesian-optimization-2ffcdb2733a2?source=collection_archive---------20-----------------------#2020-09-20">https://towardsdatascience.com/a-parallel-implementation-of-bayesian-optimization-2ffcdb2733a2?source=collection_archive---------20-----------------------#2020-09-20</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="67cb" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">介绍一种适用于昂贵、不连续或不确定函数的并行优化方法。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4a7819275a26bcfec1317966979cc6fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VpsVrPH6oE6S3qo3rAbyVg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><p id="cecd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">“优化”的概念是数据科学的核心。我们通过优化神经网络中的权重来最小化损失。我们优化梯度增强树中的超参数，以找到最佳偏差-方差权衡。我们使用A-B测试来优化我们网站上的行为。无论我们的功能是神经网络、消费者行为，还是更险恶的东西，我们都有想要优化的东西。</p><p id="0e87" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有时，我们试图优化的功能是<em class="lu">昂贵的</em>，我们希望以尽可能少的步骤到达我们的目的地。有时我们希望确信我们找到了可能的最佳解决方案，有时我们的函数没有易处理的梯度，所以没有好的箭头来给我们指出正确的方向。通常，我们的函数有随机元素，所以我们真的试图优化<em class="lu"> f(x) = y + e，</em>其中<em class="lu"> e </em>是一些随机误差元素。<em class="lu"> </em>贝叶斯优化是一种函数优化器(maximizer)，在这些条件下蓬勃发展。</p><h1 id="a15b" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">目录</h1><ol class=""><li id="3ec6" class="mn mo it la b lb mp le mq lh mr ll ms lp mt lt mu mv mw mx bi translated">什么是贝叶斯优化</li><li id="3ebc" class="mn mo it la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">从头开始实施</li><li id="461f" class="mn mo it la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">并行实施</li><li id="24c1" class="mn mo it la b lb my le mz lh na ll nb lp nc lt mu mv mw mx bi translated">最后的话</li></ol><h1 id="d703" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">什么是贝叶斯优化</h1><p id="b6a1" class="pw-post-body-paragraph ky kz it la b lb mp ju ld le mq jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">假设我们有一个函数<em class="lu"> f，</em>，我们想找到最大化(或最小化)<em class="lu"> f(x) </em>的<em class="lu"> x </em>。我们有很多很多选择。然而，如果我们的函数符合目录上面的描述，我们肯定会考虑贝叶斯优化。</p><p id="3966" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">有几种不同的方法来执行贝叶斯优化。所有这些都涉及到创建一个关于某些事物如何分布的假设，基于这个假设做出一个决定，然后更新这个假设。</p><p id="d813" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">本文中的方法使用高斯过程来创建关于<em class="lu"> f(x) </em>如何分布的假设。这些过程可以被认为是函数的分布——从高斯<em class="lu">分布</em>中抽取随机样本会产生一个数字，从高斯<em class="lu">过程</em>中抽取随机样本会产生一个函数。如果你不熟悉高斯过程，这有点难以想象。我推荐<a class="ae ng" href="https://www.youtube.com/watch?v=92-98SYOdlY" rel="noopener ugc nofollow" target="_blank">这个视频</a>，是它让我对这个概念产生了兴趣。</p><p id="4e14" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">算法本身可以总结如下:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/054f42ac4482258aa393fbf2f8552482.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*X9qN6JLhOADuo7b0BE_Lww.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><h1 id="5287" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">从头开始实施</h1><p id="b1d2" class="pw-post-body-paragraph ky kz it la b lb mp ju ld le mq jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">在这里，我们不使用软件包，只进行一次贝叶斯优化迭代。这个过程非常简单。首先，我们定义一个玩具函数<em class="lu"> func </em>我们想要最大化，然后我们采样它4次:</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="a2d8" class="nn lw it nj b gy no np l nq nr"># Function to optimize<br/>func &lt;- function(input) {<br/>  dnorm(input,15,5) + dnorm(input,30,4) + dnorm(input,40,5)<br/>}</span><span id="64e2" class="nn lw it nj b gy ns np l nq nr"># Sample the function 4 times<br/>func_results &lt;- data.frame(input = c(5,18,25,44))<br/>func_results$output &lt;- func(func_results$input)</span><span id="e0ec" class="nn lw it nj b gy ns np l nq nr"># Plot<br/>library(ggplot2)<br/>p &lt;- ggplot(data = data.frame(input=c(0,50)),aes(input)) +<br/>  stat_function(fun=func,size=1,alpha=0.25) +<br/>  geom_point(data=func_results,aes(x=input,y=output),size=2) +<br/>  ylab("output") +<br/>  ylim(c(-0.05,0.2))<br/>p + ggtitle("Our Function and Attempts")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/0cd26112ac8148068853aefd8dd6da34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZOqvUkI_1KrglST5_U4qSw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><p id="5592" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们假装不知道真正的函数，所以实际上我们看到的只是我们采样的4个点。为了保持这个演练的趣味性，我们在选择初始点时做了一件很糟糕的工作。让我们用高斯过程来拟合这4个点，以定义我们对每个输入的输出分布的假设。</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="9103" class="nn lw it nj b gy no np l nq nr">library(DiceKriging)<br/>set.seed(1991)<br/>gp &lt;- km(<br/>    design = data.frame(input=func_results$input)<br/>  , response = func_results$output<br/>  , scaling = TRUE<br/>)</span></pre><p id="934e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们看看采样点旁边的高斯过程和真实函数值:</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="1f6a" class="nn lw it nj b gy no np l nq nr">predGP &lt;- function(x,grab) {<br/>  predict(gp,data.frame(input=x),type = "UK")[[grab]]<br/>}</span><span id="74d2" class="nn lw it nj b gy ns np l nq nr">a=1<br/>cl = "purple"<br/>plotGP &lt;- function(grab,cl,a) {<br/>  stat_function(<br/>    fun=predGP,args=list(grab=grab),color=cl,alpha=a,n=1000<br/>  )<br/>}<br/>p + ggtitle("Gaussian Process Results") +<br/>  plotGP("mean",cl,a) +<br/>  plotGP("lower95",cl,a) +<br/>  plotGP("upper95",cl,a)</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/3059ace5f3f187150db3319de9859dd8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yZvz0EhzBjGNOCL5TlSZVg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><p id="b8fb" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">高斯过程允许我们为每个输入定义输出<em class="lu">的正态分布。在上图中，紫色线条显示的是高斯过程。中间的线是平均值，上面/下面的线是该输入的正态分布的第95个百分位数。因此，举例来说，如果我们想知道如何假设输出在输入= 30时分布，我们可以这样做:</em></p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="05c2" class="nn lw it nj b gy no np l nq nr">predict(gp,data.frame(input=30),type="UK")[c("mean","sd")]</span><span id="3b9d" class="nn lw it nj b gy ns np l nq nr">$mean<br/>[1] 0.05580301<br/><br/>$sd<br/>[1] 0.007755026</span></pre><p id="a826" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这说明我们假设，在输入= 30时，我们的输出服从正态分布，均值= 0.0558，标准差= 0.0078。</p><p id="060d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">既然我们已经定义了关于输出分布的假设，我们需要确定下一步在哪里对函数进行采样。要做到这一点，我们需要定义一个输入的“承诺”程度。我们通过定义一个获取函数来做到这一点。有几种可供选择:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nt"><img src="../Images/58fa82e30cc7e162ef08b4949861e3f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/1*Ir_msGm7LzyhCrAoELdY9w.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><p id="f608" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中，置信上限是最容易实现的，因此让我们定义该函数并将其绘制在图表上:</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="5a23" class="nn lw it nj b gy no np l nq nr">ucb &lt;- function(x,kappa=3) {<br/>  gpMean &lt;- predGP(x,grab="mean")<br/>  gpSD &lt;- predGP(x,grab="sd")<br/>  return(gpMean + kappa * gpSD)<br/>}</span><span id="0abb" class="nn lw it nj b gy ns np l nq nr">a=0.25<br/>p + ggtitle("Upper Confidence Bound") +<br/>  plotGP("mean",cl,a) +<br/>  plotGP("lower95",cl,a) +<br/>  plotGP("upper95",cl,a) +<br/>  stat_function(fun=ucb,color="blue")</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/def9fb48ce5fd71ca00f477ad0eac3f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uI7ZaAOhTgJGWOLtNWh-lQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><p id="6f27" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们可以看到，我们的置信上限在10到15之间的某处达到最大值(绿色菱形),所以让我们找到具体的点，对其进行采样，并更新我们的GP:</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="ccb9" class="nn lw it nj b gy no np l nq nr"># Find exact input that maximizes ucb<br/>acqMax &lt;- optim(<br/>    par = 12<br/>  , fn = ucb<br/>  , method = “L-BFGS-B”<br/>  , control = list(fnscale = -1)<br/>  , lower = 10<br/>  , upper = 20<br/>)$par</span><span id="e82d" class="nn lw it nj b gy ns np l nq nr"># Run our function as this spot<br/>func_results &lt;- rbind(<br/>    func_results<br/>  , data.frame(input = acqMax,output = func(acqMax))<br/>)</span></pre><p id="3dad" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们刚刚完成了贝叶斯优化的一次迭代！如果我们继续运行更多，我们会看到我们的图表演变:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/4a7819275a26bcfec1317966979cc6fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*VpsVrPH6oE6S3qo3rAbyVg.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><h1 id="ce22" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">并行实施</h1><p id="b760" class="pw-post-body-paragraph ky kz it la b lb mp ju ld le mq jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">我们不会从零开始实现这一部分。相反，我们将使用ParBayesianOptimization R包来完成繁重的工作。这个软件包允许我们一次对多个有希望的点进行采样。如果只有1个有希望的点，它会对周围区域进行多次采样。因此，在我们的第一个例子中，我们将对采集函数的所有5个局部最大值进行采样:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/dd7866465d9da0c249b73c03800c183e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*z1qAVXqA0kHRNw6hLzwSfw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者上传的图片</p></figure><p id="64a9" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">让我们让它运行起来，看看会有什么结果。我们用上述4个相同的点初始化流程，然后用5个点运行1个优化步骤:</p><pre class="kj kk kl km gt ni nj nk nl aw nm bi"><span id="ee4e" class="nn lw it nj b gy no np l nq nr">library(ParBayesianOptimization)<br/>library(doParallel)</span><span id="795c" class="nn lw it nj b gy ns np l nq nr"># Setup parallel cluster<br/>cl &lt;- makeCluster(5)<br/>registerDoParallel(cl)<br/>clusterExport(cl,c('func'))</span><span id="18fc" class="nn lw it nj b gy ns np l nq nr"># bayesOpt requires the function to return a list with Score<br/># as the metric to maximize. You can return other fields, too.<br/>scoringFunc &lt;- function(input) return(list(Score = func(input)))</span><span id="c677" class="nn lw it nj b gy ns np l nq nr"># Initialize and run 1 optimization step at 5 points<br/>optObj &lt;- bayesOpt(<br/>  FUN = scoringFunc<br/>  , bounds = list(input=c(0,50))<br/>  , initGrid = list(input=c(5,18,25,44))<br/>  , iters.n = 5<br/>  , iters.k = 5<br/>  , acqThresh = 0<br/>  , parallel = TRUE<br/>)<br/>stopCluster(cl)<br/>registerDoSEQ()</span><span id="74cf" class="nn lw it nj b gy ns np l nq nr"># Print the input and score of the first Epoch<br/>optObj$scoreSummary[,c("Epoch","input","Score","gpUtility")]</span><span id="13a5" class="nn lw it nj b gy ns np l nq nr"> Epoch    input        Score gpUtility<br/>     0  5.00000 0.0107981936        NA<br/>     0 18.00000 0.0677578712        NA<br/>     0 25.00000 0.0573468343        NA<br/>     0 44.00000 0.0581564852        NA<br/>     1 35.59468 0.0916401614 0.6558418<br/>     1 50.00000 0.0107985650 0.6326077<br/>     1 13.74720 0.0773487879 0.5417429<br/>     1 21.13259 0.0462167925 0.4734561<br/>     1  0.00000 0.0008863697 0.1961284</span></pre><p id="24b7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们的分数摘要显示，bayesOpt运行了我们的4个初始点(Epoch = 0)，然后运行了1个优化步骤(Epoch = 1)，其中它对采集函数的所有5个局部最优值进行了采样。如果我们运行更多的迭代，我们将继续一次采样5个点。如果我们的函数最大化实际上是昂贵的，这将允许我们更快地找到全局最优。</p><p id="5ea4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">bayesOpt中的acqThresh参数对于采样过程至关重要。该参数代表采集函数全局最优值的最小百分比，局部最优值必须达到该百分比才能进行采样。例如，如果acqThresh=0.5，那么每个局部最优值(在我们的例子中是置信上限)必须至少是全局最优值的50%，否则将被忽略。我们设置acqThresh=0，这样所有的局部优化都会被采样。</p><p id="fe00" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">请注意上面的gpUtility字段。这是采集函数在每个采样点的缩放值(在我们的例子中是置信上限)。如果您注意到这个值在多个时期内收敛到0，那么高斯过程的观点是没有多少有希望的点留下来探索。一个更彻底的，包具体的解释可以找到<a class="ae ng" href="https://github.com/AnotherSamWilson/ParBayesianOptimization#how-long-should-it-run-for" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h1 id="4ff3" class="lv lw it bd lx ly lz ma mb mc md me mf jz mg ka mh kc mi kd mj kf mk kg ml mm bi translated">最后的话</h1><p id="95a8" class="pw-post-body-paragraph ky kz it la b lb mp ju ld le mq jx lg lh nd lj lk ll ne ln lo lp nf lr ls lt im bi translated">贝叶斯优化是一个令人惊讶的利基场景工具。在现代数据科学中，它通常用于优化黑盒模型的超参数。然而，作为一个通用的函数优化器，它已经在许多不同的地方找到了用途。我个人倾向于用这种方法来调优我在R和Python中的超参数。</p></div></div>    
</body>
</html>