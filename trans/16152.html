<html>
<head>
<title>Step by Step: Twitter Sentiment Analysis in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">循序渐进:Python中的Twitter情感分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/step-by-step-twitter-sentiment-analysis-in-python-d6f650ade58d?source=collection_archive---------0-----------------------#2020-11-07">https://towardsdatascience.com/step-by-step-twitter-sentiment-analysis-in-python-d6f650ade58d?source=collection_archive---------0-----------------------#2020-11-07</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><figure class="gl gn jr js jt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi jq"><img src="../Images/eb3a3a3388b32d5f4c9f82ec8e1c615e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jukRWo4nHDSHq3ttKb3mgg.jpeg"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">图片由<a class="ae kf" href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2990424" rel="noopener ugc nofollow" target="_blank">皮克斯拜</a>的Gerd Altmann 提供</p></figure><p id="ccea" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">通过分析人们分享的推文，了解人们对一个话题的看法不再困难。情感分析是NLP(自然语言处理)最流行的用例之一。</p><p id="cb77" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在这篇文章中，我将使用<strong class="ki iu">“Tweepy”，</strong>，这是一个易于使用的Python库，用于访问Twitter API。您需要有一个Twitter开发人员帐户和样本代码来做这个分析。你可以在我的<a class="ae kf" href="https://github.com/yalinyener/TwitterSentimentAnalysis" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu"> Github库中找到Jupyter笔记本代码。</strong>T9】</a></p><p id="f568" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章的目的是分析人们对伦敦第二次封锁的看法。</p><h1 id="e46b" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated"><strong class="ak">步骤1:安装并导入库</strong></h1><p id="f361" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">在分析之前，需要使用<strong class="ki iu"> <em class="mh">安装<strong class="ki iu"> textblob </strong>和<strong class="ki iu"> tweepy </strong>库！pip在你的Jupyter笔记本上安装</em> </strong>命令。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="5354" class="mr lf it mn b gy ms mt l mu mv"># Install Libraries<br/>!pip install textblob<br/>!pip install tweepy</span></pre><p id="8be1" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您需要导入将在这个情感分析项目中使用的库。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="a5dc" class="mr lf it mn b gy ms mt l mu mv"># Import Libraries</span><span id="7dd5" class="mr lf it mn b gy mw mt l mu mv">from textblob import TextBlob<br/>import sys<br/>import tweepy<br/>import matplotlib.pyplot as plt<br/>import pandas as pd<br/>import numpy as np<br/>import os<br/>import nltk<br/>import pycountry<br/>import re<br/>import string</span><span id="6130" class="mr lf it mn b gy mw mt l mu mv">from wordcloud import WordCloud, STOPWORDS<br/>from PIL import Image<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer<br/>from langdetect import detect<br/>from nltk.stem import SnowballStemmer<br/>from nltk.sentiment.vader import SentimentIntensityAnalyzer<br/>from sklearn.feature_extraction.text import CountVectorizer</span></pre><p id="1584" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">Tweepy支持OAuth 1a(应用程序用户)和OAuth 2(仅应用程序)身份验证。身份验证由tweepy处理。AuthHandler类。</p><p id="5151" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">OAuth 2是一种身份验证方法，其中应用程序在没有用户上下文的情况下发出API请求。如果您只需要对公共信息进行只读访问，请使用此方法。</p><p id="112d" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您首先注册我们的客户端应用程序，并获得一个消费者密钥和秘密。然后创建一个AppAuthHandler实例，传入我们的消费者密钥和秘密。</p><p id="c685" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">认证之前，你需要有<strong class="ki iu"> Twitter开发者账号。</strong>如果没有，可以通过使用此<a class="ae kf" href="https://developer.twitter.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="ki iu">链接</strong> </a>进行申请。获得Twitter开发者账户通常需要一两天，有时甚至更长时间，你的申请才会被Twitter审核。</p><h1 id="1375" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">步骤Twitter API的认证</h1><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="7bb5" class="mr lf it mn b gy ms mt l mu mv"># Authentication<br/>consumerKey = “Type your consumer key here”<br/>consumerSecret = “Type your consumer secret here”<br/>accessToken = “Type your accedd token here”<br/>accessTokenSecret = “Type your access token secret here”</span><span id="85b3" class="mr lf it mn b gy mw mt l mu mv">auth = tweepy.OAuthHandler(consumerKey, consumerSecret)<br/>auth.set_access_token(accessToken, accessTokenSecret)<br/>api = tweepy.API(auth)</span></pre><p id="7b24" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在您认证之后，您需要使用tweepy获取文本，并使用Textblob从文本中计算出<strong class="ki iu">正</strong>、<strong class="ki iu">负</strong>、<strong class="ki iu">中性</strong>、<strong class="ki iu">极性</strong>和<strong class="ki iu">复合</strong>参数。</p><h1 id="4015" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">第三步:获取带有关键词或标签的推文</h1><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="d629" class="mr lf it mn b gy ms mt l mu mv">#Sentiment Analysis</span><span id="663a" class="mr lf it mn b gy mw mt l mu mv">def percentage(part,whole):<br/> return 100 * float(part)/float(whole)</span><span id="8e6e" class="mr lf it mn b gy mw mt l mu mv">keyword = input(“Please enter keyword or hashtag to search: “)<br/>noOfTweet = int(input (“Please enter how many tweets to analyze: “))</span><span id="223e" class="mr lf it mn b gy mw mt l mu mv">tweets = tweepy.Cursor(api.search, q=keyword).items(noOfTweet)<br/>positive = 0<br/>negative = 0<br/>neutral = 0<br/>polarity = 0<br/>tweet_list = []<br/>neutral_list = []<br/>negative_list = []<br/>positive_list = []</span><span id="d257" class="mr lf it mn b gy mw mt l mu mv">for tweet in tweets:<br/> <br/> #print(tweet.text)<br/> tweet_list.append(tweet.text)<br/> analysis = TextBlob(tweet.text)<br/> score = SentimentIntensityAnalyzer().polarity_scores(tweet.text)<br/> neg = score[‘neg’]<br/> neu = score[‘neu’]<br/> pos = score[‘pos’]<br/> comp = score[‘compound’]<br/> polarity += analysis.sentiment.polarity<br/> <br/> if neg &gt; pos:<br/> negative_list.append(tweet.text)<br/> negative += 1</span><span id="6fa0" class="mr lf it mn b gy mw mt l mu mv">elif pos &gt; neg:<br/> positive_list.append(tweet.text)<br/> positive += 1<br/> <br/> elif pos == neg:<br/> neutral_list.append(tweet.text)<br/> neutral += 1</span><span id="8deb" class="mr lf it mn b gy mw mt l mu mv">positive = percentage(positive, noOfTweet)<br/>negative = percentage(negative, noOfTweet)<br/>neutral = percentage(neutral, noOfTweet)<br/>polarity = percentage(polarity, noOfTweet)<br/>positive = format(positive, ‘.1f’)<br/>negative = format(negative, ‘.1f’)<br/>neutral = format(neutral, ‘.1f’)</span></pre><p id="dcbf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这篇文章中的场景是这样的，用户应该键入关键字或标签(<strong class="ki iu"> lockdown2 london </strong>)并键入想要获取和分析多少条推文(<strong class="ki iu"> 2500 </strong>)。</p><p id="2635" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">因为有限制，tweets参数的数量很重要。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi mx"><img src="../Images/d7ebd58c90a1c16ffa62b201a73e417c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9R6Qq8YsIV5PI_yKcCMWWA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="efe9" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在收到2500条关于“<strong class="ki iu">封锁伦敦</strong>”的推文后，让我们看看有多少条推文表达了这种情绪</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="6251" class="mr lf it mn b gy ms mt l mu mv">#Number of Tweets (Total, Positive, Negative, Neutral)</span><span id="331e" class="mr lf it mn b gy mw mt l mu mv">tweet_list = pd.DataFrame(tweet_list)<br/>neutral_list = pd.DataFrame(neutral_list)<br/>negative_list = pd.DataFrame(negative_list)<br/>positive_list = pd.DataFrame(positive_list)<br/>print(“total number: “,len(tweet_list))<br/>print(“positive number: “,len(positive_list))<br/>print(“negative number: “, len(negative_list))<br/>print(“neutral number: “,len(neutral_list))</span></pre><p id="5dd6" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你会收到2500条推文。</p><ul class=""><li id="aebf" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated"><strong class="ki iu"> 1025条推文(41.0%) </strong>包含正面情绪</li><li id="7e22" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated"><strong class="ki iu"> 580条(23.2%) </strong>条推文中包含负面情绪</li><li id="a8bc" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated"><strong class="ki iu"> 895条(35.8%) </strong>条推文包含中性情绪</li></ul><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="163c" class="mr lf it mn b gy ms mt l mu mv">#Creating PieCart</span><span id="218b" class="mr lf it mn b gy mw mt l mu mv">labels = [‘Positive [‘+str(positive)+’%]’ , ‘Neutral [‘+str(neutral)+’%]’,’Negative [‘+str(negative)+’%]’]<br/>sizes = [positive, neutral, negative]<br/>colors = [‘yellowgreen’, ‘blue’,’red’]<br/>patches, texts = plt.pie(sizes,colors=colors, startangle=90)<br/>plt.style.use(‘default’)<br/>plt.legend(labels)<br/>plt.title(“Sentiment Analysis Result for keyword= “+keyword+”” )<br/>plt.axis(‘equal’)<br/>plt.show()</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nm"><img src="../Images/a6358f595071c6c72cd572d8daed7dad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gh4JR1HW5B2Q6nl8kQGIWg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="90c5" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们看看推文列表。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="7ed1" class="mr lf it mn b gy ms mt l mu mv">tweet_list</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/cc16d3ee28707b83cf68e5aa989940f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GRS7Nf0H7iY1tFf4qJA2bg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><h1 id="eca2" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">第四步:清理推文以分析情绪</h1><p id="92c8" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">当你查看tweet列表时，你可以看到一些重复的tweet，所以你需要使用<strong class="ki iu"> drop_duplicates </strong>函数删除重复的记录。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="75c3" class="mr lf it mn b gy ms mt l mu mv">tweet_list.drop_duplicates(inplace = True)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi no"><img src="../Images/8948337d5043901d8a4fcd01ec732997.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WaTDwGosa62cjdDiL6LOWw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="22a2" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们的新数据框有<strong class="ki iu"> 1281 </strong>条独特的推文。</p><p id="d742" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">首先，我创建一个新的数据框(tw_list)和一个新的特征(text)，然后使用lambda函数清洗文本，清洗RT、link、标点符号字符，最后转换成小写。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="e729" class="mr lf it mn b gy ms mt l mu mv">#Cleaning Text (RT, Punctuation etc)</span><span id="c0f1" class="mr lf it mn b gy mw mt l mu mv">#Creating new dataframe and new features<br/>tw_list = pd.DataFrame(tweet_list)<br/>tw_list[“text”] = tw_list[0]</span><span id="c77e" class="mr lf it mn b gy mw mt l mu mv">#Removing RT, Punctuation etc<br/>remove_rt = lambda x: re.sub(‘RT @\w+: ‘,” “,x)<br/>rt = lambda x: re.sub(“(@[A-Za-z0–9]+)|([⁰-9A-Za-z \t])|(\w+:\/\/\S+)”,” “,x)<br/>tw_list[“text”] = tw_list.text.map(remove_rt).map(rt)<br/>tw_list[“text”] = tw_list.text.str.lower()<br/>tw_list.head(10)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi np"><img src="../Images/230ef4d5c6db57401513d9016d6bfb9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b0ijNAgpFvm1MTXVYlbAJA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><h1 id="62a3" class="le lf it bd lg lh li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb bi translated">第五步:情感分析</h1><p id="ac3b" class="pw-post-body-paragraph kg kh it ki b kj mc kl km kn md kp kq kr me kt ku kv mf kx ky kz mg lb lc ld im bi translated">现在，我可以使用清理后的文本再次计算极性、主观性、情绪、负面、正面、中性和复合参数。对于所有计算的参数，我在数据框中创建新要素</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="a691" class="mr lf it mn b gy ms mt l mu mv">#Calculating Negative, Positive, Neutral and Compound values</span><span id="3d9d" class="mr lf it mn b gy mw mt l mu mv">tw_list[[‘polarity’, ‘subjectivity’]] = tw_list[‘text’].apply(lambda Text: pd.Series(TextBlob(Text).sentiment))<br/>for index, row in tw_list[‘text’].iteritems():<br/> score = SentimentIntensityAnalyzer().polarity_scores(row)<br/> neg = score[‘neg’]<br/> neu = score[‘neu’]<br/> pos = score[‘pos’]<br/> comp = score[‘compound’]<br/> if neg &gt; pos:<br/> tw_list.loc[index, ‘sentiment’] = “negative”<br/> elif pos &gt; neg:<br/> tw_list.loc[index, ‘sentiment’] = “positive”<br/> else:<br/> tw_list.loc[index, ‘sentiment’] = “neutral”<br/> tw_list.loc[index, ‘neg’] = neg<br/> tw_list.loc[index, ‘neu’] = neu<br/> tw_list.loc[index, ‘pos’] = pos<br/> tw_list.loc[index, ‘compound’] = comp</span><span id="f566" class="mr lf it mn b gy mw mt l mu mv">tw_list.head(10)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/2277b3a69d8eef75715d9624bac05653.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RwlJ1gXsrhE1uQ0-_xC4RA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="ddc8" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以根据情绪将数据框分为3组。对于这一个，创建3个新数据帧(tw_list_negative、tw_list_positive、tw_list_neutral)并从原始tw_list数据帧导入</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="6ff5" class="mr lf it mn b gy ms mt l mu mv">#Creating new data frames for all sentiments (positive, negative and neutral)</span><span id="a2c0" class="mr lf it mn b gy mw mt l mu mv">tw_list_negative = tw_list[tw_list[“sentiment”]==”negative”]<br/>tw_list_positive = tw_list[tw_list[“sentiment”]==”positive”]<br/>tw_list_neutral = tw_list[tw_list[“sentiment”]==”neutral”]</span></pre><p id="58bd" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">让我们计算情感特征的值，并查看总百分比。</p><p id="db52" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">#单列中count _ values _的函数</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="340b" class="mr lf it mn b gy ms mt l mu mv">def count_values_in_column(data,feature):<br/> total=data.loc[:,feature].value_counts(dropna=False)<br/> percentage=round(data.loc[:,feature].value_counts(dropna=False,normalize=True)*100,2)<br/> return pd.concat([total,percentage],axis=1,keys=[‘Total’,’Percentage’])</span><span id="8617" class="mr lf it mn b gy mw mt l mu mv">#Count_values for sentiment<br/>count_values_in_column(tw_list,”sentiment”)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nq"><img src="../Images/f9a1ae413c41090c26efcf4f47884755.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*y20PZIbWcjqo8SoecZ7ZYg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="0790" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">你可以通过使用情绪推文的数量来创建一个图表。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="8f5c" class="mr lf it mn b gy ms mt l mu mv"># create data for Pie Chart<br/>pichart = count_values_in_column(tw_list,”sentiment”)<br/>names= pc.index<br/>size=pc[“Percentage”]<br/> <br/># Create a circle for the center of the plot<br/>my_circle=plt.Circle( (0,0), 0.7, color=’white’)<br/>plt.pie(size, labels=names, colors=[‘green’,’blue’,’red’])<br/>p=plt.gcf()<br/>p.gca().add_artist(my_circle)<br/>plt.show()</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nr"><img src="../Images/99aa565ff95c16b1b8e28a4035ec8711.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wIxHOtrCsO-qQKAl90kM1A.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="89cf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在你可以准备使用1281条推文创建worcloud，这样你就可以知道哪些词在这些推文中使用得最多。要创建worcloud，首先让我们定义下面的函数，这样你就可以再次使用wor cloud来处理所有的推文，正面推文，负面推文等等。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="ca1f" class="mr lf it mn b gy ms mt l mu mv">#Function to Create Wordcloud</span><span id="ce2f" class="mr lf it mn b gy mw mt l mu mv">def create_wordcloud(text):<br/> mask = np.array(Image.open(“cloud.png”))<br/> stopwords = set(STOPWORDS)<br/> wc = WordCloud(background_color=”white”,<br/> mask = mask,<br/> max_words=3000,<br/> stopwords=stopwords,<br/> repeat=True)<br/> wc.generate(str(text))<br/> wc.to_file(“wc.png”)<br/> print(“Word Cloud Saved Successfully”)<br/> path=”wc.png”<br/> display(Image.open(path))</span></pre><p id="d79f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">定义了这个函数后，你就可以查看所有推文的wordcloud了</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="6317" class="mr lf it mn b gy ms mt l mu mv">#Creating wordcloud for all tweets<br/>create_wordcloud(tw_list[“text”].values)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nn"><img src="../Images/13cb9ac8d34380d4e9c79f18ae92d0e8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jBHrWrKcMN_DhZiMPk3DIA.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="f95c" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">针对具有积极情绪的推文的词云；</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="889e" class="mr lf it mn b gy ms mt l mu mv">#Creating wordcloud for positive sentiment<br/>create_wordcloud(tw_list_positive[“text”].values)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ns"><img src="../Images/c8a6980a5967c9c3bc497fe64c21bd90.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GyEAZzW4i8o16vrWDz4xwQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="f43f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">针对带有负面情绪的推文的词云；</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="05f0" class="mr lf it mn b gy ms mt l mu mv">#Creating wordcloud for negative sentiment<br/>create_wordcloud(tw_list_negative[“text”].values)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nt"><img src="../Images/76045c92c75f636cb55f5f017bc0f04c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*v1hqtTKUH517n6O2pyfihQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="2ec3" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我们来计算一下推文长度和字数。因此，你可以看到基于不同情绪的推文中使用的单词和字符的密度。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="5251" class="mr lf it mn b gy ms mt l mu mv">#Calculating tweet’s lenght and word count<br/>tw_list[‘text_len’] = tw_list[‘text’].astype(str).apply(len)<br/>tw_list[‘text_word_count’] = tw_list[‘text’].apply(lambda x: len(str(x).split()))</span><span id="056b" class="mr lf it mn b gy mw mt l mu mv">round(pd.DataFrame(tw_list.groupby("sentiment").text_len.mean()),2)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nu"><img src="../Images/6d145ba6497a75a504b8fb10cb27d5d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QdlH_1FpId5KH-iCzUNALQ.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="76a2" class="mr lf it mn b gy ms mt l mu mv">round(pd.DataFrame(tw_list.groupby(“sentiment”).text_word_count.mean()),2)</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nv"><img src="../Images/5ac9f3f8c0b25dc82b0ed3e84c4840de.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*vw8QdxMxy8ynHt9RSTIR3w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="34cf" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应用计数矢量器可在生成矢量表示之前对文本数据进行预处理，使其成为高度灵活的文本特征表示模块。在计数矢量器之后，可以用两个或三个或者任何你想要的来分析单词。</p><p id="aa8a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应用词干分析器还可以提供单词的词根。所以你可以排除来自同一个词根的单词，比如；</p><ul class=""><li id="a5b5" class="my mz it ki b kj kk kn ko kr na kv nb kz nc ld nd ne nf ng bi translated">连接</li><li id="748c" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">关系</li><li id="aa25" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">连接的</li><li id="d58e" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">连接</li><li id="c636" class="my mz it ki b kj nh kn ni kr nj kv nk kz nl ld nd ne nf ng bi translated">连接</li></ul><p id="0d33" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">来源于<strong class="ki iu">“连接”。如果您应用词干分析器功能，您可以认为这些单词是相同的</strong></p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="aafc" class="mr lf it mn b gy ms mt l mu mv">#Removing Punctuation<br/>def remove_punct(text):<br/> text = “”.join([char for char in text if char not in string.punctuation])<br/> text = re.sub(‘[0–9]+’, ‘’, text)<br/> return text</span><span id="f896" class="mr lf it mn b gy mw mt l mu mv">tw_list[‘punct’] = tw_list[‘text’].apply(lambda x: remove_punct(x))</span><span id="261e" class="mr lf it mn b gy mw mt l mu mv">#Appliyng tokenization<br/>def tokenization(text):<br/>    text = re.split('\W+', text)<br/>    return text</span><span id="aa86" class="mr lf it mn b gy mw mt l mu mv">tw_list['tokenized'] = tw_list['punct'].apply(lambda x: tokenization(x.lower()))</span><span id="7e79" class="mr lf it mn b gy mw mt l mu mv">#Removing stopwords<br/>stopword = nltk.corpus.stopwords.words('english')<br/>def remove_stopwords(text):<br/>    text = [word for word in text if word not in stopword]<br/>    return text<br/>    <br/>tw_list['nonstop'] = tw_list['tokenized'].apply(lambda x: remove_stopwords(x))</span><span id="9d03" class="mr lf it mn b gy mw mt l mu mv">#Appliyng Stemmer<br/>ps = nltk.PorterStemmer()</span><span id="0cab" class="mr lf it mn b gy mw mt l mu mv">def stemming(text):<br/>    text = [ps.stem(word) for word in text]<br/>    return text</span><span id="2d47" class="mr lf it mn b gy mw mt l mu mv">tw_list['stemmed'] = tw_list['nonstop'].apply(lambda x: stemming(x))</span><span id="9c44" class="mr lf it mn b gy mw mt l mu mv">#Cleaning Text<br/>def clean_text(text):<br/>    text_lc = "".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation<br/>    text_rc = re.sub('[0-9]+', '', text_lc)<br/>    tokens = re.split('\W+', text_rc)    # tokenization<br/>    text = [ps.stem(word) for word in tokens if word not in stopword]  # remove stopwords and stemming<br/>    return text</span><span id="01cd" class="mr lf it mn b gy mw mt l mu mv">tw_list.head()</span></pre><p id="620f" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">应用countverctorizer后，两个结果显示所有1281条tweets有2966个独特的单词。</p><p id="8ef7" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">如果您看一下我们的数据框，您会看到一些新功能，如点状、标记化、不间断、词干化。</p><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nw"><img src="../Images/5baf21a2bf13ba90a9a6a1df94e486f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*o43y7u2IM0C2jDrOBwZw-w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="f846" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在，您可以应用coun矢量器将所有2966个唯一的单词视为一个新功能。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="2966" class="mr lf it mn b gy ms mt l mu mv">#Appliyng Countvectorizer<br/>countVectorizer = CountVectorizer(analyzer=clean_text) <br/>countVector = countVectorizer.fit_transform(tw_list[‘text’])<br/>print(‘{} Number of reviews has {} words’.format(countVector.shape[0], countVector.shape[1]))<br/>#print(countVectorizer.get_feature_names())</span><span id="9da7" class="mr lf it mn b gy mw mt l mu mv">1281 Number of reviews has 2966 words</span><span id="2302" class="mr lf it mn b gy mw mt l mu mv">count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())<br/>count_vect_df.head()</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nx"><img src="../Images/4a21e44c20d260e42421a67b58a6c693.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*O52OaSPrxDl9TUhLcv9lEg.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="2e25" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以按降序对值进行排序，以查看最常用的单词</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="2d5c" class="mr lf it mn b gy ms mt l mu mv"># Most Used Words<br/>count = pd.DataFrame(count_vect_df.sum())<br/>countdf = count.sort_values(0,ascending=False).head(20)<br/>countdf[1:11]</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi ny"><img src="../Images/86a37b98aefb9234a6d265f84a3093be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wnXWgca_C0gMjyAxfqUV8g.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="f774" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">建立n元模型有助于我们预测最有可能出现在这个序列之后的单词。首先让我们创建一个函数，然后构建n2_bigram，n3_trigram等。</p><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="ed7b" class="mr lf it mn b gy ms mt l mu mv">#Function to ngram<br/>def get_top_n_gram(corpus,ngram_range,n=None):<br/> vec = CountVectorizer(ngram_range=ngram_range,stop_words = ‘english’).fit(corpus)<br/> bag_of_words = vec.transform(corpus)<br/> sum_words = bag_of_words.sum(axis=0) <br/> words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]<br/> words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)<br/> return words_freq[:n]</span><span id="55a8" class="mr lf it mn b gy mw mt l mu mv">#n2_bigram<br/>n2_bigrams = get_top_n_gram(tw_list[‘text’],(2,2),20)</span><span id="5e65" class="mr lf it mn b gy mw mt l mu mv">n2_bigrams</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi nz"><img src="../Images/e7919735c54ab6cce4061452562e0e56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jPSRo4edE12o--kT3XXEpw.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><pre class="mi mj mk ml gt mm mn mo mp aw mq bi"><span id="15ca" class="mr lf it mn b gy ms mt l mu mv">#n3_trigram<br/>n3_trigrams = get_top_n_gram(tw_list[‘text’],(3,3),20)</span><span id="23b5" class="mr lf it mn b gy mw mt l mu mv">n3_trigrams</span></pre><figure class="mi mj mk ml gt ju gh gi paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="gh gi oa"><img src="../Images/22d66f5dce9542c80326fd910c824004.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B4hjKMFWeBVo0Tp19CXO5w.png"/></div></div><p class="kb kc gj gh gi kd ke bd b be z dk translated">作者图片</p></figure><p id="2aab" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">最后，你可以使用tweets来分析情绪，你可以意识到哪些词最常用，哪些词一起使用。</p><p id="bd7a" class="pw-post-body-paragraph kg kh it ki b kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">感谢你阅读我的帖子，希望你喜欢。如果您有任何问题或想要分享您的意见，请随时联系我。</p></div></div>    
</body>
</html>