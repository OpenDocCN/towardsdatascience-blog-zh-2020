<html>
<head>
<title>Creating VGG from Scratch using Tensorflow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用张量流从零开始创建VGG</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/creating-vgg-from-scratch-using-tensorflow-a998a5640155?source=collection_archive---------12-----------------------#2020-10-23">https://towardsdatascience.com/creating-vgg-from-scratch-using-tensorflow-a998a5640155?source=collection_archive---------12-----------------------#2020-10-23</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="a149" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">我们将看到如何使用Tensorflow 2.0从头开始实现VGG16</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/ba383fa64e0784a08b6b8a7267bffa64.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*GYvF1C_ky83_waulU5wnZg.png"/></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图一。VGG 16号建筑(来源:图片由作者创作)</p></figure><p id="79aa" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">LeNet-5是最古老的卷积神经网络架构之一，由Yann LeCun于1998年设计，用于识别手写数字。它使用5x5过滤器，平均池，没有填充。但按照现代标准，这是一个非常小的神经网络，只有6万个参数。如今，我们看到的网络有一千万到几十亿个参数。下一个革命性地使用卷积网络的大型卷积神经网络是AlexNet，它有大约6000万个参数。AlexNet第一层使用96个内核大小为11x11的滤镜，步长为4。下一层使用3x3滤镜，依此类推。此外，AlexNet使用最大池和填充，这在LeNet-5中没有使用。AlexNet与LeNet-5非常相似，但它要大得多。还有，AlexNet用的是ReLU激活功能，而LeNet-5主要用的是Sigmoid激活。这些网络的共同点是，随着我们深入网络，张量的大小不断减小，而通道的数量不断增加。此外，如今在创建神经网络架构时仍在使用的另一个趋势是使用卷积层(一层或多层),然后是一些池层，最后是一些完全连接的层。</p><p id="3f1e" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">下一个大的卷积神经网络是VGG网络。关于VGG，值得注意的是，作者没有使用这么多超参数，而是使用了一个更简单的网络，其中重点是使用具有小尺寸3×3滤波器的卷积层，步长为1，并使用“相同”填充，并使所有MaxPooling层2×2的步长为2。VGG大大简化了以前制作的神经网络结构。</p><p id="5c7c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><a class="ae lq" href="https://arxiv.org/abs/1409.1556" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1409.1556</a>VGG纸链接</p><p id="9fe6" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">使用Tensorflow的VGG 16架构和实现:</strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ls lt di lu bf lv"><div class="gh gi lr"><img src="../Images/490698f19b1d4286ad6b231d7449c5c1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NxaJlqa0nCuOAcGTuA0O2w.png"/></div></div><p class="kq kr gj gh gi ks kt bd b be z dk translated">图二。VGG建筑。用红色突出显示的VGG 16号(来源:图片来自原始论文)</p></figure><p id="adb0" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">图2显示了所有的VGG架构。VGG 16号的建筑用红色突出显示。图1给出了该架构的一个简单版本。</p><p id="59d2" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">VGG网络使用最大池和ReLU激活功能。所有隐藏层使用ReLU激活，最后一个密集层使用Softmax激活。MaxPooling是在步长为2的2x2像素窗口上执行的。</p><p id="9b02" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">VGG 16有5个卷积块和3个全连接层。每个块由2个或更多卷积层和一个最大池层组成。</p><p id="6132" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">算法:</strong></p><ol class=""><li id="5d82" class="lw lx it kw b kx ky la lb ld ly lh lz ll ma lp mb mc md me bi translated">导入所有必要的层</li><li id="8043" class="lw lx it kw b kx mf la mg ld mh lh mi ll mj lp mb mc md me bi translated">为卷积块编写代码</li><li id="e374" class="lw lx it kw b kx mf la mg ld mh lh mi ll mj lp mb mc md me bi translated">为密集层编写代码</li><li id="e1d4" class="lw lx it kw b kx mf la mg ld mh lh mi ll mj lp mb mc md me bi translated">建立模型</li></ol><p id="6f71" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">导入库:</strong></p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="5612" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># import necessary layers</em><br/><br/><strong class="ml iu">from</strong> <strong class="ml iu">tensorflow.keras.layers</strong> <strong class="ml iu">import</strong> Input, Conv2D<br/><strong class="ml iu">from</strong> <strong class="ml iu">tensorflow.keras.layers</strong> <strong class="ml iu">import</strong> MaxPool2D, Flatten, Dense<br/><strong class="ml iu">from</strong> <strong class="ml iu">tensorflow.keras</strong> <strong class="ml iu">import</strong> Model</span></pre><p id="fb9f" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">输入:</strong></p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="cef0" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># input</em>  </span><span id="5647" class="mp mq it ml b gy mw ms l mt mu">input = Input(shape =(224,224,3))</span></pre><p id="13e4" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输入是224x224 RGB图像，所以3个通道。</p><p id="1ede" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> Conv第一街区:</strong></p><p id="579c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它有两个Conv层，每个层有64个过滤器，后面是最大池。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ki"><img src="../Images/12e30ca2ee6d216a5a27137f4435e7c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:842/format:webp/1*05ni-vt0OCxveZE1cxj7bg.png"/></div></figure><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="3a61" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># 1st Conv Block</em><br/><br/>x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)<br/>x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span></pre><p id="6dd7" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> Conv第二街区:</strong></p><p id="ad53" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它有两个Conv层，128个过滤器，然后是最大池。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/556212aecb3d6709462d1939e0af43b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:822/format:webp/1*cUrxLpRjo-SbwfqngAJ2-g.png"/></div></figure><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="dc7d" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># 2nd Conv Block</em><br/><br/>x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span></pre><p id="0c6c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> Conv第三街区:</strong></p><p id="0034" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">它有三个Conv层，256个过滤器，然后是最大池。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi my"><img src="../Images/58142b6c914c4b8ff167b76b02bab99d.png" data-original-src="https://miro.medium.com/v2/resize:fit:820/format:webp/1*SWG4xWjZfkYakA_kv0AgDA.png"/></div></figure><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="15c5" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># 3rd Conv block</em>  </span><span id="1586" class="mp mq it ml b gy mw ms l mt mu">x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) <br/>x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) <br/>x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x) <br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span></pre><p id="6910" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu"> Conv第4和第5区块:</strong></p><p id="a56a" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">Conv区块4和5都有3个Conv层，512个过滤器，然后是最大池。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi mz"><img src="../Images/6d33265d36b4a06606f669a51ab9316a.png" data-original-src="https://miro.medium.com/v2/resize:fit:836/format:webp/1*meKIkDYBKDCOry_iqI16RA.png"/></div></figure><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="ec52" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># 4th Conv block</em><br/><br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)<br/><br/><em class="mv"># 5th Conv block</em><br/><br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span></pre><p id="eacd" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">密集层:</strong></p><p id="49f3" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">有3个完全连接的层，前两层具有4096个隐藏单元和ReLU激活，最后一个输出层具有1000个隐藏单元和Softmax激活。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi na"><img src="../Images/d1b43098e4a1a6c9108292477074ea5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:522/format:webp/1*zfm07YIDJ1Q7Koj7Cg5IZw.png"/></div></figure><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="3d3f" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># Fully connected layers</em>  </span><span id="a245" class="mp mq it ml b gy mw ms l mt mu">x = Flatten()(x) <br/>x = Dense(units = 4096, activation ='relu')(x) <br/>x = Dense(units = 4096, activation ='relu')(x) <br/>output = Dense(units = 1000, activation ='softmax')(x)</span></pre><p id="8293" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">创建模型:</strong></p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="a9e1" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># creating the model</em><br/><br/>model = Model (inputs=input, outputs =output)<br/>model.summary()</span></pre><p id="ba18" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/35bd95b6c8bab649a6c5fd96d6df2a14.png" data-original-src="https://miro.medium.com/v2/resize:fit:948/format:webp/1*XBCQmavIHCtWGFbjQJYjyg.png"/></div></figure><p id="53ab" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">绘制模型:</strong></p><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="f0ec" class="mp mq it ml b gy mr ms l mt mu"><em class="mv"># plotting the model</em><br/><br/><strong class="ml iu">from</strong> <strong class="ml iu">tensorflow.python.keras.utils.vis_utils</strong> <strong class="ml iu">import</strong> model_to_dot<br/><strong class="ml iu">from</strong> <strong class="ml iu">IPython.display</strong> <strong class="ml iu">import</strong> SVG<br/><strong class="ml iu">import</strong> <strong class="ml iu">pydot</strong><br/><strong class="ml iu">import</strong> <strong class="ml iu">graphviz</strong><br/><br/>SVG(model_to_dot(model, show_shapes=<strong class="ml iu">True</strong>, show_layer_names=<strong class="ml iu">True</strong>, rankdir='TB',expand_nested=<strong class="ml iu">False</strong>, dpi=60, subgraph=<strong class="ml iu">False</strong>).create(prog='dot',format='svg'))</span></pre><p id="3b34" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">输出片段:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nc"><img src="../Images/73d4007f4189cae63f267634a0e213bf.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/1*c0-2FfcYfrwsp8_8qJBysw.png"/></div></figure><h1 id="612e" class="nd mq it bd ne nf ng nh ni nj nk nl nm jz nn ka no kc np kd nq kf nr kg ns nt bi translated">用TensorFlow实现VGG 16的完整代码:</h1><pre class="kj kk kl km gt mk ml mm mn aw mo bi"><span id="0d45" class="mp mq it ml b gy mr ms l mt mu"><strong class="ml iu"><em class="mv"># import necessary layers</em>  </strong></span><span id="3578" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu">from</strong> <strong class="ml iu">tensorflow.keras.layers</strong> <strong class="ml iu">import</strong> Input, Conv2D <strong class="ml iu">from</strong> <strong class="ml iu">tensorflow.keras.layers</strong> <strong class="ml iu">import</strong> MaxPool2D, Flatten, Dense <strong class="ml iu">from</strong> <strong class="ml iu">tensorflow.keras</strong> <strong class="ml iu">import</strong> Model</span><span id="d012" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu"><em class="mv"># input</em></strong><br/><br/>input = Input(shape =(224,224,3))</span><span id="0cda" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu"><em class="mv"># 1st Conv Block</em></strong><br/><br/>x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(input)<br/>x = Conv2D (filters =64, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span><span id="12fe" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu"><em class="mv"># 2nd Conv Block</em></strong><br/><br/>x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =128, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span><span id="5615" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu"><em class="mv"># 3rd Conv block</em></strong><br/><br/>x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =256, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span><span id="3e8c" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu"><em class="mv"># 4th Conv block</em></strong><br/><br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)<br/><br/><strong class="ml iu"><em class="mv"># 5th Conv block</em></strong><br/><br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = Conv2D (filters =512, kernel_size =3, padding ='same', activation='relu')(x)<br/>x = MaxPool2D(pool_size =2, strides =2, padding ='same')(x)</span><span id="124c" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu"><em class="mv"># Fully connected layers</em></strong><br/><br/>x = Flatten()(x)<br/>x = Dense(units = 4096, activation ='relu')(x)<br/>x = Dense(units = 4096, activation ='relu')(x)<br/>output = Dense(units = 1000, activation ='softmax')(x)</span><span id="79dd" class="mp mq it ml b gy mw ms l mt mu"><strong class="ml iu"><em class="mv"># creating the model</em></strong><br/><br/>model = Model (inputs=input, outputs =output)<br/>model.summary()</span></pre><p id="fb31" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">结论:</strong></p><p id="5ce8" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">VGG网络是一个非常简单的卷积神经网络，由于其简单性，使用Tensorflow很容易实现。它只有Conv2D、MaxPooling和Dense图层。VGG 16共有1.38亿个可训练参数。</p><p id="8007" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated">VGG是CNN出版期间最深的模型架构，最多有19个重量层。它在ImageNet挑战中取得了最先进的性能，并表明更深的网络有利于更好的分类准确性。</p></div><div class="ab cl nu nv hx nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="im in io ip iq"><p id="614c" class="pw-post-body-paragraph ku kv it kw b kx ky ju kz la lb jx lc ld le lf lg lh li lj lk ll lm ln lo lp im bi translated"><strong class="kw iu">参考文献:</strong></p><ol class=""><li id="97be" class="lw lx it kw b kx ky la lb ld ly lh lz ll ma lp mb mc md me bi translated">卡伦·西蒙扬和安德鲁·齐泽曼，用于大规模图像识别的极深度卷积网络，<a class="ae lq" href="https://arxiv.org/abs/1409.1556v6" rel="noopener ugc nofollow" target="_blank">arXiv:1409.1556 V6</a>【cs .CV]，2015。</li></ol></div></div>    
</body>
</html>