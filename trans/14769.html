<html>
<head>
<title>Text Classification Using Naive Bayes: Theory &amp; A Working Example</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于朴素贝叶斯的文本分类:理论与实例</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a?source=collection_archive---------1-----------------------#2020-10-12">https://towardsdatascience.com/text-classification-using-naive-bayes-theory-a-working-example-2ef4b7eb7d5a?source=collection_archive---------1-----------------------#2020-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="873f" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="e955" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在本文中，我解释了朴素贝叶斯的工作原理，并一步步用Python实现了一个多类文本分类问题。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/060169a2229253c721e6e203193ee3d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XaMol4nW_Uyg3lehm2-3_w.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure><h2 id="c168" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">目录</h2><ol class=""><li id="3858" class="mc md it me b mf mg mh mi lq mj lu mk ly ml mm mn mo mp mq bi translated"><strong class="me jd">简介</strong></li><li id="61b0" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm mn mo mp mq bi translated"><strong class="me jd">朴素贝叶斯算法</strong></li><li id="896f" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm mn mo mp mq bi translated"><strong class="me jd">处理文本数据</strong></li><li id="2bdd" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm mn mo mp mq bi translated"><strong class="me jd">Python中的工作示例(分步指南)</strong></li><li id="15d3" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm mn mo mp mq bi translated"><strong class="me jd">奖励:与模特同乐</strong></li><li id="26af" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm mn mo mp mq bi translated"><strong class="me jd">结论</strong></li></ol></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="c24f" class="nd li it bd lj ne nf ng lm nh ni nj lp ki nk kj lt kl nl km lx ko nm kp mb nn bi translated">1.介绍</h1><p id="c346" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated"><strong class="me jd">朴素贝叶斯</strong>分类器是基于<strong class="me jd">贝叶斯定理</strong>的分类算法集合。它不是一个单一的算法，而是一个算法家族，所有算法都有一个共同的原则，即每一对被分类的特征都是相互独立的。</p><p id="0fdb" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd">朴素贝叶斯</strong>分类器被大量用于<strong class="me jd">文本分类</strong>和<strong class="me jd">文本</strong> <strong class="me jd">分析</strong>机器学习<strong class="me jd">问题</strong>。</p><p id="f416" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd">文本分析</strong>是机器学习算法的主要应用领域。然而，原始数据、符号序列(即字符串)不能直接提供给算法本身，因为大多数算法期望具有固定大小的数字特征向量，而不是具有可变长度的原始文本文档。</p><p id="7402" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">在这篇文章中，我将解释a)朴素贝叶斯如何工作，b)我们如何使用文本T34，数据T35，数据T36，在将它们转换成更合适的形式后，将它们放入模型T40。最后，我<strong class="me jd">用Python </strong>一步步实现一个<strong class="me jd">多类文本分类问题。</strong></p><p id="463f" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">我们开始吧！！！</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="37e2" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">如果你想在交互式路线图和活跃的学习社区的支持下自学数据科学，看看这个资源:<a class="ae og" href="https://aigents.co/learn" rel="noopener ugc nofollow" target="_blank">https://aigents.co/learn</a></p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="bb0f" class="nd li it bd lj ne nf ng lm nh ni nj lp ki nk kj lt kl nl km lx ko nm kp mb nn bi translated">2.朴素贝叶斯算法</h1><p id="cbf0" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">朴素贝叶斯分类器是基于<strong class="me jd">贝叶斯定理</strong>的分类算法集合。它不是一个单一的算法，而是一个算法家族，所有算法都有一个共同的原则，即每一对被分类的特征都是相互独立的。</p><p id="27de" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">数据集分为两部分，即<strong class="me jd">特征矩阵</strong>和<strong class="me jd">响应/目标向量</strong>。</p><ul class=""><li id="7a83" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated"><strong class="me jd">特征</strong> <strong class="me jd">矩阵</strong> (X)包含数据集的所有向量(行)，其中每个向量由<strong class="me jd">相关特征</strong>的值组成。特征数为<strong class="me jd"> d </strong>即<strong class="me jd"> X = (x1，x2，x2，xd)。</strong></li><li id="d0cd" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated"><strong class="me jd">响应/目标</strong> <strong class="me jd">向量</strong> (y)包含特征矩阵<strong class="me jd">每行的<strong class="me jd">类/组变量</strong>的值。</strong></li></ul><h2 id="6773" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated"><strong class="ak"> 2.1。朴素贝叶斯的两个主要假设</strong></h2><p id="00ce" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">朴素贝叶斯假设<strong class="me jd">同一类的每个特征/变量</strong>构成一个:</p><ul class=""><li id="acf3" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated"><strong class="me jd">独立</strong></li><li id="7535" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated"><strong class="me jd">等于</strong></li></ul><p id="a07a" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd">对结果的贡献。</strong></p><p id="6301" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd">旁注:</strong>朴素贝叶斯所做的假设在现实世界的情况下一般不正确。事实上，独立性假设经常无法满足，这就是为什么它被称为“<strong class="me jd">幼稚</strong>”的原因，也就是因为它假设了一些可能不真实的事情。</p><h2 id="0122" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">2.2.贝叶斯定理</h2><p id="380e" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">贝叶斯定理是在已知一个事件发生的概率的情况下，求出另一个事件发生的概率。贝叶斯定理的数学表述如下:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ol"><img src="../Images/8ee53bda87995b7d0751b927b4dba317.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wtWUVjaqWORD4ViniVMN-Q.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure><p id="ca1d" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">其中:</p><ul class=""><li id="a338" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated"><strong class="me jd"> A </strong>和<strong class="me jd"> B </strong>称为<strong class="me jd">事件。</strong></li><li id="5526" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated">P(A | B)是事件A的概率，假设事件B为真(已经发生)。事件B也被称为<strong class="me jd">证据</strong>。</li><li id="8ccc" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated">P(A)是A的<strong class="me jd">先验</strong>(先验独立概率，即事件在证据被看到之前的概率)。</li><li id="e51b" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated">P(B | A)是给定事件A的B的概率，即看到证据A后事件B的概率。</li></ul><h2 id="b7a9" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">摘要</h2><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi om"><img src="../Images/50b76d3deeb8f4411afe46e49930aded.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dAggxuYiXtI5iiqGsOgDhw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure><h2 id="0724" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">2.3.朴素贝叶斯模型</h2><p id="5a91" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">给定一个数据矩阵<strong class="me jd"> X </strong>和一个目标向量<strong class="me jd"> y，</strong>我们将我们的问题表述为:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi on"><img src="../Images/d15dc42bdb6dc33fe850de4c9e7d74c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gvNwsiJ_cTW1_QNIVqDSCg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure><p id="eafd" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">其中，<strong class="me jd"> y </strong>为<strong class="me jd">类变量</strong>，<strong class="me jd"> X </strong>为维度为d的<strong class="me jd">依赖特征向量，即X = (x1，x2，x2，xd)，</strong>其中<strong class="me jd"> d </strong>为样本的变量/特征个数。</p><ul class=""><li id="f031" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated">P(y|X)是给定样本<strong class="me jd"> X </strong>观察到类<strong class="me jd"> y </strong>的概率，其中<strong class="me jd"> X = (x1，x2，x2，xd)，</strong>其中<strong class="me jd"> d </strong>是样本的变量/特征的数量。</li></ul><p id="e515" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">现在“天真的”<a class="ae og" href="https://en.wikipedia.org/wiki/Conditional_independence" rel="noopener ugc nofollow" target="_blank">条件独立性</a>假设开始发挥作用:假设<strong class="me jd"> X </strong>中的所有特性都是<a class="ae og" href="https://en.wikipedia.org/wiki/Mutually_independent" rel="noopener ugc nofollow" target="_blank">相互独立</a>，以类别<strong class="me jd"> y </strong>为条件:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oo"><img src="../Images/f25c07c0dc374f52f69fbb4fc492615a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*K4RRmFEMKy5aEWlX3WGwFg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure><p id="d6e6" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">最后，为了找到给定的<strong class="me jd">样本</strong>对于类变量<strong class="me jd"> <em class="op"> y </em> </strong>的所有可能值的概率，我们只需要找到具有最大概率的输出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oq"><img src="../Images/1a0abfdc7337af9eedd0c2789656c628.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*1PtU86RdWWSGyCTGhgXySQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="e07f" class="nd li it bd lj ne nf ng lm nh ni nj lp ki nk kj lt kl nl km lx ko nm kp mb nn bi translated">3.处理文本数据</h1><p id="5bc8" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">此时出现的一个问题如下:</p><blockquote class="or os ot"><p id="e666" class="no np op me b mf ob kd nq mh oc kg nr ou od nt nu ov oe nw nx ow of nz oa mm im bi translated">我们如何使用原始文本数据来训练模型？原始数据是字符串的集合！</p></blockquote><p id="99f1" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">文本分析是机器学习算法的一个主要应用领域。<strong class="me jd">然而，原始数据、符号序列(即字符串)不能直接提供给算法本身，因为大多数算法期望具有固定大小的数字特征向量，而不是具有可变长度的原始文本文档。</strong></p><p id="893d" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">为了解决这个问题，scikit-learn提供了从文本内容中提取数字特征的最常见方法的实用程序，即:</p><ul class=""><li id="1ab1" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated"><strong class="me jd">标记化</strong>字符串并为每个可能的标记给出一个整数id，例如通过使用空格和标点符号作为标记分隔符。</li><li id="ec78" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated"><strong class="me jd">统计每个文档中令牌的出现次数</strong>。</li></ul><p id="709e" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">在此方案中，特征和样本定义如下:</p><ul class=""><li id="8a55" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated">每个<strong class="me jd">单个令牌出现频率</strong>被视为一个<strong class="me jd">特征</strong>。</li><li id="f6dc" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated">给定<strong class="me jd">文档</strong>的所有令牌频率的向量被视为多元<strong class="me jd">样本</strong>。</li></ul><h2 id="d682" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">“计数”示例(为了在我们继续之前真正理解这一点):</h2><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="d5d7" class="lh li it oy b gy pc pd l pe pf">from sklearn.feature_extraction.text import CountVectorizer<br/>corpus = [<br/>    'This is the first document.',<br/>    'This document is the second document.',<br/>    'And this is the third one.',<br/>    'Is this the first document?',<br/>]</span><span id="5a3b" class="lh li it oy b gy pg pd l pe pf">vectorizer = CountVectorizer()<br/>X = vectorizer.fit_transform(corpus)</span><span id="620e" class="lh li it oy b gy pg pd l pe pf">print(vectorizer.get_feature_names())<br/><strong class="oy jd">[‘and’, ‘document’, ‘first’, ‘is’, ‘one’, ‘second’, ‘the’, ‘third’, ‘this’]</strong></span><span id="5d37" class="lh li it oy b gy pg pd l pe pf">print(X.toarray())<br/>[[0 1 1 1 0 0 1 0 1]<br/> [0 2 0 1 0 1 1 0 1]<br/> [1 0 0 1 1 0 1 1 1]<br/> [0 1 1 1 0 0 1 0 1]]</span></pre><p id="6177" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">在上面的玩具示例中，我们将一组字符串存储在变量<strong class="me jd">语料库中。</strong>使用<strong class="me jd">文本</strong> <strong class="me jd">转换器</strong>，我们可以看到我们的数据中有特定数量的唯一字符串(词汇)。</p><p id="31d5" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">这可以通过打印<strong class="me jd">矢量器. get_feature_names() </strong>变量<strong class="me jd">来看出。我们观察到我们有9个独特的单词。</strong></p><p id="2e63" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">接下来，我们打印转换后的数据(<strong class="me jd"> X </strong>)和<strong class="me jd">，我们观察到以下</strong>:</p><ul class=""><li id="8aab" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated">我们在X中有4行作为我们的文本串的数量(<strong class="me jd">我们在转换后有相同数量的样本</strong>)。</li><li id="9316" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated"><strong class="me jd">我们在转换后的数据(<strong class="me jd"> X </strong> ) f <strong class="me jd">或所有样本(</strong>转换前并非如此，即各个字符串具有不同的长度)中有相同数量的列</strong>(特征/变量)。</li><li id="f7c4" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated">值0，1，2对<strong class="me jd">出现在<strong class="me jd">初始文本数据</strong>中的<strong class="me jd">字</strong>的<strong class="me jd">频率</strong>进行编码。</strong></li></ul><p id="7609" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd">例如</strong>。第一个转换行是<strong class="me jd">[0 1 1 1 0 1 0 1 0 1]</strong>和<strong class="me jd"/><strong class="me jd">唯一词汇</strong>是<strong class="me jd"> ['and '，' document '，' first '，' is '，' one '，' second '，' The '，' this']，</strong>因此这意味着单词“document”，“first”，“is”，“the”和“this”在初始文本串中各出现1次(即“这是第一个文档”).</p><p id="50fa" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd">边注:</strong>这是计数法。<a class="ae og" href="https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer" rel="noopener ugc nofollow" target="_blank">项-频率变换</a>无非是将计数矩阵变换成归一化的项-频率矩阵。</p><p id="1df3" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">希望现在一切都清楚了。如果没有，根据需要多次阅读这一段，以便真正掌握思想和理解这一转变。这是最基本的一步。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="eac2" class="nd li it bd lj ne nf ng lm nh ni nj lp ki nk kj lt kl nl km lx ko nm kp mb nn bi translated">4.Python中的工作示例</h1><p id="8a0e" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">既然您已经理解了朴素贝叶斯和文本转换是如何工作的，那么是时候开始编码了！</p><h2 id="9dbd" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">问题陈述</h2><p id="acd2" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">作为一个工作示例，我们将使用一些<strong class="me jd">文本</strong> <strong class="me jd">数据</strong>，我们将构建一个<strong class="me jd">朴素</strong> <strong class="me jd">贝叶斯</strong>模型来<strong class="me jd">预测<strong class="me jd">文本</strong>的<strong class="me jd">类别</strong>。这是一个<strong class="me jd">多类(20类)文本分类问题</strong>。</strong></p><p id="b386" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">让我们开始吧(我会带你走一遍)。首先，我们将<strong class="me jd">加载所有必要的库</strong>:</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="f45a" class="lh li it oy b gy pc pd l pe pf">import numpy as np, pandas as pd<br/>import seaborn as sns<br/>import matplotlib.pyplot as plt<br/>from sklearn.datasets import fetch_20newsgroups<br/>from sklearn.feature_extraction.text import TfidfVectorizer<br/>from sklearn.naive_bayes import MultinomialNB<br/>from sklearn.pipeline import make_pipeline<br/>from sklearn.metrics import confusion_matrix, <!-- -->accuracy_score</span><span id="466f" class="lh li it oy b gy pg pd l pe pf">sns.set() # use seaborn plotting style</span></pre><p id="4437" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">接下来，<strong class="me jd">让我们加载数据</strong> ( <strong class="me jd">训练</strong>和<strong class="me jd">测试</strong>集合):</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="6f4c" class="lh li it oy b gy pc pd l pe pf"># Load the dataset<br/>data = fetch_20newsgroups()</span><span id="2cfa" class="lh li it oy b gy pg pd l pe pf"># Get the text categories<br/>text_categories = data.target_names</span><span id="3d52" class="lh li it oy b gy pg pd l pe pf"># define the training set<br/>train_data = fetch_20newsgroups(subset="train", categories=text_categories)</span><span id="fd8b" class="lh li it oy b gy pg pd l pe pf"># define the test set<br/>test_data = fetch_20newsgroups(subset="test", categories=text_categories)</span></pre><p id="3a27" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">让我们找出<strong class="me jd">我们有多少类</strong>和<strong class="me jd">样本</strong>:</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="2622" class="lh li it oy b gy pc pd l pe pf">print("We have {} unique classes".format(len(text_categories)))<br/>print("We have {} training samples".format(len(train_data.data)))<br/>print("We have {} test samples".format(len(test_data.data)))</span></pre><p id="529c" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">上面的版画:</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="7a80" class="lh li it oy b gy pc pd l pe pf">We have 20 unique classes<br/>We have 11314 training samples<br/>We have 7532 test samples</span></pre><p id="a628" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">所以，这是一个<strong class="me jd"> 20类文本分类问题</strong>用n_train = <strong class="me jd"> 11314 </strong> <strong class="me jd">训练</strong> <strong class="me jd">样本</strong>(文本句子)和n _ test =<strong class="me jd"/><strong class="me jd">测试</strong> <strong class="me jd">样本</strong>(文本句子)。</p><p id="541b" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">让我们想象一下第五个训练样本:</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="fe25" class="lh li it oy b gy pc pd l pe pf"># let’s have a look as some training data<br/>print(test_data.data[5])</span></pre><p id="a4c2" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">如前所述，我们的数据是<strong class="me jd">文本</strong>(更具体地说，是<strong class="me jd">电子邮件</strong>)，所以您应该会看到类似下面这样的输出:</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ph"><img src="../Images/ad86d506c9084aa1bb68118fe154ec70.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OkKSVQQNhFE37m-nLcKDAQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure><p id="e756" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">下一步包括建立<strong class="me jd">朴素贝叶斯分类器</strong>，最后<strong class="me jd">训练</strong>模型<strong class="me jd">。</strong>在我们的例子中，我们将把文本文档的集合(训练和测试集)转换成一个令牌计数的矩阵(我在<strong class="me jd">第3节</strong>中解释了这是如何工作的)。</p><blockquote class="or os ot"><p id="13e6" class="no np op me b mf ob kd nq mh oc kg nr ou od nt nu ov oe nw nx ow of nz oa mm im bi translated">为了实现文本转换，我们将使用<strong class="me jd"> make_pipeline </strong>函数。这将在内部转换文本数据，然后使用转换后的数据拟合模型<strong class="me jd">。</strong></p></blockquote><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="1089" class="lh li it oy b gy pc pd l pe pf"># Build the model<br/>model = make_pipeline(TfidfVectorizer(), MultinomialNB())</span><span id="cb85" class="lh li it oy b gy pg pd l pe pf"># Train the model using the training data<br/>model.fit(train_data.data, train_data.target)</span><span id="61e8" class="lh li it oy b gy pg pd l pe pf"># Predict the categories of the test data<br/>predicted_categories = model.predict(test_data.data)</span></pre><p id="0344" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">代码的最后一行<strong class="me jd">预测了测试集</strong>的标签。</p><p id="db36" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">让我们看看预测的类别名称:</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="a1a9" class="lh li it oy b gy pc pd l pe pf">print(np.array(test_data.target_names)[predicted_categories])<br/>array(['rec.autos', 'sci.crypt', 'alt.atheism', ..., 'rec.sport.baseball', 'comp.sys.ibm.pc.hardware', 'soc.religion.christian'], dtype='&lt;U24')</span></pre><p id="742d" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">最后，让我们构建<a class="ae og" rel="noopener" target="_blank" href="/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c?source=friends_link&amp;sk=08f3dba9c6415860f84f5195d9b0ff65"> <strong class="me jd">多类混淆矩阵</strong> </a>来看看这个模型是好的还是这个模型只正确预测特定的文本类别。</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="d05e" class="lh li it oy b gy pc pd l pe pf"># plot the confusion matrix<br/>mat = confusion_matrix(test_data.target, predicted_categories)<br/>sns.heatmap(mat.T, square = True, annot=True, fmt = "d", xticklabels=train_data.target_names,yticklabels=train_data.target_names)<br/>plt.xlabel("true labels")<br/>plt.ylabel("predicted label")<br/>plt.show()</span><span id="e098" class="lh li it oy b gy pg pd l pe pf">print("The accuracy is {}".format(accuracy_score(test_data.target, predicted_categories)))</span><span id="9ba3" class="lh li it oy b gy pg pd l pe pf">The accuracy is 0.7738980350504514</span></pre><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi pi"><img src="../Images/b365025b4916f908723c8bbef17132b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eUVx9X8GD9f5IYqaPpMxLQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">作者创作的人物。</p></figure><h1 id="c448" class="nd li it bd lj ne pj ng lm nh pk nj lp ki pl kj lt kl pm km lx ko pn kp mb nn bi translated">5.额外收获:和模特玩得开心</h1><p id="a7c9" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">让我们用训练好的模型来找点乐子。让我们把我们喜欢的句子分类😄。</p><pre class="ks kt ku kv gt ox oy oz pa aw pb bi"><span id="1dac" class="lh li it oy b gy pc pd l pe pf"># custom function to have fun<br/>def my_predictions(my_sentence, model):<br/>    all_categories_names = np.array(data.target_names)<br/>    prediction = model.predict([my_sentence])<br/>    return all_categories_names[prediction]</span><span id="6e43" class="lh li it oy b gy pg pd l pe pf"><br/>my_sentence = “jesus”<br/>print(my_predictions(my_sentence, model))<br/>['soc.religion.christian']</span><span id="408f" class="lh li it oy b gy pg pd l pe pf">my_sentence = "Are you an atheist?"<br/>print(my_predictions(my_sentence, model))<br/>['alt.atheism']</span></pre><p id="e4ae" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">我们将字符串“jesus”插入到模型中，它预测了类别“' soc.religion.christian']”。</p><p id="3cc9" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">把“我的句子”换成其他字符串<strong class="me jd">玩模型</strong>😃。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="7ef8" class="nd li it bd lj ne nf ng lm nh ni nj lp ki nk kj lt kl nl km lx ko nm kp mb nn bi translated">6.结论</h1><p id="5345" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">我们看到<strong class="me jd">朴素贝叶斯对于<strong class="me jd">多类文本分类问题是一个非常强大的算法</strong>。</strong></p><p id="b5bd" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd"> <em class="op">边注</em> </strong> : <em class="op">如果你想了解更多关于混淆矩阵(以及ROC曲线)的知识，请看这个:</em></p><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">用新冠肺炎假设的例子解释ROC曲线:二分类和多分类…</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我清楚地解释了什么是ROC曲线以及如何阅读它。我用一个新冠肺炎的例子来说明我的观点，我…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qb l qc qd qe qa qf lb pr"/></div></div></a></div><h2 id="a7a7" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">解读困惑矩阵</h2><p id="995b" class="pw-post-body-paragraph no np it me b mf mg kd nq mh mi kg nr lq ns nt nu lu nv nw nx ly ny nz oa mm im bi translated">从上面的<strong class="me jd">混乱</strong> <strong class="me jd">矩阵</strong>可以验证模型真的很好。</p><ul class=""><li id="4643" class="mc md it me b mf ob mh oc lq oh lu oi ly oj mm ok mo mp mq bi translated">它能够正确地预测所有20类文本数据(大多数值在对角线上，少数不在对角线上)。</li><li id="8eb7" class="mc md it me b mf mr mh ms lq mt lu mu ly mv mm ok mo mp mq bi translated">我们还注意到最高的误分类(偏离对角线的值)是<strong class="me jd"> 131 </strong>(从末尾起5行，右边最后一列)。值131意味着属于“<strong class="me jd">宗教杂项</strong>”类别的131个文档被误分类为属于“<strong class="me jd">宗教基督教</strong>”类别。</li></ul><p id="d557" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">有趣的是，这两个类别非常相似，实际上人们可以将它们划分为一个更大的群体中的两个子群体，例如一般的“宗教”。</p><p id="47a9" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">最后，<strong class="me jd">测试</strong>集合上的<strong class="me jd">准确度</strong>为<strong class="me jd"> 0.7739 </strong>对于一个<strong class="me jd"> 20级的文本分类问题</strong>来说已经相当不错了🚀。</p><p id="f64f" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated"><strong class="me jd">那都是乡亲们！希望你喜欢这篇文章。</strong></p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="8b99" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">如果您喜欢这篇文章并觉得它有用，请关注👣我可以看到我所有的新帖子。</p><p id="a2c2" class="pw-post-body-paragraph no np it me b mf ob kd nq mh oc kg nr lq od nt nu lu oe nw nx ly of nz oa mm im bi translated">有问题吗？把它们作为评论贴出来，我会尽快回复。</p></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h2 id="bc70" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">我的个人资料(看看我收集的文章):</h2><div class="po pp gp gr pq pr"><a href="https://towardsdatascience.com/@seralouk" rel="noopener follow" target="_blank"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">Serafeim Loukas -走向数据科学</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">阅读Serafeim Loukas在《走向数据科学》中的文章。电气和计算机工程文凭(NTUA)。主人…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qg l qc qd qe qa qf lb pr"/></div></div></a></div></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h1 id="609e" class="nd li it bd lj ne nf ng lm nh ni nj lp ki nk kj lt kl nl km lx ko nm kp mb nn bi translated">和我联系</h1><ul class=""><li id="3ef3" class="mc md it me b mf mg mh mi lq mj lu mk ly ml mm ok mo mp mq bi translated"><strong class="me jd">领英</strong>:<a class="ae og" href="https://www.linkedin.com/in/serafeim-loukas/" rel="noopener ugc nofollow" target="_blank">https://www.linkedin.com/in/serafeim-loukas/</a></li></ul></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><h2 id="35c6" class="lh li it bd lj lk ll dn lm ln lo dp lp lq lr ls lt lu lv lw lx ly lz ma mb iz bi translated">您可能还喜欢:</h2><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/support-vector-machines-svm-clearly-explained-a-python-tutorial-for-classification-problems-29c539f3ad8"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">支持向量机(SVM)解释清楚:分类问题的python教程…</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我解释了支持向量机的核心，为什么以及如何使用它们。此外，我还展示了如何绘制支持…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qh l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/k-means-clustering-how-it-works-finding-the-optimum-number-of-clusters-in-the-data-13d18739255c"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">K-Means聚类:工作原理&amp;在数据中寻找最优的聚类数</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">数学公式，寻找最佳聚类数和Python中的工作示例。</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qi l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/lstm-time-series-forecasting-predicting-stock-prices-using-an-lstm-model-6223e9644a2f"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">LSTM时间序列预测:使用LSTM模型预测股票价格</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我将向你展示如何使用预测LSTM模型来预测股票价格</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qj l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/time-series-forecasting-predicting-stock-prices-using-an-arima-model-2e3b3080bd70"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">时间序列预测:使用ARIMA模型预测股票价格</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我将向你展示如何使用预测ARIMA模型来预测特斯拉的股票价格</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qk l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a href="https://medium.com/@seralouk/the-best-free-data-science-resources-free-books-online-courses-9c4a2df194e5" rel="noopener follow" target="_blank"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">最佳免费数据科学资源:免费书籍和在线课程</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">最有用的免费书籍和在线课程，适合想了解更多数据科学知识的人。</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">medium.com</p></div></div><div class="qa l"><div class="ql l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/roc-curve-explained-using-a-covid-19-hypothetical-example-binary-multi-class-classification-bab188ea869c"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">用新冠肺炎假设的例子解释ROC曲线:二分类和多分类…</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我清楚地解释了什么是ROC曲线以及如何阅读它。我用一个新冠肺炎的例子来说明我的观点，我…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qb l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/support-vector-machines-svm-clearly-explained-a-python-tutorial-for-classification-problems-29c539f3ad8"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">支持向量机(SVM)解释清楚:分类问题的python教程…</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我解释了支持向量机的核心，为什么以及如何使用它们。此外，我还展示了如何绘制支持…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qh l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/pca-clearly-explained-how-when-why-to-use-it-and-feature-importance-a-guide-in-python-7c274582c37e"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">PCA清楚地解释了——如何、何时、为什么使用它以及特性的重要性:Python指南</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我解释了什么是PCA，何时以及为什么使用它，以及如何使用scikit-learn在Python中实现它。还有…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qm l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/everything-you-need-to-know-about-min-max-normalization-in-python-b79592732b79"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">关于Python中的最小-最大规范化，您需要知道的一切</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我将解释什么是最小-最大缩放，什么时候使用它，以及如何使用scikit在Python中实现它</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qn l qc qd qe qa qf lb pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/how-and-why-to-standardize-your-data-996926c2c832"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">Scikit-Learn的标准定标器如何工作</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在这篇文章中，我将解释为什么以及如何使用scikit-learn应用标准化</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qo l qc qd qe qa qf lb pr"/></div></div></a></div></div></div>    
</body>
</html>