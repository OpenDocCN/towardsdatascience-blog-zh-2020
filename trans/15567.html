<html>
<head>
<title>The structure behind an award-winning photo — a deep learning approach</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">获奖照片背后的结构——深度学习方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/the-essence-behind-an-award-winning-photo-an-ai-approach-f044d908d412?source=collection_archive---------57-----------------------#2020-10-26">https://towardsdatascience.com/the-essence-behind-an-award-winning-photo-an-ai-approach-f044d908d412?source=collection_archive---------57-----------------------#2020-10-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9e3a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">通过可视化CNN架构的各层，我们深入了解机器如何处理图像。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/8eb56365599036e2a55748c17d8b4913.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*AZ4LdIxiTiW40xp-"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ky">来源</em><a class="ae kz" href="https://unsplash.com/photos/hJKkyoG8_ng" rel="noopener ugc nofollow" target="_blank"><em class="ky">https://unsplash.com/photos/hJKkyoG8_ng</em></a><em class="ky">由哈迪·雅兹迪·阿兹纳韦—昂斯普拉什奖2019年入选《时事要闻》</em></p></figure><p id="19d6" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">卷积神经网络(CNN)允许计算机对图像进行分类。除了对物体进行分类，它们还能让我们了解是什么构成了一幅图片。一幅画的本质是什么？通过可视化CNN架构的各层，我们深入了解机器如何处理图像。这也提供了人类如何“看见”图片的见解。</p><p id="63b5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这篇文章将在一边展示什么元素构建了一幅图片，并提供了用Keras实现Python的代码。</p><h1 id="3e75" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">目录</h1><ul class=""><li id="8e8e" class="mo mp it lc b ld mq lg mr lj ms ln mt lr mu lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#disclaimer" rel="noopener ugc nofollow" target="_blank">免责声明</a></li><li id="9259" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#the-base-image" rel="noopener ugc nofollow" target="_blank">基础图像</a></li><li id="d8ba" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#using-a-vgg-network" rel="noopener ugc nofollow" target="_blank">使用VGG网络</a></li><li id="e10a" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#convolutional-layer-feature-maps" rel="noopener ugc nofollow" target="_blank">卷积层特征图</a></li><li id="479c" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated">我们能观察到什么？</li><li id="0ed1" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#visualize-with-code" rel="noopener ugc nofollow" target="_blank">用代码</a>可视化</li><li id="47c9" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#features-in-grid" rel="noopener ugc nofollow" target="_blank">网格中的特征</a></li><li id="e731" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#features-with-notebook-display" rel="noopener ugc nofollow" target="_blank">笔记本显示器的特性</a></li><li id="9427" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#bonus---a-neural-transfer-approach" rel="noopener ugc nofollow" target="_blank">奖励——一种神经转移方法</a></li><li id="f4c7" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#inspiration" rel="noopener ugc nofollow" target="_blank">灵感</a></li><li id="40e1" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd/Writing/blob/master/2020/articles/visualizeLayersCNN.md#about" rel="noopener ugc nofollow" target="_blank">关于</a></li></ul><h1 id="1f48" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">放弃</h1><p id="74ff" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">我与本文中使用的任何服务都没有关联。</p><p id="aa7c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我不认为自己是专家。如果你觉得我错过了重要的步骤或者忽略了什么，可以考虑在评论区指出来或者联系我。</p><p id="da8d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我总是乐于听取建设性的意见以及如何改进。</p><p id="4fec" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated"><strong class="lc iu">这篇文章写于2020年10月25日。</strong>我无法监控我的所有文章。当你阅读这篇文章时，提示很可能已经过时，过程已经改变。</p><p id="536d" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果你需要更多关于某些部分的信息，请在评论中指出来。</p><h1 id="0f2a" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">基本图像</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f17e6026c15ae7510fbcca9e3aebe0d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3uEp00P25SA_BnHf"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ky">来源</em><a class="ae kz" href="https://unsplash.com/photos/hJKkyoG8_ng" rel="noopener ugc nofollow" target="_blank"><em class="ky">https://unsplash.com/photos/hJKkyoG8_ng</em></a><em class="ky">由哈迪·雅兹迪·阿兹纳韦—昂斯普拉什奖2019入选《时事热点》</em></p></figure><p id="b8ff" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我喜欢这张图片，因为它有一个故事，它激发了情感，但也在摄影的层面上提供了一个丰富的结构。</p><p id="f708" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为了解释我为什么选择这张图片，我直接引用Vice的设计总监Joel Tellier的话(摘自<a class="ae kz" href="https://awards.unsplash.com/2019/#/current-events" rel="noopener ugc nofollow" target="_blank"> Unsplash Awards页面</a>):</p><blockquote class="nh"><p id="712b" class="ni nj it bd nk nl nm nn no np nq lv dk translated">这张照片的构图令人难以置信。每个元素都有故事和历史层次。这个主题的随意性表明，她在一个她和她的性别在历史上从未受到欢迎的地方完全自在。她受伤，因此很难参加那一天，增加了她爱国庆祝活动的轻松性质，暗示了一个更复杂的故事。座位上的数字有助于暗示历史，让我想知道在一个(第一个)女人被允许之前，有多少男人坐在她坐的地方。</p></blockquote><p id="d2a5" class="pw-post-body-paragraph la lb it lc b ld nr ju lf lg ns jx li lj nt ll lm ln nu lp lq lr nv lt lu lv im bi translated">这使得用CNN提取信息成为一个非常有趣的图像。</p><h1 id="402c" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">使用VGG网络</h1><p id="3045" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">我假设理解卷积神经网络(CNN)。这种架构对于计算机视觉和深度学习中的许多事情都非常关键。网上有很多可用的资源。作为复习，我建议这篇<a class="ae kz" href="https://medium.com/@himadrisankarchatterjee/a-basic-introduction-to-convolutional-neural-network-8e39019b27c4" rel="noopener">文章</a>。</p><p id="b2df" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">为了理解随后的可视化，有必要说明CNN的不同层代表什么。</p><ul class=""><li id="0413" class="mo mp it lc b ld le lg lh lj nw ln nx lr ny lv mv mw mx my bi translated">CNN的较浅层倾向于检测较低级别的特征，例如边缘和简单纹理。</li><li id="8640" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated">更深的层倾向于检测更高级的特征，例如更复杂的纹理以及对象类别。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/7bd80fe1f07e54ec82988cfd0ee15d9a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*S27bVAdspBCrhoIQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来自研究论文<a class="ae kz" href="https://www.researchgate.net/publication/334388209_Automatic_Mass_Detection_in_Breast_Using_Deep_Convolutional_Neural_Network_and_SVM_Classifier" rel="noopener ugc nofollow" target="_blank">的VGG19架构使用深度卷积神经网络和SVM分类器</a>和<a class="ae kz" href="https://creativecommons.org/licenses/by/4.0/" rel="noopener ugc nofollow" target="_blank">知识共享许可</a>进行乳房自动肿块检测</p></figure><p id="6e1f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">可以可视化过滤器和特征图。过滤器也是描绘特定特征的图像。应用这些过滤器导致特征图。实际上，图层越浅，要素地图看起来就越像原始输入。在这篇文章中，我想把重点放在特征地图和它们的可视化上，因为它们给CNN“看到”和学到的东西留下了很好的印象。</p><h1 id="57d5" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">卷积图层要素地图</h1><p id="b7a3" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">VGG19模型具有以下结构和层:</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="9ab2" class="of lx it ob b gy og oh l oi oj">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #<br/>=================================================================<br/>input_1 (InputLayer)         (None, None, None, 3)     0<br/>_________________________________________________________________<br/>block1_conv1 (Conv2D)        (3, 800, 1199, 64)        1792<br/>_________________________________________________________________<br/>block1_conv2 (Conv2D)        (3, 800, 1199, 64)        36928<br/>_________________________________________________________________<br/>block1_pool (MaxPooling2D)   (3, 400, 599, 64)         0<br/>_________________________________________________________________<br/>block2_conv1 (Conv2D)        (3, 400, 599, 128)        73856<br/>_________________________________________________________________<br/>block2_conv2 (Conv2D)        (3, 400, 599, 128)        147584<br/>_________________________________________________________________<br/>block2_pool (MaxPooling2D)   (3, 200, 299, 128)        0<br/>_________________________________________________________________<br/>block3_conv1 (Conv2D)        (3, 200, 299, 256)        295168<br/>_________________________________________________________________<br/>block3_conv2 (Conv2D)        (3, 200, 299, 256)        590080<br/>_________________________________________________________________<br/>block3_conv3 (Conv2D)        (3, 200, 299, 256)        590080<br/>_________________________________________________________________<br/>block3_conv4 (Conv2D)        (3, 200, 299, 256)        590080<br/>_________________________________________________________________<br/>block3_pool (MaxPooling2D)   (3, 100, 149, 256)        0<br/>_________________________________________________________________<br/>block4_conv1 (Conv2D)        (3, 100, 149, 512)        1180160<br/>_________________________________________________________________<br/>block4_conv2 (Conv2D)        (3, 100, 149, 512)        2359808<br/>_________________________________________________________________<br/>block4_conv3 (Conv2D)        (3, 100, 149, 512)        2359808<br/>_________________________________________________________________<br/>block4_conv4 (Conv2D)        (3, 100, 149, 512)        2359808<br/>_________________________________________________________________<br/>block4_pool (MaxPooling2D)   (3, 50, 74, 512)          0<br/>_________________________________________________________________<br/>block5_conv1 (Conv2D)        (3, 50, 74, 512)          2359808<br/>_________________________________________________________________<br/>block5_conv2 (Conv2D)        (3, 50, 74, 512)          2359808<br/>_________________________________________________________________<br/>block5_conv3 (Conv2D)        (3, 50, 74, 512)          2359808<br/>_________________________________________________________________<br/>block5_conv4 (Conv2D)        (3, 50, 74, 512)          2359808<br/>_________________________________________________________________<br/>block5_pool (MaxPooling2D)   (3, 25, 37, 512)          0<br/>=================================================================<br/>Total params: 20,024,384<br/>Trainable params: 20,024,384<br/>Non-trainable params: 0<br/>_________________________________________________________________</span></pre><p id="7166" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">所以这是原图:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/6d7aa71a4e21b637f433afced4cbff85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6nMa0pr7Nhlf1G0v"/></div></div></figure><p id="932e" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">通过CNN的不同层，我们可以观察到不同过滤器应用于原始图像的结果。我将用“热”色图显示它。只是因为我觉得它比其他色彩映射表更能突出特色。</p><p id="dda5" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">请注意，过滤器的尺寸和数量随着块的数量而变化。为了简单起见，我将只绘制8*8的网格。</p><p id="3d46" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们先来看一下每个块的<strong class="lc iu">第一个</strong>卷积层:</p><div class="kj kk kl km gt ab cb"><figure class="ok kn ol om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/328191e0fd88fe85c5ca92cf8a14ae4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:992/format:webp/0*0OmrqDaEsmjK_8nW.png"/></div></figure><figure class="ok kn oq om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/071a9427120cbc3fff2a5af0bd5329dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/0*0k_YIO3ClJj1YcN8.png"/></div></figure></div><div class="ab cb"><figure class="ok kn or om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f5a8b54c485d784c7aec42f82151ee40.png" data-original-src="https://miro.medium.com/v2/resize:fit:666/format:webp/0*XPGhUcIqlcU1_4yU.png"/></div></figure><figure class="ok kn os om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/715420886ad1abf28622d88adbc52489.png" data-original-src="https://miro.medium.com/v2/resize:fit:662/format:webp/0*q6jygS9wIcywA-H3.png"/></div></figure><figure class="ok kn ot om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/9c2dd4a6c512df7706bd0eb049aed3d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:676/format:webp/0*O13KdIX1ZZdocY0J.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov ow translated">每个块的第<strong class="bd ox">个</strong>卷积层</p></figure></div><p id="cea3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">我们来看看每个块的<strong class="lc iu">最后</strong>卷积层:</p><div class="kj kk kl km gt ab cb"><figure class="ok kn oy om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/69e630b62c524da1cbe83e7a1cc4da94.png" data-original-src="https://miro.medium.com/v2/resize:fit:998/format:webp/0*ND-_kNmFoA7uebKP.png"/></div></figure><figure class="ok kn oz om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/c51ac8c0a86797540d25a62b6554bfb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1004/format:webp/0*x4jzEpG2omqji07w.png"/></div></figure></div><div class="ab cb"><figure class="ok kn pa om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/5c0b1cdf005a8f45254b1871df97c2af.png" data-original-src="https://miro.medium.com/v2/resize:fit:660/format:webp/0*GSKcbgSxinRKsGTt.png"/></div></figure><figure class="ok kn pb om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f6888f01dbf91cff7ef9263b55446ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/0*H-2fzvIl7h1Pmvzj.png"/></div></figure><figure class="ok kn pc om on oo op paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><img src="../Images/f15c98ac8d785217daa020ee8f8e6f3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/0*vZ3OGwwZ_vKNqrl7.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk ou di ov ow translated">每个块的最后一个卷积层<strong class="bd ox"/></p></figure></div><h1 id="5347" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">我们能观察到什么？</h1><p id="50a2" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">两件事:</p><ol class=""><li id="02cf" class="mo mp it lc b ld le lg lh lj nw ln nx lr ny lv pd mw mx my bi translated">我们可以清楚地看到在更深的层中物体被探测到。例如，孤立的女人，但也有一个座位，国旗，甚至有色座椅脱颖而出。</li><li id="39ea" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv pd mw mx my bi translated">这幅图像吸引人的很大一部分是它的结构本身。我们可以看到图片中的女人是如何在非常结构化的环境中带来柔和感的。它看起来很吸引人，因为它的结构是圆形的。圆形的元素使观察者能够将注意力集中在这个独特的物体上，而不是类似的座位上。</li></ol><p id="564a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">本质上，我们可以看到一个图像的相当有趣的组成。我们通过竞技场中的座位提供了许多纹理和结构，但这种结构在人类的形式中是一种扭曲。这将观察者的眼睛直接引导至图像的主角，即女性。它完全符合故事情节。我想说这是区分好照片和优秀照片的地方。通过可视化来支持故事情节。</p><p id="3c6b" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">它就像一个视频，完美地将音乐切割成了它的视觉表达。明白我对这个视频的意思了吗:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pe pf l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">为什么音乐在视频中如此重要</p></figure></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><p id="242a" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">至少这些是我的观察。你认为是什么让这张照片吸引人？请在评论中告诉我。</p></div><div class="ab cl pg ph hx pi" role="separator"><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl pm"/><span class="pj bw bk pk pl"/></div><div class="im in io ip iq"><h1 id="700a" class="lw lx it bd ly lz pn mb mc md po mf mg jz pp ka mi kc pq kd mk kf pr kg mm mn bi translated">用代码可视化</h1><h1 id="335e" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">网格中的特征</h1><p id="47d8" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">在我对CNN图层的特征地图进行可视化的研究中，我经常会找到一些教程和实现，这些教程和实现提供了关于如何实现可视化的见解，但并没有真正看到和理解图像所显示的内容。</p><p id="a0a9" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">在我的“灵感”部分，你可以找到形象化的各种实现。通常提取图像的方法是很好的。我只是总觉得它们太小了，不足以表达自己的观点。</p><p id="a351" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果您遵循现有的解决方案，您可以这样做:</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="a990" class="of lx it ob b gy og oh l oi oj">import numpy as np<br/>from keras.preprocessing.image import save_img, load_img, img_to_array<br/>from PIL import Image<br/>from keras.applications.vgg19 import preprocess_input<br/>from keras.models import Model<br/>from keras.applications import vgg19<br/>import matplotlib.pyplot as plt<br/></span><span id="1638" class="of lx it ob b gy ps oh l oi oj">size = 224</span><span id="1a74" class="of lx it ob b gy ps oh l oi oj">image = load_img(image_path).resize((size, size))<br/>image = img_to_array(image)<br/>image = np.expand_dims(image, axis=0)<br/>image = preprocess_input(image)</span><span id="1c2f" class="of lx it ob b gy ps oh l oi oj">model = vgg19.VGG19()</span><span id="4629" class="of lx it ob b gy ps oh l oi oj">layer_dict = dict([(layer.name, layer) for layer in model.layers])</span><span id="bc93" class="of lx it ob b gy ps oh l oi oj">layer_name = 'block1_conv1'</span><span id="8e43" class="of lx it ob b gy ps oh l oi oj">model = Model(inputs=model.inputs, outputs=layer_dict[layer_name].output)</span><span id="dfda" class="of lx it ob b gy ps oh l oi oj">feature_maps = model.predict(image)</span><span id="aec5" class="of lx it ob b gy ps oh l oi oj">tiles = 8<br/>index = 1<br/>fig, ax = plt.subplots(figsize=(size, size))<br/>for _ in range(tiles):<br/>    for _ in range(tiles):<br/>        ax = plt.subplot(tiles, tiles, index)<br/>        ax.set_xticks([])<br/>        ax.set_yticks([])</span><span id="ac3a" class="of lx it ob b gy ps oh l oi oj">        plt.imshow(feature_maps[0, :, :, index-1], aspect='auto', cmap='hot')<br/>        index += 1</span><span id="bc5e" class="of lx it ob b gy ps oh l oi oj">plt.tight_layout()<br/>plt.show()</span></pre><p id="0182" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果您想要在不同的图层上显示多个可视化效果，这将非常有用。喜欢</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="0e81" class="of lx it ob b gy og oh l oi oj">for layer in layer_names:<br/>    print(f'{"-"*100}\nLayer {layer}')<br/>    model = Model(inputs=model.inputs, outputs=layer_dict[layer].output)</span><span id="e05a" class="of lx it ob b gy ps oh l oi oj">    feature_maps = model.predict(image)<br/>    print(feature_maps.shape)</span><span id="8c8b" class="of lx it ob b gy ps oh l oi oj">tiles = 8<br/>    index = 1<br/>    fig, ax = plt.subplots(figsize=(size, size))<br/>    for _ in range(tiles):<br/>        for _ in range(tiles):</span><span id="c93f" class="of lx it ob b gy ps oh l oi oj">            ax = plt.subplot(tiles, tiles, index)<br/>            ax.set_xticks([])<br/>            ax.set_yticks([])</span><span id="e52f" class="of lx it ob b gy ps oh l oi oj">            plt.imshow(feature_maps[0, :, :, index-1], aspect='auto', cmap='hot')<br/>            index += 1</span><span id="306f" class="of lx it ob b gy ps oh l oi oj">    plt.tight_layout()<br/>    plt.show()</span></pre><p id="ac8f" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这导致每层8*8的网格:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pt"><img src="../Images/f60e63182aa78e1c20279b876e7ceaab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FS4KZPRiKIGkJu0X.png"/></div></div></figure><p id="c9f7" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">图像更大，可以快速发现您想要更详细检测的类型。尤其是在笔记本里。提醒一句:如果你在网格中渲染了太多细节太多的图像，在某个时候，你的笔记本会崩溃。</p><h1 id="26ae" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">笔记本电脑显示屏的特性</h1><p id="1f76" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">假设您想要以全尺寸显示每张图片。那么以下内容会有所帮助:</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="63b2" class="of lx it ob b gy og oh l oi oj">for index in range(feature_maps.shape[-1]):<br/>    display(Image.fromarray(np.uint8(feature_maps[0, :, :, index])).convert(<br/>        'RGB').resize(display_size))</span></pre><p id="1e3c" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">这将显示灰度图像。如果你想要一个特定的颜色图，你需要做如下的事情:</p><pre class="kj kk kl km gt oa ob oc od aw oe bi"><span id="10eb" class="of lx it ob b gy og oh l oi oj">from keras.preprocessing.image import img_to_array<br/>from IPython.display import display<br/>from PIL import Image<br/>from matplotlib import cm</span><span id="8122" class="of lx it ob b gy ps oh l oi oj">cmap = cm.get_cmap('hot')<br/>display_size = 1000, 1000</span><span id="7edc" class="of lx it ob b gy ps oh l oi oj">for index in range(feature_maps.shape[-1]):<br/>    im = Image.fromarray(np.uint8(feature_maps[0, :, :, index])).convert('L').resize(display_size)<br/>    im = np.array(im)<br/>    im = cmap(im)<br/>    im = np.uint8(im * 255)<br/>    im = Image.fromarray(im).resize(display_size)<br/>    display(im)</span></pre><p id="abf3" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">滚动浏览它们看起来像这样(作为. gif文件):</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pu"><img src="../Images/e15d30b1179e841323b8728d52cef4a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*2N6yVKkXUgYLk082.gif"/></div></div></figure><p id="0056" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">使用调整大小功能，可以以合适的尺寸检查所有图像。</p><h1 id="d0b8" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">奖金——一种神经传递方法</h1><p id="d584" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">在我之前的文章<a class="ae kz" rel="noopener" target="_blank" href="/neural-style-transfer-a-high-level-approach-250d4414c56b">神经类型转移——一种高级方法</a>中，我提供了神经类型转移的概述。使用以下风格图像的想法。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pv"><img src="../Images/8a8f5fb7da4d6eae7b8ba86f3d82757a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*tWq_O27YShhtRRL6"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><em class="ky">来源</em><a class="ae kz" href="https://unsplash.com/photos/Cj8h7-b47ko" rel="noopener ugc nofollow" target="_blank"><em class="ky">https://unsplash.com/photos/Cj8h7-b47ko</em></a><em class="ky">作者约书亚·科尔曼</em></p></figure><p id="7773" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">会产生这样一幅图像:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pw"><img src="../Images/90a7432b08194b431e718032ef06b2a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*jfpg7auxPlHzJbVM7zq6EQ.gif"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">神经类型转移</p></figure><h1 id="f3a6" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">灵感</h1><p id="8d01" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">CNN图层可视化阅读清单(排名不分先后):</p><ul class=""><li id="61df" class="mo mp it lc b ld le lg lh lj nw ln nx lr ny lv mv mw mx my bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/visualising-filters-and-feature-maps-for-deep-learning-d814e13bd671#:~:text=The%20feature%20maps%20of%20a,what%20features%20our%20CNN%20detects">https://towards data science . com/visualizing-filters-and-feature-maps-for-deep-learning-d 814 e 13 BD 671 #:~:text = The % 20 feature % 20 maps % 20 of % 20a，what % 20 features % 20 our % 20 CNN % 20 detects</a>。</li><li id="fb1a" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/extract-features-visualize-filters-and-feature-maps-in-vgg16-and-vgg19-cnn-models-d2da6333edd0">https://towards data science . com/extract-features-visualize-filters-and-feature-maps-in-vgg 16-and-vgg 19-CNN-models-d2da 6333 edd 0</a></li><li id="ce59" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://debuggercafe.com/visualizing-filters-and-feature-maps-in-convolutional-neural-networks-using-pytorch/" rel="noopener ugc nofollow" target="_blank">https://debugger cafe . com/visualizing-filters-and-feature-maps-in-convolutionary-neural-networks-using-py torch/</a></li><li id="2039" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030">https://towards data science . com/how-to-visualize-convolatile-features-in-40-line of-code-70b7d 87 b 0030</a>了解神经网络如何识别某种模式</li><li id="cda9" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated">https://arxiv.org/pdf/1804.11191.pdf<a class="ae kz" href="https://arxiv.org/pdf/1804.11191.pdf" rel="noopener ugc nofollow" target="_blank">卷积网络如何看待世界</a></li><li id="09f6" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated">【https://www.deeplearningbook.org/contents/convnets.html T4】</li><li id="a5b8" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://www.analyticsvidhya.com/blog/2019/05/understanding-visualizing-neural-networks/" rel="noopener ugc nofollow" target="_blank">https://www . analyticsvidhya . com/blog/2019/05/understanding-visualizing-neural-networks/</a></li><li id="72b4" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" rel="noopener" target="_blank" href="/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c">https://towards data science . com/convolutionary-neural-network-feature-map-and-filter-visualization-f 75012 a5 a49c</a></li></ul><h1 id="83f3" class="lw lx it bd ly lz ma mb mc md me mf mg jz mh ka mi kc mj kd mk kf ml kg mm mn bi translated">关于</h1><p id="0e94" class="pw-post-body-paragraph la lb it lc b ld mq ju lf lg mr jx li lj ne ll lm ln nf lp lq lr ng lt lu lv im bi translated">丹尼尔是一名企业家、软件开发人员和商业法毕业生。他曾在各种IT公司、税务咨询、管理咨询和奥地利法院工作。</p><p id="4f61" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">他的知识和兴趣目前围绕着编程机器学习应用程序及其所有相关方面。从本质上说，他认为自己是复杂环境的问题解决者，这在他的各种项目中都有所体现。</p><p id="4888" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">如果您有想法、项目或问题，请不要犹豫与我们联系。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi px"><img src="../Images/001f7429b362782fdf8ebd56e0e0aa8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*vVd2kEr5CMB7rmlW.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">你可以在<a class="ae kz" href="https://www.buymeacoffee.com/createdd" rel="noopener ugc nofollow" target="_blank">https://www.buymeacoffee.com/createdd</a>上支持我</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi py"><img src="../Images/200fd8ce634f1d996da4532bdfd7230a.png" data-original-src="https://miro.medium.com/v2/resize:fit:920/0*qQCVlYOg2PZyzZtf"/></div></figure><p id="5473" class="pw-post-body-paragraph la lb it lc b ld le ju lf lg lh jx li lj lk ll lm ln lo lp lq lr ls lt lu lv im bi translated">连接到:</p><ul class=""><li id="9eae" class="mo mp it lc b ld le lg lh lj nw ln nx lr ny lv mv mw mx my bi translated"><a class="ae kz" href="https://www.linkedin.com/in/createdd" rel="noopener ugc nofollow" target="_blank">领英</a></li><li id="18f1" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://github.com/Createdd" rel="noopener ugc nofollow" target="_blank"> Github </a></li><li id="79ce" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://medium.com/@createdd" rel="noopener">中等</a></li><li id="bc52" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://twitter.com/_createdd" rel="noopener ugc nofollow" target="_blank">推特</a></li><li id="0e49" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated">Instagram </li><li id="21fe" class="mo mp it lc b ld mz lg na lj nb ln nc lr nd lv mv mw mx my bi translated"><a class="ae kz" href="https://www.createdd.com/" rel="noopener ugc nofollow" target="_blank">createdd.com</a></li></ul></div></div>    
</body>
</html>