<html>
<head>
<title>How to Decide on Learning Rate</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何决定学习速度</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-decide-on-learning-rate-6b6996510c98?source=collection_archive---------9-----------------------#2020-11-14">https://towardsdatascience.com/how-to-decide-on-learning-rate-6b6996510c98?source=collection_archive---------9-----------------------#2020-11-14</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="4a2d" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">使用PyTorch Lightning为您的神经网络找到好的LR</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/14e0852e2acb20440a0b34cc34921878.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JcS9S73xC5nxOz9mlXpq4Q.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">用PyTorch Lightning为你的神经网络寻找LR(图片由作者提供)</p></figure><p id="284f" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">在机器学习算法中使用的所有超参数中，学习率可能是你最先了解的一个参数。很有可能这也是你开始玩的第一个。通过一点超参数优化，有机会找到最佳值，但这需要大量的实验。那么，为什么不让您的工具来做这件事(更快)？</p><h1 id="0785" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">了解学习速度</h1><p id="4ea2" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">对什么是学习率的最简短的解释是，它控制着你的网络(或任何算法)学习的速度。如果你还记得<a class="ae mo" href="https://en.wikipedia.org/wiki/Supervised_learning" rel="noopener ugc nofollow" target="_blank">监督学习</a>是如何工作的，你应该熟悉神经网络的概念，它根据监督人的反应来适应问题，例如:</p><ul class=""><li id="f77b" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated"><em class="my">错误类别</em>——对于分类任务，</li><li id="3098" class="mp mq iq kx b ky mz lb na le nb li nc lm nd lq mu mv mw mx bi translated"><em class="my">输出值过低/过高</em> —用于回归问题。</li></ul><p id="b237" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">由于这一点，它可以迭代地给出越来越准确的答案。每当它收到来自主管的反馈时，它就会知道正确的答案应该是什么。而学习率控制了响应于最近的错误(反馈)而改变模型感知的程度。</p><h2 id="8db5" class="ne ls iq bd lt nf ng dn lx nh ni dp mb le nj nk md li nl nm mf lm nn no mh np bi translated">好的学习率，差的学习率</h2><p id="86f6" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">如果存在我们所寻求的“好的学习率”，“坏的学习”是否也存在？这意味着什么？让我坚持监督学习的概念，讨论一个微不足道的例子:</p><ul class=""><li id="7811" class="mp mq iq kx b ky kz lb lc le mr li ms lm mt lq mu mv mw mx bi translated">我们在玩“猜数字”游戏，</li><li id="c765" class="mp mq iq kx b ky mz lb na le nb li nc lm nd lq mu mv mw mx bi translated">每猜错一次，你都会得到一个回应:<em class="my">【太低】</em>或者<em class="my">【太高】</em>。</li></ul><p id="d682" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">虽然这不是一个真正的神经网络的例子，让我们想象一下如何玩这个游戏，让我们假设这次不是纯粹的随机猜测。</p><p id="3c91" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">每次你得到反馈时，你是愿意向正确答案迈出一小步还是一大步？虽然这个例子不是真正关于神经网络或机器学习，但这本质上是学习率如何工作的。</p><p id="5ffb" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，想象一下，只迈出很小的一步，每一步都让你更接近正确的数字。这能行吗？当然了。然而，这真的需要一些时间，直到你到达那里。这是<strong class="kx ir">小学习率</strong>的情况。在机器学习的背景下，LR太小的模型学习速度会很慢，并且需要更多的迭代来解决问题。有时你可能已经决定在训练结束前停止训练(或者玩猜数字游戏)。</p><p id="b8e7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你也可以选择一个太大的值。然后呢？例如，它可能会导致神经网络<strong class="kx ir">过多地</strong>(并且过于频繁地)改变它的想法。每一个新的样本都会对你的网络信仰产生巨大的影响。这样的训练会<strong class="kx ir">高度不稳定</strong>。它不再是一个学习缓慢的人，但它可能更糟糕:你的模型可能最终没有学到任何有用的东西。</p><h1 id="22ca" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">学习率范围测试</h1><p id="996f" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">Leslie N. Smith在2015年撰写的论文<a class="ae mo" href="https://arxiv.org/abs/1506.01186" rel="noopener ugc nofollow" target="_blank"> <em class="my">《训练神经网络的循环学习率》</em> </a>引入了一个循环学习率的概念——在训练过程中轮流增加和减少。然而，论文中提到了一件重要的事情，即所谓的“LR范围测试”(第3.3节)。</p><p id="0710" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">整个事情相对简单:我们运行一个短的(几个时期)训练会话，其中在两个边界值 <code class="fe nq nr ns nt b">min_lr</code>和<code class="fe nq nr ns nt b">max_lr</code>之间<strong class="kx ir">学习率增加</strong>(线性)<strong class="kx ir">。在开始时，学习率小，网络将开始慢慢收敛，导致损失值越来越低。在某些时候，学习率会变得太大，导致网络发散。</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nu"><img src="../Images/a9c08893160f1548c3161a3373808b0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:982/format:webp/0*appyn_bsB4n3bQOI.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nv">图一。lr_find方法建议的学习率(图片由作者提供)</em></p></figure><p id="52f7" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果您绘制损失值与测试学习率的关系图(图1。)，你通常会在最陡下降损失曲线中间的某个地方<strong class="kx ir">寻找学习的最佳初始值——这仍然可以让你使用学习速率调度器减少一点LR。在图1中。当损耗在LR 0.001和0.1之间开始显著下降时，红点表示PyTorch Lightning框架选择的最佳值。</strong></p><h1 id="7388" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">在PyTorch闪电中寻找LR</h1><p id="89b5" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">最近PyTorch Lightning成为我短期机器学习项目的首选工具。几个月前我第一次使用它，从那以后我一直在使用它。除了所有很酷的东西，它还提供了<a class="ae mo" href="https://pytorch-lightning.readthedocs.io/en/latest/lr_finder.html" rel="noopener ugc nofollow" target="_blank">学习率查找器</a>类，帮助我们找到一个好的学习率。</p><p id="5601" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">使用LR Finder无非是<em class="my">训练器</em>类中的<em class="my"> auto_lr_find </em>参数:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="e057" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">现在，当你调用<code class="fe nq nr ns nt b">trainer.fit</code>方法时，它在下面执行学习率范围测试，找到一个好的初始学习率，然后直接训练(拟合)你的模型。因此，基本上这一切都是在<code class="fe nq nr ns nt b">fit</code>通话中自动发生的，你完全不用担心。</p><p id="6b02" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如<a class="ae mo" href="https://pytorch-lightning.readthedocs.io/en/latest/lr_finder.html" rel="noopener ugc nofollow" target="_blank">文档</a>中所述，有一种替代方法允许您手动使用LR Finder并检查其结果。这一次你必须创建一个默认值为<code class="fe nq nr ns nt b">auto_lr_find</code> (False)的<code class="fe nq nr ns nt b">Trainer</code>对象，并手动调用<code class="fe nq nr ns nt b">lr_find</code>方法:</p><figure class="kg kh ki kj gt kk"><div class="bz fp l di"><div class="nw nx l"/></div></figure><p id="39cf" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">仅此而已。这种方法的主要优点是，您可以更仔细地查看显示选择了哪个值的图(参见图1。).</p><h1 id="8ab9" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">例如:时尚MNIST的LR搜索器</h1><p id="3a61" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">我决定在时尚MNIST数据集上训练一个相当简单的网络架构。我运行了四个<strong class="kx ir">独立的实验，它们的不同之处仅在于初始学习率</strong>值。其中三个是亲手挑选的(1e-5、1e-4、1e-1)，最后一个是Learning Rate Finder建议的。整个实现和其他参数我就不描述了(自己看<a class="ae mo" href="https://github.com/mtszkw" rel="noopener ugc nofollow" target="_blank">这里</a>)。让我给你看看我的发现。</p><p id="3a23" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">大概用了12秒(！)来找到最佳的初始学习率，对于我的网络和正在解决的问题，结果是0.0363。看着loss versusLR图(完全是图1中的图)，我很惊讶，因为建议的点并不完全是<em class="my">“最陡下坡的中途”</em>(如论文中所述)。然而，我不知道这是好是坏，所以开始训练模型。</p><p id="21ec" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">为了记录和可视化，我使用TensorBoard来记录训练和验证步骤中的损失和准确性。下面您可以看到四个实验中每个实验的指标历史。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ny"><img src="../Images/d2116c4efbfb0208f117f2edd440c67d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qiisCW-CyUD7fUL2.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nv">图二。培训和验证。对于4个实验(图片由作者提供)</em></p></figure><p id="81fd" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">闪电(浅蓝色)建议的学习率似乎在训练和验证阶段都优于其他值。最后，它在验证集上达到88，85%的准确率，这是所有实验的最高分(<em class="my">图2 </em>)。不仅如此，损失函数值显然是“find_lr”实验的最佳值。在最后一个验证步骤中，损失达到0.3091，这是与图3 中的其他曲线相比的最低值。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nz"><img src="../Images/743c82726d66bd4f1d4a1fa216303420.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*zrKDGvNrW4vXviHJ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated"><em class="nv">图三。4个实验的训练和验证损失(图片由作者提供)</em></p></figure><h1 id="a2ac" class="lr ls iq bd lt lu lv lw lx ly lz ma mb jw mc jx md jz me ka mf kc mg kd mh mi bi translated">结论</h1><p id="d3e5" class="pw-post-body-paragraph kv kw iq kx b ky mj jr la lb mk ju ld le ml lg lh li mm lk ll lm mn lo lp lq ij bi translated">在这个短暂的实验中，学习率查找器的表现超过了我亲手挑选的学习率。当然，有可能我会选择0.0363作为我最初的猜测，但是<strong class="kx ir">LR Finder的整个要点是最小化所有的猜测</strong>(除非你是一个幸运的人)。</p><p id="c13c" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">我认为使用这个功能是有用的，正如莱斯利·n·史密斯所写的:</p><blockquote class="oa ob oc"><p id="ccdc" class="kv kw my kx b ky kz jr la lb lc ju ld od lf lg lh oe lj lk ll of ln lo lp lq ij bi translated">每当一个人开始一个新的架构或数据集，一个单一的LR范围测试提供了良好的LR值和良好的范围。那么应该比较具有固定LR的运行和具有该范围的CLR。无论哪一次获胜，都可以放心地用于余下的实验。</p></blockquote><p id="12e2" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">如果你不想使用不同的值来执行超参数搜索，这可能需要很长时间，<strong class="kx ir">你有两个选择</strong>:随机选择初始值(这可能会让你的性能和收敛性非常差，但如果你是一个幸运的人，可能会工作得很好)或使用你选择的机器学习框架中包含的学习率查找器。</p><p id="d7da" class="pw-post-body-paragraph kv kw iq kx b ky kz jr la lb lc ju ld le lf lg lh li lj lk ll lm ln lo lp lq ij bi translated">你会选哪一个？</p></div></div>    
</body>
</html>