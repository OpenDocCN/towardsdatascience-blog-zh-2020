<html>
<head>
<title>Text Vectorization: Term Frequency — Inverse Document Frequency (TFIDF)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">文本矢量化:词频—逆文档频率(TFIDF)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/text-vectorization-term-frequency-inverse-document-frequency-tfidf-5a3f9604da6d?source=collection_archive---------6-----------------------#2020-10-04">https://towardsdatascience.com/text-vectorization-term-frequency-inverse-document-frequency-tfidf-5a3f9604da6d?source=collection_archive---------6-----------------------#2020-10-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="2ebd" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">一种将文本转换成有限长度向量的技术</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/c59c6123e115354180e1bb30024ed25e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ug7ZvOXwIgdZgJykCeqBUA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由<a class="ae kv" href="https://www.pexels.com/photo/black-and-white-design-text-wall-241832/" rel="noopener ugc nofollow" target="_blank">赫尔曼</a>(左)和<a class="ae kv" href="https://unsplash.com/photos/faixctm2YRQ" rel="noopener ugc nofollow" target="_blank">泰勒·伊斯顿</a>(右)拍摄</p></figure><p id="550f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">单词包(BoW)通过计算文档中单词的出现次数将文本转换为特征向量。它没有考虑到文字的重要性。<strong class="ky ir">词频—逆文档频率(TFIDF) </strong>基于词袋(BoW)模型，该模型包含关于文档中不太相关和更相关的词的见解。文本中一个词的重要性在信息检索中具有重要意义。</p><p id="4835" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">例</strong> —如果你在搜索引擎上搜索某个东西，借助TFIDF值，搜索引擎可以给我们与我们的搜索最相关的文档。</p><p id="fab7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将详细讨论TFIDF如何告诉我们哪个单词更重要？我们将首先分别研究术语频率(TF)和逆文档频率(IDF ),然后在最后将它们结合起来。</p><h2 id="558a" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">术语频率(TF)</h2><p id="16ce" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">它是一个单词(w)在文档(d)中出现频率的度量。TF被定义为单词在文档中出现的次数与文档中单词总数的比率。公式中的分母项是归一化，因为所有语料库文档的长度都不同。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mq"><img src="../Images/38053c1533e605e41c400d187eb85d56.png" data-original-src="https://miro.medium.com/v2/resize:fit:934/format:webp/1*SphmlJiMjjpHFjAuZRJDqA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="0344" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">例子</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/7087130dd5536997025cd66034160686.png" data-original-src="https://miro.medium.com/v2/resize:fit:1116/format:webp/1*-0g0HFp9BKdgYSJOUhlKOA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="6ae8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">第一步是制作一个独特单词的词汇表，并计算每个文档的TF。TF对于频繁出现在文档中的单词会更大，而对于文档中不常见的单词会更小。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ms"><img src="../Images/4dde4defa6655f97d9b6ac0dd2656dda.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*ZXVW1MFpPGOgDne8spdawA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="7fdd" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">反向文档频率(IDF)</h2><p id="18bf" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">它是衡量一个单词重要性的标准。词频(TF)不考虑词的重要性。有些词如of、and等。可能最常见，但意义不大。IDF基于每个单词在语料库d中的频率为其提供权重</p><p id="13cd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">单词(w)的IDF定义为</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mt"><img src="../Images/d2696fd8a5271cb531038a0d958a095d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1082/format:webp/1*sMAGjYvUyPNMmx5zA9qo0g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="c2aa" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在我们的例子中，由于语料库中有两个文档，N=2。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mu"><img src="../Images/1326e8ba2c33bd1bfe41f3e13c338cbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1350/format:webp/1*owBBWicmILMFw7gHvE5rzw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><h2 id="acf6" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">术语频率—反向文档频率(TFIDF)</h2><p id="6542" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">它是TF和IDF的产物。</p><ul class=""><li id="219c" class="mv mw iq ky b kz la lc ld lf mx lj my ln mz lr na nb nc nd bi translated">TFIDF给予语料库(所有文档)中不常见的单词更多的权重。</li><li id="9d92" class="mv mw iq ky b kz ne lc nf lf ng lj nh ln ni lr na nb nc nd bi translated">TFIDF为在文档中出现频率较高的单词提供了更高的重要性。</li></ul><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nj"><img src="../Images/7718b9096a93978540ae19bbbe48cbe6.png" data-original-src="https://miro.medium.com/v2/resize:fit:716/format:webp/1*fKWpB082SSPWQWEn_2NSSw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi nk"><img src="../Images/40f91d2b091381f0454a7751f885f512.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FCG4RqeoOIdttCVHh9qxcA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="9a7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">应用TFIDF后，A和B文档中的文本可以表示为一个TFIDF向量，其维数等于词汇表中的单词。对应于每个单词的值表示该单词在特定文档中的重要性。</p><p id="6732" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">为什么我们在IDF公式中使用Ln？</strong></p><p id="d3fb" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TFIDF是TF与IDF的产物。由于TF值介于0和1之间，因此不使用ln会导致某些单词的高IDF，从而支配TFIDF。我们不希望这样，因此，我们使用<strong class="ky ir"> ln </strong>，这样IDF就不会完全控制TFIDF。</p><h2 id="f2b0" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">TFIDF的缺点</h2><p id="bfb8" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">它无法捕捉到<strong class="ky ir">语义</strong>。例如，<strong class="ky ir">滑稽</strong>和<strong class="ky ir">幽默</strong>是同义词，但是TFIDF没有抓住这一点。此外，如果词汇表很大，TFIDF的计算开销会很大。</p><h2 id="e821" class="ls lt iq bd lu lv lw dn lx ly lz dp ma lf mb mc md lj me mf mg ln mh mi mj mk bi translated">结论</h2><p id="788d" class="pw-post-body-paragraph kw kx iq ky b kz ml jr lb lc mm ju le lf mn lh li lj mo ll lm ln mp lp lq lr ij bi translated">词频—逆文档频率(TFIDF)是一种基于词袋(BoW)模型的文本矢量化技术。它比BoW模型表现得更好，因为它考虑了单词在文档中的重要性。主要的限制是它不能捕捉单词的语义。TFIDF的这种局限性可以通过word2Vec等更高级的技术来克服。</p><p id="cc65" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">感谢阅读！</p></div></div>    
</body>
</html>