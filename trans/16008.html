<html>
<head>
<title>What is attention mechanism?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是注意机制？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/what-is-attention-mechanism-can-i-have-your-attention-please-3333637f2eac?source=collection_archive---------6-----------------------#2020-11-04">https://towardsdatascience.com/what-is-attention-mechanism-can-i-have-your-attention-please-3333637f2eac?source=collection_archive---------6-----------------------#2020-11-04</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="9a06" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated"><em class="ki">解决Seq2Seq问题技术的演变，从RNN到自我关注</em></h2></div><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi kj"><img src="../Images/71f57761cc40c4a459be670db6c3ff21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*DoWSdZA3dND9_Xq0rStQFw.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="cee9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在整篇文章中，我们将首先了解我们所使用的技术的局限性，然后介绍新的机制来克服他们所面临的问题。我们将了解以下几个部分:</p><ul class=""><li id="408c" class="lr ls it kx b ky kz lb lc le lt li lu lm lv lq lw lx ly lz bi translated"><strong class="kx iu">编码器解码器，瓶颈问题</strong></li><li id="5acd" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx iu">注意机制</strong></li><li id="e956" class="lr ls it kx b ky ma lb mb le mc li md lm me lq lw lx ly lz bi translated"><strong class="kx iu">自我关注</strong></li></ul><h1 id="e968" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak"> 1 —编码器解码器，瓶颈问题</strong></h1><p id="e07a" class="pw-post-body-paragraph kv kw it kx b ky mx ju la lb my jx ld le mz lg lh li na lk ll lm nb lo lp lq im bi translated">编码器解码器架构<a class="ae nc" href="https://medium.com/swlh/introduction-to-recurrent-neural-networks-rnn-c2374305a630" rel="noopener">由RNN </a>构建，广泛用于神经机器翻译(NMT)和序列到序列(Seq2Seq)预测。它的主要好处是我们可以<strong class="kx iu">分离编码器和解码器，所以它们有不同的长度。</strong></p><p id="9aac" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">例如，具有不同序列长度的模型是接收单词序列并输出数字的情感分析，或者输入是图像而输出是单词序列的图像字幕模型。这种架构非常强大，甚至谷歌都将其作为谷歌翻译的核心技术。</p><p id="b84e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在下图中，我们可以看到一个翻译示例的模型:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nd"><img src="../Images/146590d3fcbcedbf3ca145b5c30daa5c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NhzTb2Wcp4rQThL3J_TzgA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="02f7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们用一个输入层和一个递归神经网络(RNN)更准确地说是一个长短期记忆(LSTM)构建了<strong class="kx iu">编码器</strong>(蓝色矩形)。编码器接收西班牙语句子，并且<strong class="kx iu">输出单个向量</strong>,该向量是最后一个LSTM时间步长的隐藏状态，整个句子的含义在该向量中被捕获。然后<strong class="kx iu">解码器</strong>接收这个隐藏状态作为输入，并返回一个单词序列，即英语翻译。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ni"><img src="../Images/0e3e432616481383d6032f08a6f2413c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Ga4lrRx6kl4VRFYd0ZJVMQ.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者提供:编码过程中，输出的是隐藏状态的最后一个时间步。</p></figure><p id="8c72" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这种架构已经展示了它在Seq2Seq问题上的巨大能力，然而它也有一个重要的限制。正如我们已经说过的，所有输入句子的含义都是在一个向量中捕获的，所以<strong class="kx iu">随着句子长度的增加，模型捕获这个向量中的信息就越困难。</strong>因此，它的性能随着长句而下降，因为它倾向于忘记部分长句，<strong class="kx iu">隐藏向量成为瓶颈。</strong></p><p id="ea69" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">注意机制</strong>建立在我们刚刚分析过的编码器解码器结构之上。存在两个主要的差异，我们将在下面的章节中进行分析</p><h1 id="e883" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated">2—隐藏状态的St<strong class="ak">ack</strong></h1><p id="0242" class="pw-post-body-paragraph kv kw it kx b ky mx ju la lb my jx ld le mz lg lh li na lk ll lm nb lo lp lq im bi translated">在前面的结构中，我们只是传递了上一个时间步的隐藏状态。有了这个新的结构<strong class="kx iu">,我们保持了每个时间步的所有隐藏状态。</strong></p><p id="cbd8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如我们在下图中看到的，以前编码器的输出是一个向量，<strong class="kx iu">我们现在有一个由每个隐藏状态</strong>组成的矩阵。这解决了只有一个向量没有足够信息的问题，但它也增加了完全相反的问题，太多的信息。对于解码器想要翻译的每个单词，它不需要完整的矩阵，因为不是所有的单词都提供相关信息，所以解码器如何知道应该关注矩阵的哪一部分或对给予更多<strong class="kx iu">关注？</strong></p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi kj"><img src="../Images/71f57761cc40c4a459be670db6c3ff21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*DoWSdZA3dND9_Xq0rStQFw.gif"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="f1f5" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当人类描述一幅图像时，我们并不把它作为一个整体来分析，而是检查图像的相关部分，并关注我们所描述的内容。一个机器学习模型是如何关注的？</p><p id="fe2d" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">完全一样的方式。注意机制的一个很好的例子可以在论文“<a class="ae nc" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank"> <em class="nj">显示、出席和讲述</em> </a>”中找到。这里我们有一个图像作为输入，目标是生成一个描述它的句子。在下图中，我们有一个热图，显示了模型在生成单词时更关注的地方，白色区域越多，关注越多，黑色区域越少。</p><p id="3fad" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">当它描述鸟时，注意力集中在动物身上(白色部分)，而当它描述水时，注意力从动物转移到它的周围。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nk"><img src="../Images/22d9e7be21dc6df49c3d165321e2da11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xNJNole5unXqrmKz7p0Y4g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:模型架构</p></figure><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi nl"><img src="../Images/fa00fd7f5f83c3f1c1e9a703480f6131.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*I20hbdjpdCKEgH1SRVFZKQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:显示模型关注的地方。图片来自<a class="ae nc" href="https://arxiv.org/abs/1502.03044" rel="noopener ugc nofollow" target="_blank">“展示、参与和讲述”</a></p></figure><p id="67b3" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">另一个例子可以在Bzmitry Bahdanau等人于2015年发表的论文<a class="ae nc" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank">‘通过联合学习对齐和翻译进行神经机器翻译’</a>中找到。让我们分析下面的热图，它显示了模型在翻译句子时更关注的地方:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nm"><img src="../Images/f92d1285d5c4a1d353ef8dcce334520e.png" data-original-src="https://miro.medium.com/v2/resize:fit:964/format:webp/1*Bg_Hg0p9ta4l95c5DvsqWA.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2:图片来自<a class="ae nc" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank">“通过联合学习对齐和翻译的神经机器翻译”</a></p></figure><p id="e97c" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">x轴对应于英语的源句子，y轴对应于生成的法语翻译。每个像素显示了模型转移注意力的地方，区域越白，注意力越集中，区域越暗，注意力越少(就像前面的例子)。</p><p id="57a9" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">例如，为了生成单词“accord ”,它主要关注“agreement”。当模型将“欧洲经济区”转换为“欧洲经济区”时，我们可以看到关注机制的力量。在英语中，形容词用在名词之前，而在法语中，形容词在名词之后，所以在这种情况下，模型将注意力转移到后面出现的单词。</p><p id="751f" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">关键问题是，<strong class="kx iu">模型如何知道关注哪里</strong>？它计算出一个被称为<strong class="kx iu">对齐分数</strong>的分数，该分数量化了我们应该给予每个输入多少关注。<strong class="kx iu">存在多种比对分数</strong>，最流行的是加法(也称为concat，<a class="ae nc" href="https://arxiv.org/abs/1409.0473" rel="noopener ugc nofollow" target="_blank"> Bahdanau et al 2015 </a>)、位置基、一般和点积(<a class="ae nc" href="https://arxiv.org/abs/1508.04025" rel="noopener ugc nofollow" target="_blank"> Luong 2015 </a>)。这种区别导致了更广泛的类别，如全局/软和局部/硬注意。</p><p id="8977" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">我们转移注意力的方式对我们的解释有影响，因此对结果也有影响，我们选择的比对分数函数也有类似的影响。</p><p id="8e2b" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">这种注意机制<strong class="kx iu">在模型</strong>中只能应用一次，它是<strong class="kx iu">连接编码器和解码器</strong>的部件，并允许比较输入和输出句子，如前一幅图像所示。它从编码器<strong class="kx iu">接收隐藏状态矩阵</strong>并根据需要注意的对齐分数进行计算，简化表示如下:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi nn"><img src="../Images/eebb9b1810b0758a78a8ec077758e9a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1296/format:webp/1*OI-6mRsz9gdDGQanAu5idA.jpeg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片:模型架构</p></figure><h1 id="be17" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak"> 3 —自我关注</strong></h1><p id="94b6" class="pw-post-body-paragraph kv kw it kx b ky mx ju la lb my jx ld le mz lg lh li na lk ll lm nb lo lp lq im bi translated">2017年，在谷歌团队的论文'<a class="ae nc" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">关注是你所需要的'</a>中，他们介绍了一种称为变压器的新型架构，这也是变压器<a class="ae nc" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank"> (BERT) </a>双向编码器表示的种子。</p><p id="602a" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这篇论文中，他们提出了<strong class="kx iu">我们已经分析过的先前架构</strong>的两个主要变化。首先，他们把RNN从照片中去掉。第二，他们增加了自我关注机制。在下一节中，我们将分析这两个决定及其含义。</p><h2 id="fe1b" class="no mg it bd mh np nq dn ml nr ns dp mp le nt nu mr li nv nw mt lm nx ny mv nz bi translated"><strong class="ak">谢谢你载了RNN </strong></h2><p id="b5a0" class="pw-post-body-paragraph kv kw it kx b ky mx ju la lb my jx ld le mz lg lh li na lk ll lm nb lo lp lq im bi translated">如果RNN在NLP任务中表现得如此出色，我们为什么要取消它呢？<strong class="kx iu"> RNN按顺序工作，</strong>这意味着为了计算句子的第二个单词(第二时间步)，我们需要计算第一个隐藏向量(第一时间步)。然后为了计算隐藏状态，时间t，你必须一直等待t-1的结果，<strong class="kx iu">，所以我们不能并行化</strong>。此外，RNN意味着大量的计算需要大量的资源。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ni"><img src="../Images/0e3e432616481383d6032f08a6f2413c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*Ga4lrRx6kl4VRFYd0ZJVMQ.gif"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片由作者提供，要处理单词“camino”我们必须首先计算“Estoy”和“de”</p></figure><p id="0566" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">此外，注意力RNN已经改善了对较长句子的时间依赖的提取，但仍然与长序列作斗争，所以我们还没有完全解决这个问题。</p><p id="d086" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><strong class="kx iu">如果我们没有RNN，模型结构是什么？</strong>为了更好地理解这款新车型，我们来看看下图:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oa"><img src="../Images/c9b2cf8432816116a48886ca2e4290c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xxattlvK_SYjwT_jRiIHJA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="12b0" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">正如我们可以看到的<strong class="kx iu">我们保留了编码器解码器</strong>、<strong class="kx iu">的结构，但是我们不再有相互连接的注意力机制</strong>。那么注意力机制是从哪里计算出来的呢？如果我们没有RNN，编码器和解码器里面是什么？</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi ob"><img src="../Images/e6b9120d509cd20c18139f8ff7eb84a9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Kk8BZGn618s0MZC-xDJHxg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="bdac" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">编码组件是一堆编码器，这些编码器共享相同的内部结构。本文提出的模型由6个编码器构成，解码器也是如此。</p><p id="5dda" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们来探索这些组件:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div role="button" tabindex="0" class="ne nf di ng bf nh"><div class="gh gi oc"><img src="../Images/156fbbd1d58134e714fb87a0c9c753e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3FTmK2TdiMiKYs1URi0PAg.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者图片</p></figure><p id="7cab" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">让我们首先关注编码器，它由两层组成<strong class="kx iu">自关注机制(我们将在后面探讨)和前馈网络</strong>。每个编码器都有这两层，所以如果我们之前说我们堆叠了6个编码器，那么我们在编码阶段就有6个自关注机制。<strong class="kx iu">这意味着我们并不局限于应用一次注意机制，而是可以应用我们所拥有的层数。</strong></p><p id="8224" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">解码器共享相同的层，并增加了一层称为<strong class="kx iu">编码器-解码器注意</strong>的层，我们可以将这一层视为第二节中使用的注意机制(attention mechanism)来连接编码器和解码器。</p><p id="52c7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated"><em class="nj">这篇文章的目的是关注注意力机制，如果你想更好地了解变形金刚，我推荐下面这篇文章</em> <a class="ae nc" href="http://jalammar.github.io/illustrated-transformer/" rel="noopener ugc nofollow" target="_blank"> <em class="nj">。</em> </a></p><p id="8e3e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">由于新的结构，模型可以并行化，所需的计算对资源的要求更低，从而大大提高了训练性能，这是深度学习中的关键任务。此外，无论句子有多长，它都可以从整个句子中提取时间依存关系。那么，这种新的突破技术是如何工作的呢？</p><h2 id="f5ea" class="no mg it bd mh np nq dn ml nr ns dp mp le nt nu mr li nv nw mt lm nx ny mv nz bi translated"><strong class="ak">自我关注</strong></h2><p id="6417" class="pw-post-body-paragraph kv kw it kx b ky mx ju la lb my jx ld le mz lg lh li na lk ll lm nb lo lp lq im bi translated">虽然之前我们使用注意机制来连接编码器和解码器，但是这里我们使用注意机制来<strong class="kx iu">计算同一个句子</strong>的单词之间的依赖关系，输入的句子<strong class="kx iu">的单词相互作用(自身)</strong>。在下图中，我们可以看到一个翻译结果的示例，更准确地说，我们关注的是5号编码器:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi od"><img src="../Images/980e9496d2a9d2181729e4d2c2321f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*xbBFNEJQ5MMvYTMZgAXbWg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自以下<a class="ae nc" href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="ed22" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这张图片中，我们看到同一个句子出现了两次。当模型翻译单词“it”时，它需要注意相关的单词并提取其含义，这个单词是指动物还是街道？在本例中，我们选择单词“it”(右栏)，它会突出显示更关注的单词(左栏)，在本例中是“the”和“animal”。颜色越深，模特就越关注这个特定的单词。</p><p id="a971" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">虽然之前我们计算了输入和输出句子之间的注意机制(图1，图2 ),但这里我们计算的是句子和句子本身之间的注意。</p><h2 id="1d07" class="no mg it bd mh np nq dn ml nr ns dp mp le nt nu mr li nv nw mt lm nx ny mv nz bi translated"><strong class="ak">多头关注</strong></h2><p id="1605" class="pw-post-body-paragraph kv kw it kx b ky mx ju la lb my jx ld le mz lg lh li na lk ll lm nb lo lp lq im bi translated">论文不断对模型进行微调，并增加了多头关注。</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi od"><img src="../Images/980e9496d2a9d2181729e4d2c2321f52.png" data-original-src="https://miro.medium.com/v2/resize:fit:870/format:webp/1*xbBFNEJQ5MMvYTMZgAXbWg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自下面的<a class="ae nc" href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="dd2e" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">从这个例子中我们知道单词“它”指的是动物，但是这个动物会发生什么呢？只有一个子空间，我们无法提取这么多的意义，这就是多头注意力的来源:</p><figure class="kk kl km kn gt ko gh gi paragraph-image"><div class="gh gi oe"><img src="../Images/4c73c5368deaa7b4bb24ae6cdc26d75f.png" data-original-src="https://miro.medium.com/v2/resize:fit:880/format:webp/1*h9X9b_UH0MGvjrIWSk8IFQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图片来自下面的<a class="ae nc" href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb" rel="noopener ugc nofollow" target="_blank">链接</a></p></figure><p id="f8c7" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">在这张图片中，我们现在有两个头或子空间(橙色和绿色)，颜色越强，它越受关注。从第一个子空间我们知道“它”指的是动物，从第二个子空间我们知道动物“累了”。<strong class="kx iu">多头是在自我注意机制中增加维度或子空间的概念，以获取更多的意义</strong>，在本文中他们使用了8个头。</p><h1 id="26a0" class="mf mg it bd mh mi mj mk ml mm mn mo mp jz mq ka mr kc ms kd mt kf mu kg mv mw bi translated"><strong class="ak">结论</strong></h1><p id="e536" class="pw-post-body-paragraph kv kw it kx b ky mx ju la lb my jx ld le mz lg lh li na lk ll lm nb lo lp lq im bi translated">通过这篇文章，我们分析了注意机制的演变。我们从使用RNN和编码器解码器结构来解决Seq2Seq问题开始。这些模型的问题是<strong class="kx iu">瓶颈</strong>，我们期望在一个隐藏状态中提取句子的全部意思。</p><p id="2ab8" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">为了解决这个问题，<strong class="kx iu">我们保留了编码器的所有隐藏状态</strong>但是现在信息太多，所以<strong class="kx iu">我们需要注意相关部分</strong>。这里当我们引入注意机制来连接编码器和解码器时。</p><p id="5014" class="pw-post-body-paragraph kv kw it kx b ky kz ju la lb lc jx ld le lf lg lh li lj lk ll lm ln lo lp lq im bi translated">最后，<strong class="kx iu">变形金刚忽略了RNN </strong>，它主要关注自我注意机制。在这种情况下<strong class="kx iu">注意</strong>不只是用于一次连接编码器和解码器，而是<strong class="kx iu">我们可以多次使用</strong>。而且，自我注意是用来比较一个句子和它自己，而不是输入和输出。</p></div><div class="ab cl of og hx oh" role="separator"><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok ol"/><span class="oi bw bk oj ok"/></div><div class="im in io ip iq"><div class="kk kl km kn gt om"><a rel="noopener follow" target="_blank" href="/how-to-build-an-encoder-decoder-translation-model-using-lstm-with-python-and-keras-a31e9d864b9b"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">如何建立一个编码器解码器翻译模型使用LSTM与Python和Keras。</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">按照这一步一步的指南来建立一个编码器和解码器模型，并创建自己的翻译模型。</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="ow l ox oy oz ov pa kp om"/></div></div></a></div><div class="pb pc gp gr pd om"><a rel="noopener follow" target="_blank" href="/3-reasons-why-i-love-to-be-a-data-scientist-90696ac0d314"><div class="on ab fo"><div class="oo ab op cl cj oq"><h2 class="bd iu gy z fp or fr fs os fu fw is bi translated">我喜欢成为数据科学家的3个原因</h2><div class="ot l"><h3 class="bd b gy z fp or fr fs os fu fw dk translated">这一切都归结于马尔科姆·格拉德威尔在他的书《局外人》中解释的“有意义的工作”的概念。</h3></div><div class="ou l"><p class="bd b dl z fp or fr fs os fu fw dk translated">towardsdatascience.com</p></div></div><div class="ov l"><div class="pe l ox oy oz ov pa kp om"/></div></div></a></div></div></div>    
</body>
</html>