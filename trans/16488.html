<html>
<head>
<title>Using Deep Learning to identify dog breeds</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习识别狗的品种</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/computer-vision-part-2-8e07029955ee?source=collection_archive---------50-----------------------#2020-11-13">https://towardsdatascience.com/computer-vision-part-2-8e07029955ee?source=collection_archive---------50-----------------------#2020-11-13</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><p id="1af9" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">继续我们关于计算机视觉的讨论(关于该领域的详细介绍，请参见<a class="ae kl" href="https://aditya-mehta.medium.com/computer-vision-part-1-774113a2bec5" rel="noopener">这篇</a>文章)我们将建立一个深度学习模型，根据狗的图像将狗分类到120个品种中的一个。为此，我们将使用谷歌的<a class="ae kl" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank">tensor flow</a>Python平台。</p><h1 id="6f66" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">卷积神经网络:蓝图</h1><p id="4ad8" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">在我们建立实际的模型之前，有必要讨论一下卷积神经网络的构建模块。每个模型都是由几个堆叠在一起的“层”组成的，每一层都有特定的功能。我将在下面简要讨论最重要的层的直觉，但是有许多资源提供了关于这些层如何工作以及如何针对特定任务对它们进行微调的更详细的文档(我将从来自<a class="ae kl" href="https://keras.io/api/layers/" rel="noopener ugc nofollow" target="_blank"> Keras </a>的官方文档开始)。</p><ul class=""><li id="cad6" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk lu lv lw lx bi translated"><strong class="jp ir">卷积层<br/> </strong>卷积层用于从图像中提取特征，正如本系列第1部分所讨论的。我们通过指定要从图像中提取多少特征以及要使用的卷积矩阵的大小来设置卷积层。我们不需要告诉模型提取哪些特征:例如，我们不需要告诉它检测边缘和轮廓——模型“学习”这一点，因为它被给予数据进行训练。</li><li id="e220" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated"><strong class="jp ir">汇集层</strong> <br/>汇集层用于通过“汇总”图像特定片段中包含的信息来减少数据的维度。这方面的一个例子是，通过用最大值表示每个线段(我们也可以选择平均值而不是最大值)，将4*4的网格缩减为2*2的网格。池化有两个目的，一是减少维度，二是使模型对要素的确切位置不太敏感，这是我们所希望的，因为我们希望模型能够识别出一个要素，即使它稍微偏于其参考位置的左侧或右侧。</li></ul><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi md"><img src="../Images/d9f0cbfc44f05f399cb42c2e0272d55c.png" data-original-src="https://miro.medium.com/v2/resize:fit:860/format:webp/1*eCVlMc2-wTdq-jmbPW648g.png"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">最大池:<em class="mp">作者图片</em></p></figure><ul class=""><li id="eb93" class="lp lq iq jp b jq jr ju jv jy lr kc ls kg lt kk lu lv lw lx bi translated"><strong class="jp ir">密集层<br/> </strong>密集层由固定数量的“神经元”或细胞组成，它们从卷积层(在CNN的情况下)获取一维输入，并对其进行处理以供进一步使用——这些层的输出要么被前馈到其他密集层，要么用于预测最终输出。例如，如果我们有一个从图像中提取64个特征的卷积层，我们希望使用这些特征来达到我们的预测。我们可以将此信息传递给密集层，例如16个节点。密集层中的每个节点都完全连接到卷积层，即它从所有64个特征中收集信息。然后，每个节点将一组不同的权重应用于来自每个特征的输入，并得出一个“分数”，该分数随后被提供给其他密集层或用于预测结果。</li><li id="ff8b" class="lp lq iq jp b jq ly ju lz jy ma kc mb kg mc kk lu lv lw lx bi translated"><strong class="jp ir">展平和删除层<br/> </strong>卷积层返回2D输出(因为图像被处理为2D网格)，但我们的密集层只接受1D输入。为了允许这些层进行通信，我们需要将这些信息从2D“扁平化”到1D。我们可以通过使用“全局池”来做到这一点，即通过用单个概要图来表示整个图像，或者通过使用“展平”层。<br/>删除层用于防止模型过度拟合数据。例如，丢失率为30%的层将告诉模型每次随机忽略前一层的30%的节点。这意味着，当30%的节点将被随机忽略时，模型必须很好地“概括”以给出准确的输出。</li></ul><p id="d5ed" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated"><strong class="jp ir">过度拟合与欠拟合的快速说明<br/> </strong>理解过度拟合和欠拟合的最佳方式是使用类比。让我们想象一下，我们有三个学生正在准备考试。a的准备包括记忆课程材料，B花了时间去理解概念，而C根本懒得准备。“过拟合”模型就像一个——它“记忆”它所训练的数据集的特征。我们不希望模型过度拟合的原因是，当我们实际上想要对它没有见过的数据使用模型时，它将表现不佳(就像在要求应用他应该已经学习过的概念的考试中一样)。“欠适应”模型就像C——它没有学习训练数据的特征，我们显然不希望这样。理想的模型就像B——它从我们训练它的数据中学习，但能够概括这个数据集的特征，并仍然对新数据做出准确的预测。</p><p id="70af" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">通常，我们会在同一个模型中使用几个卷积层和密集层。一个简单的结构可能如下所示:</p><figure class="me mf mg mh gt mi"><div class="bz fp l di"><div class="mq mr l"/></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">简单的模型结构</p></figure><h1 id="d310" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">数据</h1><p id="c768" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">我们将使用10，000多张属于120个品种的狗的图像数据集。数据集在<a class="ae kl" href="https://www.kaggle.com/jessicali9530/stanford-dogs-dataset" rel="noopener ugc nofollow" target="_blank">这里</a>可用。我们将把这个数据集的大部分交给模型来训练它，然后看看它能够在剩余的图像上预测品种的准确程度，这是它以前没有见过的。随机猜测正确品种的概率约为1/120——让我们看看我们的模型表现如何。</p><h1 id="2f24" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">数据扩充</h1><p id="b84e" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">对于大多数计算机视觉问题，增加数据集通常是个好主意。我们获取现有的图像，然后在一些设定的参数内随机变换它们。例如，我们可以将图像旋转多达30度，将图像的亮度增加和减少多达20%，增加图像的缩放等。这做了两件事——它增加了我们必须处理的数据量，它有助于确保模型仍然可以识别(在这种情况下)狗的品种，即使图像略有移动。这有明显的优势，因为我们遇到的每一张新图像都不会有完全相同的缩放、亮度等。</p><p id="925f" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">为了说明这一点，让我们见见黑兹尔。她是一只可卡犬，不属于用于训练或测试模型的数据集。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi ms"><img src="../Images/37412e292418417935154b4feffa7b44.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ugfDgVgAZvLpMO_0-TOX7A.jpeg"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">原图:<em class="mp">作者</em></p></figure><p id="8041" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">现在，让我们“放大”这张图片，创建15张图片，每张图片都略有不同。输出如下所示:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mx"><img src="../Images/366a8982e55b2fe2d5e5fc23182a398f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*TZQCf7pPNe7nO5jGdElBWg.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">增强图像:<em class="mp">作者</em></p></figure><h1 id="dbd0" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">模型</h1><p id="a7d9" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">现在考虑到问题的复杂性(我们必须区分120个品种，其中许多看起来很像)，像前面描述的简单模型不太可能胜任这项任务。我们可能想要一个更深的模型，有更多的层次。选择正确的模型结构的过程必然涉及大量的试验和错误。幸运的是，有一些“预训练”模型可供使用，这些模型已经被训练(当然是在不同的数据集上)来分类多达1000个类别。我们可以使用这些模型，重新训练数据集上的所有或部分图层，并观察其表现如何。这就是所谓的“迁移学习”。</p><p id="e8b6" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">在这里，我使用了DenseNet 121模型(它有121层和超过800万个参数！).我用一个有120个节点的密集层替换了最后一个有1000个节点的密集层(因为原始模型是在一个有1000个类的数据集上训练的，而我们只有120个品种)，并且只重新训练了模型的最后11层。</p><p id="9cba" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">模型架构在他们的<a class="ae kl" href="https://arxiv.org/abs/1608.06993" rel="noopener ugc nofollow" target="_blank">论文</a>中有详细描述，摘录如下:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi my"><img src="../Images/078a135bb114864e41b7707228af044a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dMSN9tMUKwZ_mW1krhx3CQ.png"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">DenseNet架构:摘自上述DenseNet论文</p></figure><p id="c374" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">作为Keras库的一部分，所有可用的预训练模型的详细信息可在<a class="ae kl" href="https://keras.io/api/applications/" rel="noopener ugc nofollow" target="_blank">此处</a>找到。</p><h1 id="57c4" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">寻找“引擎盖下”</h1><p id="aec7" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">由于其复杂性，神经网络通常是一个“黑箱”。因此，在展示代码和模型性能之前，尝试并可视化模型在最终预测的不同步骤中“看到”的内容是一个好主意。</p><p id="3617" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">最终的模型有120个卷积层(每个卷积层从图像中提取几个特征)和一个密集层。虽然看到每个图像经历的所有卷积的结果是不实际的，但我使用Hazel的图像作为例子，并在下面展示了最终(训练)模型的不同层生成的3个“卷积”图像。这将允许我们看到模型所看到的内容(即使它只是模型用来进行预测的全部信息的一小部分)。</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div role="button" tabindex="0" class="mt mu di mv bf mw"><div class="gh gi mz"><img src="../Images/0a6baa630c3d6f689de65f41826dc42a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*8lPrud-7awXICv_BPEL6rg.jpeg"/></div></div><p class="ml mm gj gh gi mn mo bd b be z dk translated">看CNN的“引擎盖下”:<em class="mp">作者图片</em></p></figure><p id="b93d" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">正如我们所看到的，在前几层提取的特征对我们来说可能仍然是可识别的，但当模型到达第27层(120层)卷积层时，最终的图像基本上是人眼无法识别的。(重要的是要明白，我们没有告诉CNN要寻找什么样的特征，这是它自己学会的。)<br/>最后一行显示了最终的一组图像(注意，这是一个7*7的像素网格，每个像素用不同的颜色来表征)，然后将这些图像“展平”，并传递到密集层上进行预测。这意味着该模型达到了它的预测，即图像显示的120种狗中的哪一种是基于一堆7*7的图像，我们甚至不能再将这些图像与原始图像联系起来。虽然这对我们来说看起来像是胡言乱语，但CNN经过仔细校准，可以识别这些“点”中复杂的模式，帮助它做出预测。</p><h1 id="a018" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">模型性能</h1><p id="e154" class="pw-post-body-paragraph jn jo iq jp b jq lk js jt ju ll jw jx jy lm ka kb kc ln ke kf kg lo ki kj kk ij bi translated">该模型在测试数据集中的准确率约为75%(请记住，这些图像不是该模型训练的图像)。虽然可以通过调整一些参数和重新训练原始DenseNet模型的更多层来提高性能，但考虑到随机猜测正确品种的概率小于1%，并且许多狗品种看起来彼此非常相似，这已经是很好的了。</p><p id="a42a" class="pw-post-body-paragraph jn jo iq jp b jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk ij bi translated">至于预测黑兹尔属于哪个品种，这个模型是这么说的:</p><figure class="me mf mg mh gt mi gh gi paragraph-image"><div class="gh gi na"><img src="../Images/ee0f26e8d517e84abeca541cd1e89135.png" data-original-src="https://miro.medium.com/v2/resize:fit:760/format:webp/1*8s8MrpTnrv7K-4XoGhrtPQ.png"/></div></figure><figure class="me mf mg mh gt mi"><div class="bz fp l di"><div class="nb mr l"/></div></figure><h1 id="6182" class="km kn iq bd ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj bi translated">密码</h1><figure class="me mf mg mh gt mi"><div class="bz fp l di"><div class="mq mr l"/></div></figure></div></div>    
</body>
</html>