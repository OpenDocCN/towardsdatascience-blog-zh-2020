<html>
<head>
<title>Anomaly detection with Local Outlier Factor (LOF)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于局部异常因子的异常检测(LOF)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/anomaly-detection-with-local-outlier-factor-lof-d91e41df10f2?source=collection_archive---------10-----------------------#2020-09-26">https://towardsdatascience.com/anomaly-detection-with-local-outlier-factor-lof-d91e41df10f2?source=collection_archive---------10-----------------------#2020-09-26</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/b60a6084afda0af8a71bbf9d1f7f8038.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*3lXZN1AKHXa3_K4R"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">照片由<a class="ae jg" href="https://unsplash.com/@kovacsz1?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Z S </a>在<a class="ae jg" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a></p></figure><div class=""/><div class=""><h2 id="2a2f" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">小型数据科学</h2></div><p id="fc2e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">今天的文章是我写的关于用于异常检测的不同技术的一系列“小文章”中的第5篇。如果有兴趣，以下是之前的四篇文章:</p><ul class=""><li id="6c8c" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/z-score-for-anomaly-detection-d98b0006f510">异常检测的Z值</a></li><li id="644c" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/boxplot-for-anomaly-detection-9eac783382fd">异常检测的箱线图</a></li><li id="2d68" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/statistical-techniques-for-anomaly-detection-6ac89e32d17a">异常检测的统计技术</a></li><li id="6ac2" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><a class="ae jg" rel="noopener" target="_blank" href="/time-series-anomaly-detection-with-anomalize-library-67472003c003">利用“异常化”库进行时间序列异常检测</a></li></ul><p id="e7eb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">今天，我将超越统计技术，进入用于异常检测的机器学习算法。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h2 id="9c7a" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lh my mz na ll nb nc nd lp ne nf ng nh bi translated">什么是本地异常因素(LOF)？</h2><p id="7c5c" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">LOF是一种无监督(半监督)的机器学习算法，它使用分布中数据点的密度作为检测异常值的关键因素。</p><p id="d420" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">LOF将任何给定数据点的密度与其相邻数据点的密度进行比较。由于异常值来自低密度区域，因此异常数据点的比率会更高。根据经验，正常数据点的LOF在1到1.5之间，而异常观测值的LOF要高得多。LOF越高，越有可能是异常值。如果点X的LOF是5，这意味着X的邻居的平均密度比其局部密度高5倍。</p><p id="1b64" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">用数学术语来说，</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="f2e8" class="mp mq jj ns b gy nw nx l ny nz">LOF(X)=[(LRD(1st neighbor) + LRD(2nd neighbor ) + .................+ LRD(kth neighbor))/LRD(X)]/k</span></pre><p id="3840" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其中，LRD是本地可达性距离，计算方法如下。</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="55d4" class="mp mq jj ns b gy nw nx l ny nz">LRD(X) = 1/(sum of Reachability Distance (X, n))/k)</span><span id="8c58" class="mp mq jj ns b gy oa nx l ny nz">where n is neighbors upto k</span></pre><p id="31b1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该算法有四个不同的部分:</p><ul class=""><li id="8b54" class="lu lv jj la b lb lc le lf lh lw ll lx lp ly lt lz ma mb mc bi translated"><strong class="la jk">超参数</strong> <em class="ob"> k </em>:决定邻居的数量</li><li id="c359" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la jk">可达性距离</strong>:使用3种方法测量的距离——欧几里德、闵可夫斯基、曼哈顿</li><li id="5f25" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la jk">局部可达性:</strong> (LRD) (X) = 1/(可达性距离之和(X，n))/k)，其中n是k以内的邻居</li><li id="b943" class="lu lv jj la b lb md le me lh mf ll mg lp mh lt lz ma mb mc bi translated"><strong class="la jk">本地异常值因子(LOF) </strong></li></ul><p id="85bb" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">理论和数学讲够了。如果你不太明白，不要难过。正如我过去常说，要驾驶一辆汽车，我们不需要了解它的机械结构，但我们需要知道如何驾驶！因此，请直接进入下一节，讨论用Python实现LOF。</p></div><div class="ab cl mi mj hx mk" role="separator"><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn mo"/><span class="ml bw bk mm mn"/></div><div class="im in io ip iq"><h1 id="f612" class="oc mq jj bd mr od oe of mu og oh oi mx kp oj kq na ks ok kt nd kv ol kw ng om bi translated">Python实现</h1><p id="f98c" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">我们将使用Scikit-Learn库实现Python环境中异常检测的LOF。让我们首先导入所需的库:</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="8ec5" class="mp mq jj ns b gy nw nx l ny nz"># data preparation<br/>import pandas as pd<br/>import numpy as np</span><span id="314b" class="mp mq jj ns b gy oa nx l ny nz"># data visualzation<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="83a4" class="mp mq jj ns b gy oa nx l ny nz"># outlier/anomaly detection<br/>from sklearn.neighbors import LocalOutlierFactor</span></pre><p id="00f7" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在让我们创建一个包含5个数据点的假设数据集。</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="f2de" class="mp mq jj ns b gy nw nx l ny nz"># data<br/>df = pd.DataFrame(np.array([[0,1], [1,1], [1,2], [2,2], [5,6]]), columns = ["x", "y"], index = [0,1,2,3,4])</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div class="gh gi on"><img src="../Images/3afcb24361d1e62dfbbeaaba446ab31c.png" data-original-src="https://miro.medium.com/v2/resize:fit:202/format:webp/1*fh_fNH56qzKP8CYE12S6ig.png"/></div></figure><p id="d7a8" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你绘制数据点，用目视检查找出异常值并不困难。</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="3044" class="mp mq jj ns b gy nw nx l ny nz"># plot data points<br/>plt.scatter(df["x"], df["y"], color = "b", s = 65)<br/>plt.grid()</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div class="gh gi oo"><img src="../Images/81f21df285e5fb7079e505aea9324bac.png" data-original-src="https://miro.medium.com/v2/resize:fit:778/format:webp/1*PtM30afvBkZ3xia2uNOFzg.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">编造数据点</p></figure><p id="bcb0" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所以的确，我们不需要机器学习算法来发现第5个数据点是异常值。但是让我们看看算法是否能检测出来。</p><pre class="nn no np nq gt nr ns nt nu aw nv bi"><span id="f461" class="mp mq jj ns b gy nw nx l ny nz"># model specification<br/>model1 = LocalOutlierFactor(n_neighbors = 2, metric = "manhattan", contamination = 0.02)</span><span id="798d" class="mp mq jj ns b gy oa nx l ny nz"># model fitting<br/>y_pred = model1.fit_predict(df)</span><span id="633a" class="mp mq jj ns b gy oa nx l ny nz"># filter outlier index<br/>outlier_index = where(y_pred == -1) # negative values are outliers and positives inliers</span><span id="c20e" class="mp mq jj ns b gy oa nx l ny nz"># filter outlier values<br/>outlier_values = df.iloc[outlier_index]</span><span id="2177" class="mp mq jj ns b gy oa nx l ny nz"># plot data<br/>plt.scatter(df["x"], df["y"], color = "b", s = 65)</span><span id="1934" class="mp mq jj ns b gy oa nx l ny nz"># plot outlier values<br/>plt.scatter(outlier_values["x"], outlier_values["y"], color = "r")</span></pre><figure class="nn no np nq gt iv gh gi paragraph-image"><div class="gh gi op"><img src="../Images/b42dffcaf2dbab52b043e0855b521fe7.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*B9xXonq111gnFWp_xQWdRQ.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk translated">使用LOF检测异常数据点</p></figure><p id="1d9c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这就对了。该算法正确地检测出异常值。</p><h2 id="a764" class="mp mq jj bd mr ms mt dn mu mv mw dp mx lh my mz na ll nb nc nd lp ne nf ng nh bi translated">总结和结论</h2><p id="e539" class="pw-post-body-paragraph ky kz jj la b lb ni kk ld le nj kn lg lh nk lj lk ll nl ln lo lp nm lr ls lt im bi translated">本文的目的是介绍一种基于密度的异常检测技术——局部异常因子。LOF将给定数据点的密度与其相邻数据点的密度进行比较，并确定该数据是正常的还是异常的。由于有了<code class="fe oq or os ns b">sklearn</code>库，这个算法的实现并不太困难。对结果的解释也相当直接。</p><p id="efab" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了只关注一件事，我忽略了<code class="fe oq or os ns b">LocalOutlierFactor()</code>算法的另一个重要用例——新奇感检测。这是另一篇文章的主题，但简单来说，LOF是一种半监督ML算法，其中该算法仅在正常数据上训练<em class="ob"/>。在训练算法之后，显示新的数据来识别它是否新颖。</p><p id="f04e" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">希望你喜欢这篇文章，欢迎随时关注我的<a class="ae jg" href="https://medium.com/@mab.datasc" rel="noopener">媒体</a>或<a class="ae jg" href="https://twitter.com/DataEnthus" rel="noopener ugc nofollow" target="_blank">推特</a>。</p></div></div>    
</body>
</html>