<html>
<head>
<title>Attention and Transformer Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">注意力和变压器模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/attention-and-transformer-models-fe667f958378?source=collection_archive---------10-----------------------#2020-11-16">https://towardsdatascience.com/attention-and-transformer-models-fe667f958378?source=collection_archive---------10-----------------------#2020-11-16</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="38e1" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="120d" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">一个复杂的算法，简单解释一下</h2></div><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ko"><img src="../Images/aa2c644c7a0250f17bd50c88d3e54690.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fLmyn6OmFAf-X68g8A1uEg.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="5db0" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><a class="ae ma" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">2017</a>瓦斯瓦尼等人的《注意力就是你所需要的全部》是一篇里程碑式的论文，提出了一种全新的模型——变压器。如今，Transformer模型在机器学习领域中无处不在，但它的算法非常复杂，难以琢磨。所以这篇博客希望能让你对此有更多的了解。</p><h1 id="b252" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">基本架构</h1><p id="a8dc" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">那么下图中所有这些彩色矩形意味着什么呢？一般而言，转换器模型基于编码器-解码器架构。编码器是左手边的灰色矩形，解码器是右手边的那个。编码器和解码器都由两个和三个子层组成，分别是:<strong class="lg ja">多头自关注</strong>、一个<strong class="lg ja">全连接前馈网络</strong>和——在解码器的情况下——<strong class="lg ja">编码器-解码器自关注</strong>(在下面的可视化中称为多头关注)。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi my"><img src="../Images/cc5af40bc9a3a296c8e58bf50684d54c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1234/format:webp/1*43lgCTyM5cTTABjC2VEHdA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">变压器架构(来源:Vaswani等人，2017年)</p></figure><p id="eb09" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">图中看不清楚的是，变压器实际上堆叠了多个编码器和解码器(图中用Nx表示，即编码器和解码器堆叠了<em class="mz"> n </em>次)。这意味着一个编码器的输出用作下一个编码器的输入，一个解码器的输出用作下一个解码器的输入。</p><h1 id="0d33" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">多头自我关注</h1><p id="7d45" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">Transformer的新之处并不在于它的编码器-解码器架构，而在于它摒弃了传统上使用的循环层。相反，它完全依赖于自我关注。</p><p id="e747" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">那么什么是自我关注呢？简而言之，这是模型理解其接收到的输入的方式。</p><p id="313e" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">递归模型的一个问题是长期相关性(在一个序列内或跨几个序列)经常丢失。也就是说，如果序列开头的一个单词对于序列结尾的一个单词很重要，那么一旦到达最后一个单词，模型可能会忘记第一个单词。那些RNNs没那么聪明吧？；-)变形金刚模型使用不同的策略来记忆整个序列:自我关注！</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi na"><img src="../Images/5f0a1af7a5d65e63586e4e2d5fcab3cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1376/format:webp/1*mRUUXWkeu2xj05allMMi-Q.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">序列中的长期依赖:如果模型没有从一开始就记住“男孩”，它可能不知道在结尾使用哪个代词。他，她，它？(图片由作者提供)</p></figure><p id="3768" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">在自我注意层，输入x(表示为向量)通过输入的三个表示向量:q(ueries)，k(eys)和v(values)被转换成向量z。这些用于计算一个分数，该分数显示该特定输入应该对给定序列中的其他元素给予多少关注。</p><p id="3f00" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">我刚才用语言模糊表达的东西可以用下面的公式更精确地定义:</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nb"><img src="../Images/914f7fdd9caa244aac5ceafe43619909.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sajmII73ldY_nd9vBca42w.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="9a06" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">由于公式并不总是非常直观，一步一步的可视化计算应该会使事情变得更清楚一些。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi nc"><img src="../Images/d5fe3dc031cf7745135b04c8c23fae40.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*t-o5IrZHRZgrz2MwPpcNQA.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="26d2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">比方说我们要为“蓬松煎饼”序列中的“蓬松”这个词计算<strong class="lg ja">自我关注度。首先，我们将输入向量<em class="mz"> x1 </em>(代表单词“fluffy”)与三个不同的权重矩阵Wq、Wk和Wv(在训练期间不断更新)相乘，以获得三个不同的向量:q1、k1和v1。对输入向量<em class="mz"> x2 </em>(代表单词“煎饼”)进行完全相同的操作。我们现在有了两个单词的查询、键和值向量。</strong></p><p id="09e2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">查询</strong>是我们想要计算自我关注度的单词的表示。因此，由于我们想获得对“fluffy”的自我关注，我们只考虑它的查询，而不考虑“pancakes”的查询。一旦我们计算完“fluffy”的自我关注度，我们也可以丢弃它的查询向量。</p><p id="9b43" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">键</strong>是序列中每个单词的表示，用于匹配我们当前想要计算自我注意的单词的查询。</p><p id="6748" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated"><strong class="lg ja">值</strong>是序列中每个单词的实际表示，我们真正关心的表示。将查询和关键字相乘得到一个分数，这个分数告诉我们每个值(以及相应的单词)在自我关注向量中所占的权重。请注意，该值不是直接与分数相乘，而是首先将分数除以<em class="mz"> dk </em>的平方根，即关键向量的维数，然后应用softmax。</p><p id="0469" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">这些计算的结果是每个单词一个向量。最后一步，将这两个向量相加，瞧，我们有了对单词“fluffy”的自我关注。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/103c86a770d3913a068592016afd4b15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1136/format:webp/1*MZ58mwmCXbQEQib1r0QlhA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">自我关注“他的”这个词。这些线条表示单词“his”对序列中其他单词的关注程度。(图片由作者提供)</p></figure><p id="2d2a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">你可能注意到了，它叫<em class="mz">多头</em>自关注。这是因为上面的过程使用不同的权重矩阵进行了多次，这意味着我们最终得到了多个向量(在下面的公式中称为头部)。这些报头然后被连接并乘以权重矩阵Wo。这意味着每个大脑学习不同的关于给定序列的信息，并且这些知识在最后被结合。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ne"><img src="../Images/ae6e89203f2e519b40faf32c67aefe16.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yhnoNZPG3EjJNuTlmFw4JQ.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="e5b2" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">到目前为止，我还没有提到最重要的一点:所有这些计算都可以<strong class="lg ja">并行化</strong>。为什么这是一件大事？我们先来看看RNNs。它们需要按顺序处理顺序数据，也就是说，一个序列中的每个单词都要一个接一个地传递给模型。然而，变压器模型可以一次处理所有输入。这使得这些模型非常快，允许它们用大量的数据进行训练。您现在想知道，如果转换器一次收到一个句子，它是如何知道句子的正确顺序的？我将在下面关于位置编码的部分解释这一点。</p><p id="010a" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">正如我们在展示Transformer架构的第一张图片中看到的，自关注层集成在编码器和解码器中。刚刚看了一下自我关注在编码器中的样子。然而，解码器使用所谓的<strong class="lg ja"> <em class="mz">屏蔽</em>多头自关注</strong>。这意味着解码器输入中的一些位置被屏蔽，从而被自我关注层忽略。他们为什么要戴面具？当预测句子的下一个单词时，解码器不应该知道哪个单词在预测的单词之后。相反，解码器应该只知道直到当前位置的字。毕竟，当实际使用模型来获得真正的下一个单词预测时，解码器也无法看到未来的位置。因此，通过在训练期间屏蔽它们，我们不允许解码器作弊。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/48af7082391150dd03f87a8eeedd610b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1010/format:webp/1*8bMycmEg2YzbuFrE-_EsRA.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">在第一句话中(带面具)，下一个词远比第二句话(不带面具)更难预测。“它的尾巴”这个词清楚地表明，预测这个词可能是“摆动”。(图片由作者提供)</p></figure><p id="4dd6" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">该模型的一个关键方面仍然缺失。信息是如何从编码器流向解码器的？这就是<strong class="lg ja">编码器-解码器自关注层</strong>在这里的目的。这一层的工作方式与编码器中的自我关注层非常相似。然而，查询向量来自前一个被屏蔽的自我关注层，键和值向量来自最顶层编码器的输出。这允许解码器考虑编码器输入序列中的所有位置。</p><h1 id="536e" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">前馈网络</h1><p id="81ab" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">所以我们现在知道了自我关注层在每个编码器和解码器中做了什么。这就给我们留下了另一个我们没有谈到的子层:全连接的前馈网络。它们进一步处理自关注层的输出，然后将它们传递给下一个编码器或解码器。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div role="button" tabindex="0" class="ku kv di kw bf kx"><div class="gh gi ng"><img src="../Images/d8328853d7cbc915a55d66debc53296f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OYA-jNOSsaTtsKch5ddaYw.png"/></div></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="5190" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">每个前馈网络由两个线性层组成，中间有一个ReLU函数。权重和偏差W1、W2、b1和b2在序列中的不同位置是相同的，但是在每个编码器和解码器中是不同的。</p><h1 id="e37c" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">位置编码</h1><p id="805c" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">正如我们已经说过的，Transformer模型可以并行处理序列中的所有单词。然而，这意味着丢失了一些重要的信息:序列中的<strong class="lg ja">字位置。为了保留这些信息，单词的位置和顺序必须对模型明确。这是通过位置编码完成的。这些位置编码是与输入向量维数相同的向量，使用正弦和余弦函数计算。为了组合输入向量和位置编码的信息，它们被简单地相加。</strong></p><p id="ff00" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">要更详细地解释位置编码到底是如何工作的，我在这里推荐<a class="ae ma" href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h1 id="0fc9" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">图层规范化</h1><p id="a382" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">变压器模型的一个小但重要的方面是层标准化，它在每个编码器和解码器的每个子层之后执行。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/1a854234c04293aa104996e25e196928.png" data-original-src="https://miro.medium.com/v2/resize:fit:594/format:webp/1*do7eaaZM0ZHeSykigWXRDg.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">(图片由作者提供)</p></figure><p id="8413" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">首先，将各个编码器或解码器层的输入和输出相加。这意味着在最底层，输入向量X和输出向量Z1相加；在第二层中，输入向量Z1和输出向量Z2等等。然后用零和单位方差的平均值对求和向量进行归一化。这可以防止给定层中的值范围波动过大，从而使模型更快地收敛。</p><p id="92bb" class="pw-post-body-paragraph le lf iq lg b lh li ka lj lk ll kd lm ln lo lp lq lr ls lt lu lv lw lx ly lz ij bi translated">为了更深入地解释图层规范化，我在这里推荐<a class="ae ma" href="https://leimao.github.io/blog/Layer-Normalization/" rel="noopener ugc nofollow" target="_blank">这篇文章</a>。</p><h1 id="0c44" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">最终线性层和Softmax</h1><p id="c131" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">最后，为了得到输出预测，我们需要将最后一个解码器的输出向量转换成单词。因此，我们首先将输出向量输入到一个全连接的线性层中，并获得一个词汇表大小的logits向量。然后，我们将softmax函数应用于这个向量，以便获得词汇表中每个单词的概率分数。然后，我们选择概率最大的单词作为我们的预测。</p><figure class="kp kq kr ks gt kt gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/46c7a7f4e7e6583dc80ea45fd26403af.png" data-original-src="https://miro.medium.com/v2/resize:fit:956/format:webp/1*P8O40-tT79FhDUOBPBlxjQ.png"/></div><p class="la lb gj gh gi lc ld bd b be z dk translated">《小背狗__》下一个词预测的概率得分。(图片由作者提供)</p></figure><h1 id="d0e4" class="mb mc iq bd md me mf mg mh mi mj mk ml kf mm kg mn ki mo kj mp kl mq km mr ms bi translated">摘要</h1><p id="0470" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">Transformer模型是一种新的编码器-解码器模型，它使用自我注意来理解语言序列。这允许并行处理，从而使它比任何其他具有相同性能的模型快得多。他们因此为现代语言模型(如<a class="ae ma" href="https://arxiv.org/abs/1810.04805" rel="noopener ugc nofollow" target="_blank">伯特</a>和<a class="ae ma" href="https://openai.com/blog/language-unsupervised/" rel="noopener ugc nofollow" target="_blank"> GPT </a>以及最近的<a class="ae ma" href="https://arxiv.org/abs/1802.05751" rel="noopener ugc nofollow" target="_blank">图像生成模型</a>铺平了道路。</p><h2 id="5227" class="nj mc iq bd md nk nl dn mh nm nn dp ml ln no np mn lr nq nr mp lv ns nt mr iw bi translated"><strong class="ak">参考文献</strong></h2><p id="2a9b" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">[1] A. Vaswani，N. Shazeer，N. Parmar，J. Uszkoreit，L. Jones，A. N. Gomez，L. Kaiser和I. Polosukhin，<a class="ae ma" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">注意力是你所需要的一切</a> (2017)，NIPS'17:第31届神经信息处理系统国际会议论文集<br/> [2] A. Kazemnejad，<a class="ae ma" href="https://kazemnejad.com/blog/transformer_architecture_positional_encoding/" rel="noopener ugc nofollow" target="_blank"> Transformer Architecture:位置编码</a> (2019)，Amirhossein Kazemnejad</p><h2 id="cd3b" class="nj mc iq bd md nk nl dn mh nm nn dp ml ln no np mn lr nq nr mp lv ns nt mr iw bi translated">信用</h2><p id="9e48" class="pw-post-body-paragraph le lf iq lg b lh mt ka lj lk mu kd lm ln mv lp lq lr mw lt lu lv mx lx ly lz ij bi translated">特别感谢Philip Popien对本文的建议和更正。</p></div></div>    
</body>
</html>