<html>
<head>
<title>Training models on imbalanced data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">不平衡数据的训练模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/training-models-on-imbalanced-data-561fa3f842b5?source=collection_archive---------16-----------------------#2020-10-07">https://towardsdatascience.com/training-models-on-imbalanced-data-561fa3f842b5?source=collection_archive---------16-----------------------#2020-10-07</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="152f" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">了解阶级不平衡，并学习如何规避它</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/808ed06abec67df7afe98fdfeb709f75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WC-ulpbLB4cxzrahKqMaUA.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">Elena Mozhvilo在Unsplash 上拍摄的照片</p></figure><p id="c972" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">类别不平衡是指数据中不同类别的样本数量不同。在机器学习的实际应用中，经常会遇到具有不同程度类别不平衡的数据集:从中度不平衡(例如，医学图像中10%被诊断患有疾病，90%没有)到极端不平衡(例如，工厂中的异常检测，其中可能有1/10，000批次失败)。</p><p id="f013" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">大多数根据不平衡数据训练的模型会偏向于预测较大的类别，并且在许多情况下，可能会完全忽略较小的类别。当训练数据中存在类别不平衡时，由于较大类别的先验概率增加，机器学习模型通常会对较大类别进行过度分类。</p><p id="8996" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">结果，属于较小类的实例通常比属于较大类的实例更经常被错误分类。在许多用例中，例如医疗诊断，这与我们想要实现的正好相反，因为罕见类别(例如疾病)是正确预测的最重要类别是很常见的。为了实现这一点，我们需要在训练模型时以某种方式处理类的不平衡。</p><p id="749e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">今天我们将复习:</p><ul class=""><li id="9b7f" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">阶级失衡的症状是什么；</li><li id="5815" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">类别不平衡如何影响模型性能；</li><li id="62a7" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">处理不平衡数据的可能解决方案是什么，以及每种方法的优缺点；</li><li id="75ff" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">在这种情况下，评估模型时首选哪些度量。</li></ul><p id="32dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">识别阶层失衡</strong></p><p id="b660" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过查看数据中目标类的分布，很容易识别类不平衡。在Peltarion平台中，直方图显示分布，位于数据集视图中每列的上方。</p><p id="2cad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您注意到您希望模型预测的列的非均匀分布，那么您有一个不平衡的类问题，需要采取一些措施来处理它。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mg"><img src="../Images/5861f9f90d72cf1fe19804da0cb0b8bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:616/0*a123lPmbgsj0pwwv"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图1:不平衡的阶级分布的例子。图片来自<a class="ae kv" href="https://platform.peltarion.com/" rel="noopener ugc nofollow" target="_blank"> Peltarion平台</a>。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mh"><img src="../Images/214894e86bb3185085ce5125713d5187.png" data-original-src="https://miro.medium.com/v2/resize:fit:612/0*hUO-WbKGs-Bj1Tnh"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图2 :(相当)平衡的阶级分布的例子。图片来自<a class="ae kv" href="https://platform.peltarion.com/" rel="noopener ugc nofollow" target="_blank"> Peltarion平台</a>。</p></figure><p id="1d61" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">它如何影响模型性能</strong></p><p id="4c83" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在每个类别的比例显著不同的情况下进行分类是有问题的，因为预测模型通常可以通过简单地“猜测”所有新的示例属于在训练数据中观察到的最常见的类别来达到高精度。由于准确性是我们通常优化的目标——通常通过分类交叉熵损失间接实现——我们经常会发现琐碎的多数猜测模型。例如，如果只有5%的房屋受到水毁的影响，我们可以构建一个模型，猜测没有房屋受到水毁，但仍然获得95%的准确性。虽然95%是一个令人愉快的高比例，但该模型可能不会达到预期效果，即很好地区分受到水损害的房屋和没有受到水损害的房屋。</p><p id="8de4" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">从神经网络的角度来看，这可以通过以下替代方式来理解。如果在上述95/5水损害案例中，我们的批量为20，则平均只有一个样本来自阳性类别。所述批次的梯度更新将“看到”19个负样本和一个正样本，使得一个正样本很难影响梯度的方向。</p><p id="ade1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如何解决阶层失衡</strong></p><p id="8ad5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">有不同的方法可以用来处理阶级不平衡的问题。它们通常可以分为数据级和算法级方法。</p><p id="d4f8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">数据级方法</strong>修改训练分布，降低不平衡程度。平均而言，这使得梯度更新能够从每个类中“看到”相似数量的示例。</p><ol class=""><li id="6d75" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mi ly lz ma bi translated">欠采样丢弃从较大类别中随机选择的样本。这会导致信息丢失，因为一些样本被从训练数据中移除，并且模型不能利用这些样本中包含的信息。</li><li id="988b" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mi ly lz ma bi translated">过采样从较小的类中复制随机选择的样本，这导致多次显示学习算法完全相同的样本。这有过度拟合这些稀有样本的风险。</li><li id="5ab4" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mi ly lz ma bi translated">或者，您可以将数据扩充与过采样结合使用，以降低过度拟合的风险。数据扩充包括通过模仿观察到的类别分布来构建合成训练样本。对于图像，你可以使用<a class="ae kv" href="https://peltarion.com/knowledge-center/documentation/modeling-view/build-an-ai-model/image-augmentation" rel="noopener ugc nofollow" target="_blank">这些技术</a>进行放大。</li></ol><p id="4307" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">算法级方法</strong>调整学习过程，以便在训练期间增加较小类的重要性。一种常见的方法是在损失函数中使用类权重。</p><p id="2e82" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在模型训练期间，计算每批的总损失，然后在减少该损失的方向上迭代更新模型参数。损失是实际值和模型预测值之间的误差，是该批次中所有样本的总和。默认情况下，每个样本同等计入总损失。然而，使用类别加权，总和被调整为加权总和，使得每个样本对损失的贡献与样本的类别权重成比例。</p><p id="579f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样，属于较小类别的样本可以对总损失做出较大的贡献。这反过来意味着，当执行参数更新时，学习算法将更加关注它们。回头参考上面给出的以神经网络为中心的解释，正类的高类权重将为批中的单个正样本提供影响梯度更新的“能力”。</p><p id="3b45" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">一种常见的方法是分配与训练数据中的类频率成反比的类权重。平均而言，这相当于在梯度更新上给予所有类别同等的重要性，而不管我们从训练数据中的每个类别获得多少样本。这反过来防止模型简单地基于它们增加的先验概率对较大的类进行过度分类。</p><p id="5431" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Peltarion平台支持类别加权，即根据上述策略设置权重。这是您需要做的来启用它:在建模视图中，点击您的目标块，然后选中“使用类权重”复选框。就是这样！</p><p id="0e97" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">如何衡量绩效</strong></p><p id="b1ed" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在处理不平衡数据时，我们不建议将分类准确性作为主要评估标准。当测试在非常不平衡的数据上训练的分类模型时，观察到高的评估准确度并不罕见。在这种情况下，精确度仅仅反映了底层的类别分布。你要避免这种情况！</p><p id="13e6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这种情况下，区分微观平均和宏观平均是有用的。这些是衡量绩效的非常有用的概念。所以我们开始了<a class="ae kv" href="https://doi.org/10.1016/j.ipm.2009.03.002" rel="noopener ugc nofollow" target="_blank">【1】</a>:</p><ol class=""><li id="0d31" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr mi ly lz ma bi translated">某个度量的微平均值将集合所有类的贡献来计算平均度量。</li><li id="9208" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr mi ly lz ma bi translated">某个度量的宏观平均值将为每个类独立计算度量，然后取平均值。</li></ol><p id="709a" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因此，微观平均赋予每个样本同样的重要性，这意味着，样本数量越多，相应类别对最终得分的影响越大，从而有利于大多数类别。相反，宏平均值赋予每个类相同的重要性，因此可以更好地反映模型的性能——考虑到您的目标是拥有一个对所有类(包括少数类)都性能良好的模型。</p><p id="38a5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">除了准确性，研究社区还经常使用其他衡量标准来评估基于不平衡数据训练的模型，即精确度、召回率和F1分数【T0【2】。如前所述，优先考虑宏观平均精度、召回率和F1分数，而不是微观平均分数。特别是对于二元分类问题，利用ROC-AUC分数或者更适合不平衡数据集的PR-AUC分数<a class="ae kv" href="https://dl.acm.org/doi/10.1145/1143844.1143874" rel="noopener ugc nofollow" target="_blank">【3】</a>。在Peltarion平台中，您可以在评估视图中检查所有这些测量，以评估您的模型。</p><p id="04a9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">最后，混淆矩阵是这类问题的基本评估工具。参见下面的混淆矩阵，其评估了在具有来自不同音乐风格的歌词的数据集上训练的BERT分类模型，用于上面所示的直方图:在图3中，模型在原始数据上训练(其明显不平衡)，而在图4(平台外)中，过采样用于在模型训练之前平衡类别。请注意，不平衡数据中的大多数类别“摇滚”是如何主导预测的。在对相当平衡的数据训练模型之后，混淆矩阵呈现出更强的对角线，表明处理数据不平衡提高了整体分类性能。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mj"><img src="../Images/5d6f0eb8d5ff78a9328887a65e0d3bae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*X3lULJii5-UJDWHt"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图3:不平衡类别分布的混淆矩阵。图片来自<a class="ae kv" href="https://platform.peltarion.com/" rel="noopener ugc nofollow" target="_blank"> Peltarion平台</a>。</p></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mk"><img src="../Images/1894fa6f5331f5bebb3950207c5a3813.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*H3nSxZ5XJzIQP6p1"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">图4 :(相当)平衡的类分布的混淆矩阵。图片来自<a class="ae kv" href="https://platform.peltarion.com/" rel="noopener ugc nofollow" target="_blank"> Peltarion平台</a>。</p></figure><p id="5bf8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">总结</strong></p><p id="3cb0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，您已经准备好:</p><ul class=""><li id="a943" class="ls lt iq ky b kz la lc ld lf lu lj lv ln lw lr lx ly lz ma bi translated">向世界解释为什么在不平衡数据上训练ML模型往往不是小事；</li><li id="4866" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">确定你自己的数据集有多倾斜；</li><li id="9bf8" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">调整你的数据或你的学习算法以避免不平衡；</li><li id="c617" class="ls lt iq ky b kz mb lc mc lf md lj me ln mf lr lx ly lz ma bi translated">最后，采用正确的评估方法来比较您的模型。</li></ul><p id="e2ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">干杯！</p><p id="9a27" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">参考文献</strong></p><p id="35b9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[1] M. Sokolova，G. Lapalme，<a class="ae kv" href="https://doi.org/10.1016/j.ipm.2009.03.002" rel="noopener ugc nofollow" target="_blank">分类任务的性能测量的系统分析</a> (2009)，信息处理&amp;管理</p><p id="0a6e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[2] <a class="ae kv" href="https://ieeexplore.ieee.org/author/37291665900" rel="noopener ugc nofollow" target="_blank"> H .何</a>，<a class="ae kv" href="https://ieeexplore.ieee.org/author/37534980900" rel="noopener ugc nofollow" target="_blank"> E. A .加西亚</a>，<a class="ae kv" href="https://doi.org/10.1109/TKDE.2008.239" rel="noopener ugc nofollow" target="_blank">从不平衡数据中学习</a> (2009)，IEEE知识与数据工程汇刊</p><p id="c921" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">[3] J. Davis，M. Goadrich，<a class="ae kv" href="https://dl.acm.org/doi/10.1145/1143844.1143874" rel="noopener ugc nofollow" target="_blank">精确召回与ROC曲线的关系</a> (2006)，ICML 06:第23届机器学习国际会议论文集</p></div></div>    
</body>
</html>