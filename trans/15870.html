<html>
<head>
<title>A Cloud ML first: Google’s AI Platform Deep Learning Container with NVIDIA Tensor Core A100 GPU</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">A Cloud ML first: Google的AI平台深度学习容器，搭配NVIDIA Tensor Core A100 GPU</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/a-cloud-ml-first-googles-ai-platform-deep-learning-container-with-nvidia-tensor-core-a100-gpu-53ab9d313d17?source=collection_archive---------28-----------------------#2020-11-01">https://towardsdatascience.com/a-cloud-ml-first-googles-ai-platform-deep-learning-container-with-nvidia-tensor-core-a100-gpu-53ab9d313d17?source=collection_archive---------28-----------------------#2020-11-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7779" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">在本文中，我们提供了对谷歌人工智能平台和深度学习容器的介绍，然后探索A100 GPU的惊人性能。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c67a1e681aace322ce3b9524b399e089.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x3AHpT1uNQYrFxNt8ZrYng.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">授权给作者的图像</p></figure><p id="f11e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">基于云的深度学习的关键一步；数据科学家第一次可以访问NVIDIA A100 Tensor Core GPU前所未有的加速。</p><p id="51f2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们提供了对谷歌人工智能平台和深度学习容器的介绍，然后探索A100 GPU的惊人性能。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="3410" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">谷歌云人工智能平台</h1><p id="202b" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">对于那些不熟悉人工智能平台的人来说，本质上它是谷歌云平台上的一套服务，专门用于在云中构建、部署和管理机器学习模型。</p><p id="56f5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人工智能平台旨在使数据科学家和数据工程师简化他们的ML工作流程。我们经常在AutoML (Google的点击式ML引擎)中使用它，但除此之外，它还支持使用Tensorflow构建的高级模型的训练、预测和版本管理。</p><blockquote class="my mz na"><p id="0243" class="ky kz nb la b lb lc ju ld le lf jx lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">通过像TPUs和tensor flow<br/><strong class="la iu">Google Cloud</strong>这样的工具，利用谷歌在人工智能方面的专业知识，将我们的尖端人工智能技术注入到您的应用程序中</p></blockquote><h1 id="9597" class="mb mc it bd md me nf mg mh mi ng mk ml jz nh ka mn kc ni kd mp kf nj kg mr ms bi translated">云人工智能平台服务</h1><p id="5c13" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">AI Platform有一套服务，用于支持典型ML工作流中的活动。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nk"><img src="../Images/d5ba0808028977abeb4d0d81e3724d84.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eF7n2JCVmwb1mRD49UMaYg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">谷歌云AI平台服务(图片来源谷歌云)</p></figure><p id="cc1e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我们将重点关注<strong class="la iu">深度学习容器</strong>(这些属于上图中的<strong class="la iu">管道</strong>部分)。虽然其他服务不在本文讨论范围内，但我们已经包括了对每个服务的简要描述以及一些链接，以防您想了解更多。</p><p id="3252" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 1。准备</strong></p><p id="b179" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们通常首先在<a class="ae nl" href="https://cloud.google.com/bigquery/docs/datasets-intro" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">大查询数据集</strong> </a>中准备(摄取、清理、特征工程)我们的数据，大查询数据集是Google Clouds超大规模数据仓库中的表集合。</p><p id="508c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Google提供了一个<a class="ae nl" href="https://cloud.google.com/ai-platform/data-labeling/docs" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">数据标注服务</strong> </a>用于标注训练数据<br/>(通常我们用于图像、视频、音频和文本的分类)。</p><p id="95aa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 2。构建</strong></p><p id="9ed0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们已经提到过<strong class="la iu"> AutoML </strong>，训练模型的零代码平台。</p><p id="33bd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们使用<a class="ae nl" href="https://cloud.google.com/ai-platform-notebooks" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> AI平台笔记本</strong> </a>(托管Jupyter笔记本)来构建定制模型(通常是Tensorflow或SkLearn)。</p><p id="8bd4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，我们使用<a class="ae nl" href="https://cloud.google.com/ai-platform/training/docs" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> AI平台训练</strong> </a>进行方便的模型训练。</p><p id="fb00" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 3。验证</strong></p><p id="76c2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="https://cloud.google.com/explainable-ai" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">可解释AI </strong> </a> <strong class="la iu"> </strong>是一套非常棒的工具，可以帮助您理解模型的输出，验证模型行为，识别模型中的偏差，并获得改进模型和训练数据的方法。这确实有助于消除模型调优等活动中的猜测。</p><p id="a29c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="https://cloud.google.com/ai-platform/optimizer/docs/overview" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> AI平台Vizier </strong> </a>更进一步，提供黑盒优化服务，调整超参数，优化模型输出。</p><p id="51e7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 4。展开</strong></p><p id="e217" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">无论您是使用无代码AutoML训练的模型，还是使用AI平台笔记本构建的高级Tensorflow模型，AI平台都提供了许多服务来帮助部署模型和生成预测。</p><p id="15e2" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="http://AI Platform Prediction that manages the infrastructure needed to run your model and makes it available for online and batch prediction requests. You can also use AutoML Vision Edge to deploy your models at the edge and trigger real-time actions based on local data. TensorFlow Enterprise offers enterprise-grade support for your TensorFlow instance." rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> AI平台预测</strong> </a> <strong class="la iu"> </strong>管理运行您的模型所需的基础设施，并使其可用于在线和批量预测请求。</p><p id="bb7d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="https://cloud.google.com/vision/automl/docs/edge-quickstart" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">AutoML Vision Edge</strong></a><strong class="la iu"/>帮助部署Edge模型(在本地设备上运行，例如智能手机、物联网设备)并可以基于本地数据触发实时操作。</p><p id="09a6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="https://cloud.google.com/tensorflow-enterprise" rel="noopener ugc nofollow" target="_blank"><strong class="la iu">TensorFlow Enterprise</strong></a><strong class="la iu"/>为您的tensor flow实例提供企业级支持。</p><p id="ac29" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> 5。ML管道(ML操作)</strong></p><p id="32cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">ML Ops是部署健壮的、可重复的和可伸缩的ML管道来管理您的模型的实践。人工智能平台提供了许多服务来协助这些管道。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nm"><img src="../Images/f9c1edd502bcf8bbe413292dcb090922.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FnQTrUGkPy4JbzHbNCKdvA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">授权给作者的图像</p></figure><p id="c571" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="http://Continuous evaluation helps you monitor the performance of your models and provides continual feedback on how your models are performing over time." rel="noopener ugc nofollow" target="_blank"> <strong class="la iu"> AI平台管道</strong> </a>提供使用Kubeflow管道或TensorFlow Extended (TFX)创建ML管道的支持。</p><p id="9f8f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="http://Continuous evaluation helps you monitor the performance of your models and provides continual feedback on how your models are performing over time." rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">持续评估</strong> </a> <strong class="la iu"> </strong>帮助您监控您的模型的性能，并对您的模型在一段时间内的表现提供持续反馈。</p><p id="4e80" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nl" href="https://cloud.google.com/deep-learning-vm" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">深度学习虚拟机映像</strong> </a>支持轻松调配深度学习ML应用的云虚拟机。</p><p id="7382" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">最后，<a class="ae nl" href="https://cloud.google.com/ai-platform/deep-learning-containers" rel="noopener ugc nofollow" target="_blank"> <strong class="la iu">深度学习容器</strong> </a>为深度学习环境提供预配置和优化的容器。</p><h1 id="8570" class="mb mc it bd md me nf mg mh mi ng mk ml jz nh ka mn kc ni kd mp kf nj kg mr ms bi translated">深度学习容器</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/7118b62597940f4448cb5d5343d7aa04.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Okao1S_Gvo9OfX2_HG5mSA.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">授权给作者的图像</p></figure><blockquote class="my mz na"><p id="618b" class="ky kz nb la b lb lc ju ld le lf jx lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">AI平台深度学习容器为您提供性能优化的一致环境，帮助您快速原型化和实施工作流。深度学习容器映像预装了最新的机器学习数据科学框架、库和工具。<br/> <strong class="la iu">谷歌云</strong></p></blockquote><p id="8aff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">人们很容易低估启动和运行机器学习项目所需的时间。通常，这些项目需要您管理不断发展的软件堆栈的兼容性和复杂性，这可能会令人沮丧、耗时，并使您无法做您真正想做的事情:花费时间迭代和细化您的模型。</p><p id="c41f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">深度学习容器旨在加速这一过程。</p><p id="9de0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">所有深度学习容器都有一个预先配置的Jupyter环境，因此每个容器都可以直接作为原型空间使用。首先，确保你已经安装并配置了<a class="ae nl" href="https://cloud.google.com/sdk/" rel="noopener ugc nofollow" target="_blank"> gcloud </a>工具。然后，确定您想要使用的容器。所有容器都托管在gcr.io/deeplearning-platform-release,下，可以使用以下命令列出:</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="89c9" class="nt mc it np b gy nu nv l nw nx">gcloud container images list --repository=”gcr.io/deeplearning-platform-release”</span></pre><p id="35be" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">每个容器都提供了一个与相应的深度学习虚拟机一致的Python3环境，包括选定的数据科学框架conda，用于GPU映像的NVIDIA堆栈(CUDA，cuDNN，NCCL)，以及许多其他支持包和工具。</p><p id="acbd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">创建CPU Tensorflow容器的示例</strong></p><p id="bfb7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这真的很简单。以下命令将在分离模式下启动TensorFlow深度学习容器，将正在运行的Jupyter服务器绑定到本地机器上的端口8080，并将容器中的/path/to/local/dir挂载到/home。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="707d" class="nt mc it np b gy nu nv l nw nx">docker run -d -p 8080:8080 -v /path/to/local/dir:/home \<br/>gcr.io/deeplearning-platform-release/tf-cpu.1–13</span></pre><p id="9680" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，可以在localhost:8080访问正在运行的JupyterLab实例。确保在/home中开发，因为当容器停止时，任何其他文件都将被删除。</p><p id="d859" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你想使用支持GPU的容器，你需要一个CUDA 10兼容的GPU，相关的驱动程序，并安装<a class="ae nl" href="https://github.com/NVIDIA/nvidia-docker" rel="noopener ugc nofollow" target="_blank"> nvidia-docker </a>。然后，您可以运行类似的命令。</p><pre class="kj kk kl km gt no np nq nr aw ns bi"><span id="ad0e" class="nt mc it np b gy nu nv l nw nx">docker run --runtime=nvidia -d -p 8080:8080 -v /path/to/local/dir:/home \<br/>gcr.io/deeplearning-platform-release/tf-gpu.1–13</span></pre><p id="61cd" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在您只需使用这个容器开发您的模型。</p><h1 id="72f4" class="mb mc it bd md me nf mg mh mi ng mk ml jz nh ka mn kc ni kd mp kf nj kg mr ms bi translated">NVIDIA A100张量核心GPU</h1><p id="6f50" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">所以，现在你已经定位于谷歌云人工智能平台及其深度学习容器，让我们先探索一下云；能够访问由<a class="ae nl" href="https://www.nvidia.com/en-us/data-center/a100/" rel="noopener ugc nofollow" target="_blank"> NVIDIA A100 Tensor Core GPU </a>驱动的深度学习容器。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ny"><img src="../Images/1d945f9754cec6db8e7a0e0a9038ebba.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*D2Y0bOiPnn4iGybgu_bvKQ.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">授权给作者的图像</p></figure><blockquote class="my mz na"><p id="eee0" class="ky kz nb la b lb lc ju ld le lf jx lg nc li lj lk nd lm ln lo ne lq lr ls lt im bi translated">A100 GPU。加速我们时代最重要的工作。<br/>T5】英伟达</p></blockquote><p id="00ff" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么这在现实世界中到底意味着什么呢？</p><p id="a93c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">首先要注意的是，这条GPU线是专门针对深度学习和其他高计算人工智能应用而设计的。第二点要注意的是，与它的前辈相比，A100提供了高达<strong class="la iu">20倍的性能，而代码变化为零</strong>。这是一个巨大的飞跃。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nz"><img src="../Images/d4aae0b2e5977e7943a6f2179fe18110.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zRPgHEH28UhalEt2weY3jA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">高性能计算吞吐量(图像来源Nvidia)</p></figure><p id="99e4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> A100 GPU技术规格</strong></p><p id="b343" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">A100的<a class="ae nl" href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet.pdf" rel="noopener ugc nofollow" target="_blank">数据表</a>的亮点包括:</p><ul class=""><li id="6c0d" class="oa ob it la b lb lc le lf lh oc ll od lp oe lt of og oh oi bi translated"><strong class="la iu"> 40GB </strong>的GPU内存</li><li id="c11b" class="oa ob it la b lb oj le ok lh ol ll om lp on lt of og oh oi bi translated"><strong class="la iu">1.6 TB/秒</strong>内存带宽</li><li id="8ee3" class="oa ob it la b lb oj le ok lh ol ll om lp on lt of og oh oi bi translated">深度学习的<strong class="la iu"> 312万亿次浮点运算</strong>(前代的20倍)</li><li id="79e1" class="oa ob it la b lb oj le ok lh ol ll om lp on lt of og oh oi bi translated"><strong class="la iu"> 250W-450W </strong>最大功耗</li><li id="80a3" class="oa ob it la b lb oj le ok lh ol ll om lp on lt of og oh oi bi translated"><strong class="la iu">结构稀疏性</strong>A100s张量内核的架构支持高达2倍的“稀疏”模型(其参数集包含大量零的模型，非常适合NLP应用)性能增益。</li></ul><p id="bdf6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果其中一个功能不足以满足您的使用案例，不要担心，因为由于NVIDIA的一些聪明的SDK支持，这些功能将<strong class="la iu">扩展到1000个A100 GPUs。</strong></p><h1 id="ef7e" class="mb mc it bd md me nf mg mh mi ng mk ml jz nh ka mn kc ni kd mp kf nj kg mr ms bi translated"><strong class="ak">对A100进行基准测试；训练伯特</strong></h1><p id="c9bf" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated"><a class="ae nl" href="https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html" rel="noopener ugc nofollow" target="_blank"> BERT </a>代表来自变压器的双向编码器表示。最近由Google发布的BERT是一个自然语言处理(NLP) ML模型。由于完全训练模型需要高计算量，BERT经常用于基准测试。</p><p id="1912" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">A100产生了一些惊人的结果:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/a08d839486bba219f0d420ddeb870587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zDRyPa3N3zC0q7gSIxN9gQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">性能基准训练BERT(图片来源Nvidia)</p></figure><p id="bcac" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">那么谷歌人工智能平台的深度学习容器中有哪些A100选项呢？</p><p id="01d1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu">每台虚拟机高达16个GPUs】</strong></p><p id="5863" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">对于要求苛刻的工作负载，可以选择<strong class="la iu"> a2-megagpu-16g深度学习容器。</strong>使用<strong class="la iu">16</strong>T8】A100 GPU，这提供了惊人的<strong class="la iu">640 GB GPU内存</strong>，并在使用新的稀疏特性时，在单个虚拟机中提供高达<strong class="la iu"> 10 petaflops的FP16或10 petaflops的int8的有效性能</strong>。哇哦。我们不得不把这些数字读两遍。</p><p id="67d7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，我们必须加倍占用系统内存；惊人的1.3 TB。并且不用担心访问它的任何瓶颈，内存总线支持高达<strong class="la iu">9.6 TB/s。</strong></p><p id="fb85" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">足以消耗最苛刻的工作负载…</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nn"><img src="../Images/1819dc7039a2ce01e86950d6fedf05c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*piffyt5Gwg4D6vJwN6Haqw.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">授权给作者的图像</p></figure><p id="05cf" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">当然，A100驱动的虚拟机也有较小的配置，允许您匹配应用对GPU计算能力的需求。</p><h1 id="48be" class="mb mc it bd md me nf mg mh mi ng mk ml jz nh ka mn kc ni kd mp kf nj kg mr ms bi translated">后续步骤</h1><p id="0c33" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">1.阅读<a class="ae nl" href="https://cloud.google.com/blog/products/ai-machine-learning/introducing-deep-learning-containers-consistent-and-portable-environments" rel="noopener ugc nofollow" target="_blank">谷歌云AI平台发布说明</a></p><p id="f380" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">2.了解更多关于<a class="ae nl" href="https://www.ancoris.com/solutions/data_analytics_ai" rel="noopener ugc nofollow" target="_blank">安科瑞斯数据，分析&amp;人工智能</a></p><p id="f345" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">3.与<a class="ae nl" href="https://www.linkedin.com/in/google-cloud-platform/" rel="noopener ugc nofollow" target="_blank">作者</a>连线</p></div></div>    
</body>
</html>