<html>
<head>
<title>How to train graph convolutional network models in a graph database</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在图形数据库中训练图形卷积网络模型</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-train-graph-convolutional-network-models-in-a-graph-database-5c919a2f95d7?source=collection_archive---------19-----------------------#2020-10-01">https://towardsdatascience.com/how-to-train-graph-convolutional-network-models-in-a-graph-database-5c919a2f95d7?source=collection_archive---------19-----------------------#2020-10-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="64a1" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/making-sense-of-big-data" rel="noopener" target="_blank">理解大数据</a></h2><div class=""/><div class=""><h2 id="0b8b" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">在图形数据库中训练GCN模型可以利用图形数据库的分布式计算框架。对于现实应用中的大型图形，这是一个可扩展的解决方案。</h2></div><h1 id="6601" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">什么是图卷积网络？</h1><p id="1abd" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">典型的前馈神经网络将每个数据点的特征作为输入，并输出预测。利用训练数据集中每个数据点的特征和标签来训练神经网络。这种框架已被证明在各种应用中非常有效，例如人脸识别、手写识别、对象检测，其中数据点之间不存在明确的关系。但是，在某些用例中，当给定<em class="mf"> v </em> ( <em class="mf"> i </em>)和<em class="mf"> v </em> ( <em class="mf"> j </em>)之间的关系时，对于一个数据点<em class="mf"> v </em> ( <em class="mf"> i </em>)的预测不仅可以由其自身的特征来确定，还可以由其他数据点<em class="mf"> v </em> ( <em class="mf"> j </em>)的特征来确定。例如，期刊论文的主题(例如计算机科学、物理学或生物学)可以从论文中出现的单词频率中推断出来。另一方面，论文中的参考文献也可以在预测论文主题时提供信息。在这个例子中，我们不仅知道每个数据点的特征(词频)，还知道数据点之间的关系(引用关系)。那么我们如何将它们结合起来以提高预测的准确性呢？</p><p id="060c" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">通过应用图形卷积网络(GCN)，单个数据点及其连接的数据点的特征将被组合并输入到神经网络中。我们再以论文分类问题为例。在引用图(图1)中，每篇论文由引用图中的一个顶点表示。顶点之间的边表示引用关系。为简单起见，这些边被视为无向的。每张纸及其特征向量分别表示为<em class="mf"> v_i </em>和<em class="mf"> x_i </em>。根据Kipf和Welling [1]的GCN模型，我们可以使用具有一个隐含层的神经网络预测论文的主题，其步骤如下:</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ml"><img src="../Images/3fb18daf80d8d17f6a515effda938676.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OL9YsKn-Pb5La96X3Ft26w.png"/></div></div></figure><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/f3e9b78b59ef89d8127c305ca4bc1f62.png" data-original-src="https://miro.medium.com/v2/resize:fit:1216/0*JcL0SPAsxaOrYkDK"/></div><p class="my mz gj gh gi na nb bd b be z dk translated">图一。(图片由作者提供)图卷积网络的架构。每个顶点<em class="nc"> vi </em>代表引用图中的一篇论文。xi是<em class="nc"> vi </em>的特征向量。<em class="nc"> W </em> (0)和<em class="nc"> W </em> (1)是三层神经网络的权重矩阵。<em class="nc"> A </em>、<em class="nc"> D、</em>和<em class="nc"> I </em>分别是邻接矩阵、度矩阵和单位矩阵。水平和垂直传播分别以橙色和蓝色突出显示。</p></figure><p id="550c" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">在上面的工作流中，步骤1和4执行水平传播，其中每个顶点的信息被传播到其邻居。而步骤2和5执行垂直传播，其中每层上的信息被传播到下一层。(参见图1)对于具有多个隐藏层的GCN，将会有水平和垂直传播的多次迭代。值得注意的是，每次执行水平传播时，顶点的信息在图上传播一跳。在本例中，水平传播执行了两次(步骤2和4)，因此每个顶点的预测不仅取决于其自身的特征，还取决于距其2跳距离内的所有顶点的特征。此外，由于权重矩阵W(0)和W(1)由所有顶点共享，神经网络的大小不必随着图的大小而增加，这使得该方法可扩展。</p><h1 id="806a" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">为什么您需要一个GCN图形数据库</strong></h1><p id="cee5" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated"><strong class="ll jd">通过融合每个顶点的图形特征，GCN可以以较低的标注率达到较高的准确率。</strong>在Kipf和Welling的工作[1]中，使用图中5%的标记顶点(实体)可以获得超过80%的准确度。考虑到整个图在传播过程中需要参与计算，训练一个GCN模型的空间复杂度为O(<em class="mf">E</em>+<em class="mf">V</em>*<em class="mf">N</em>+<em class="mf">M</em>)，其中<em class="mf"> E </em>和<em class="mf"> V </em>是图中的边数和顶点数，<em class="mf"> N </em>是每个顶点的特征数，<em class="mf"> M </em>是大小</p><p id="63a4" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">对于工业应用来说，一个图可以有数亿个顶点和数十亿条边，这意味着邻接矩阵<em class="mf"> A </em>，特征矩阵<em class="mf"> X </em>和其他中间变量(图1)在模型训练期间都可以消耗万亿字节的内存。这种挑战可以通过在图形数据库(GDB)中训练GCN来解决，其中图形可以分布在多节点集群中，并且部分存储在磁盘上。此外，图结构的用户数据，如社交图、消费图和移动图，首先存储在数据库管理系统中。数据库内模型训练还避免了将图形数据从DBMS导出到其他机器学习平台，从而更好地支持对进化训练数据的连续模型更新。</p><h1 id="f67f" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated"><strong class="ak">如何在图形数据库中训练GCN模型</strong></h1><p id="9584" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在本节中，我们将在TigerGraph cloud上提供一个图表数据库(带有免费层)，加载一个引用图表，并在数据库中训练一个GCN模型。按照下面的步骤，您将在15分钟内拥有一个纸张分类模型。</p><p id="a01b" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">按照<a class="ae nd" href="https://www.tigergraph.com/2020/01/20/taking-your-first-steps-in-learning-tigergraph-cloud/" rel="noopener ugc nofollow" target="_blank">创建您的第一个TigerGraph实例</a>(前3个步骤)来<strong class="ll jd">在TigerGraph cloud </strong>上提供一个免费实例。在步骤1中，选择“图卷积网络”作为初学者工具包。在步骤3中，选择TG.Free。(如果找不到初学者工具包，请参阅脚注)</p><p id="6a3c" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">按照<a class="ae nd" href="https://www.tigergraph.com/2020/01/20/taking-your-first-steps-in-learning-tigergraph-cloud/" rel="noopener ugc nofollow" target="_blank">tiger graph云门户</a>入门和<strong class="ll jd">登录GraphStudio </strong>。在<em class="mf">将数据映射到图形</em>页面，您将看到数据文件是如何映射到图形的。在这个初学者工具包中，<a class="ae nd" href="https://relational.fit.cvut.cz/dataset/CORA" rel="noopener ugc nofollow" target="_blank"> Cora引用数据</a>文件已经上传到实例中。Cora数据集有三个文件:</p><ul class=""><li id="e495" class="ne nf it ll b lm mg lp mh ls ng lw nh ma ni me nj nk nl nm bi translated">cite.csv有三列，paperA_id、paper _ id和weight。前两列用于创建论文之间的引用边缘。CITE边上的权重将由后续步骤中的查询更新，因此不需要加载最后一列。应该注意的是，这个初学者工具包中的文件为每篇论文添加了self链接，以简化查询实现。这与Kipf和Welling的方法一致[1]。</li><li id="0acb" class="ne nf it ll b lm nn lp no ls np lw nq ma nr me nj nk nl nm bi translated">paper_tag.csv有两列:paper_id和class_label。此文件中的每一行都将用于创建一个纸张顶点，其中包含文件中填充的纸张id和纸张类别。</li><li id="4f40" class="ne nf it ll b lm nn lp no ls np lw nq ma nr me nj nk nl nm bi translated">content.csv有三列:paper_id、word_id和weight。前两列用于在纸张和文字之间创建散列边缘。散列边缘将用于存储稀疏词袋特征向量。散列边上的权重将由后续步骤中的查询更新，因此不需要加载最后一列。</li></ul><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ns"><img src="../Images/ef7b7466d0714aac1d6a7bf4183804d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*U9Zxu2bwFvYt_CXe"/></div></div><p class="my mz gj gh gi na nb bd b be z dk translated"><em class="nc"> (Image by Author)在Map Data To Graph页面，可以看到csv文件中的列是如何映射到引用图中的顶点和边的。</em></p></figure><p id="e1fa" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated"><strong class="ll jd">进入<em class="mf">加载数据</em>页面，点击<em class="mf">开始/恢复</em>加载</strong>。加载完成后，您可以在右侧看到图表统计信息。Cora数据集有2708篇论文，1433个不同的词(特征向量的维度)，7986个引用关系。每张纸都标有7种不同类别中的一种。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ns"><img src="../Images/604b03db3242773a9ce9b0667c967c34.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*VDz-_kG9CO_seits"/></div></div><p class="my mz gj gh gi na nb bd b be z dk translated"><em class="nc">(图片作者)在</em>加载数据页面，加载完成后，可以在右边看到图表统计。</p></figure><p id="3570" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">在<em class="mf"> Explore Graph </em>页面中，您可以看到我们刚刚在引用图的顶部创建了一个神经网络。引文图表中的每篇论文都与多个单词相关联。散列边缘上的权重因此形成稀疏特征向量。1433个不同的单词连接到隐藏层中的16个神经元，隐藏层连接到输出层中的7个神经元(代表7个不同的类别)。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ns"><img src="../Images/bb4c1734c055ceb74d460387dfbf29c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*z5jz2rW8gQ2UaqsV"/></div></div><p class="my mz gj gh gi na nb bd b be z dk translated"><em class="nc">(图片由作者提供)在浏览图形页面中，您可以使用“拾取顶点”和“从顶点展开”来显示图形中的顶点和边。</em></p></figure><p id="0647" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">在<em class="mf">编写查询</em>页面中，您会发现GCN所需的查询已经添加到数据库中。这些查询是用TigerGraph的查询语言GSQL编写的。<strong class="ll jd">点击安装所有查询</strong>将所有GSQL查询编译成C++代码。您还可以在此页面上看到自述文件查询。按照以下步骤训练GCN。</p><h2 id="f9c1" class="nt ks it bd kt nu nv dn kx nw nx dp lb ls ny nz ld lw oa ob lf ma oc od lh iz bi translated"><strong class="ak">运行初始化查询。</strong></h2><p id="f494" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">该查询首先通过将纸张<em class="mf"> i </em>和<em class="mf"> j </em>之间的权重指定为<em class="mf">e _ ij</em>= 1/(<em class="mf">d _ I</em>*<em class="mf">d _ j</em>)来归一化引用边缘上的权重，其中<em class="mf"> d_i </em>、<em class="mf"> d_j </em>是纸张<em class="mf"> i </em>和纸张<em class="mf"> j </em>的引用程度第二，它通过将纸张<em class="mf"> p </em>和单词<em class="mf"> w </em>之间的权重指定为<em class="mf">e</em>_<em class="mf">pw</em>= 1/<em class="mf">DP</em>来标准化HAS边缘上的权重，其中<em class="mf"> dp </em>是纸张<em class="mf"> w </em>的HAS出度。第三，它对140、500和1000个纸顶点进行采样，用于测试、验证和训练集。</p><h2 id="d027" class="nt ks it bd kt nu nv dn kx nw nx dp lb ls ny nz ld lw oa ob lf ma oc od lh iz bi translated"><strong class="ak">运行权重_初始化查询</strong></h2><p id="60b0" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">该查询使用Glorot和Bengio的方法初始化神经网络的权重[2]。神经网络的输入层有1433个神经元，对应于词汇量的大小，隐层有16个神经元，输出层有7个神经元，对应于论文的7个类别。</p><h2 id="1bf8" class="nt ks it bd kt nu nv dn kx nw nx dp lb ls ny nz ld lw oa ob lf ma oc od lh iz bi translated"><strong class="ak">运行培训查询</strong></h2><p id="76df" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">此查询使用Kipf和Welling [1]中使用的相同超参数来训练图形卷积神经网络。具体来说，使用交叉熵损失、丢失正则化和L2正则化(5e-4)对第一层的模型进行评估。Adam优化器已在此查询中实现，批处理梯度下降用于训练。查询完成后，将显示根据训练和验证数据评估的损失以及根据测试数据评估的预测准确性。如训练查询的输出所示，在5个训练时期之后，准确率达到53.2%。为了更高的准确性，可以将历元数设置为查询输入。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ns"><img src="../Images/835ae89a3e2ce426d217410024cfce4b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*bn5DpcO5EfR6XsgG"/></div></div><p class="my mz gj gh gi na nb bd b be z dk translated">(图片由作者提供)训练查询输出训练和验证数据集的交叉熵损失，以及每个训练时期的测试数据集的预测精度。</p></figure><h2 id="2aa1" class="nt ks it bd kt nu nv dn kx nw nx dp lb ls ny nz ld lw oa ob lf ma oc od lh iz bi translated"><strong class="ak">运行预测查询</strong></h2><p id="bcba" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">该查询将训练好的GCN应用于图中的所有论文，并将结果可视化。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi ns"><img src="../Images/4d1461f8f48e2679cf5a3676b0241776.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*B2azdJbi9kEVMDfp"/></div></div><p class="my mz gj gh gi na nb bd b be z dk translated">(图片由作者提供)预测查询输出引用图中每篇论文的预测类和标记类。</p></figure><h2 id="cb81" class="nt ks it bd kt nu nv dn kx nw nx dp lb ls ny nz ld lw oa ob lf ma oc od lh iz bi translated"><strong class="ak">GSQL查询概述</strong></h2><p id="1b32" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在最后一节中，我们将深入查询，看看TigerGraph的大规模并行处理框架是如何支持训练GCN的。简言之，TigerGraph将每个顶点视为一个可以存储、发送和处理信息的计算单元。我们将选择查询中的一些语句来说明GSQL语句是如何执行的。</p><p id="40e6" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated"><a class="ae nd" href="https://docs.tigergraph.com/dev/gsql-ref/querying/select-statement#from-clause-vertex-and-edge-sets" rel="noopener ugc nofollow" target="_blank"> <strong class="ll jd">选择语句:</strong> </a></p><p id="e963" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">先来看查询<em class="mf">初始化</em>。第一行将初始化一个顶点集Papers，它包括图中所有的PAPER顶点。在下一个SELECT语句中，我们将从顶点集开始，遍历所有引用的边。对于每条边(由e表示)，其边权重是从其源顶点(由s表示)和其目标顶点(由t表示)的外向度并行计算的。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi oe"><img src="../Images/e0243d85ac9d08a1e4ded42db1eeb731.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ufu9KWtq_YZh-fsVlCwjww.png"/></div></div></figure><p id="a869" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated"><a class="ae nd" href="https://docs.tigergraph.com/start/accumulators-tutorial#introduction" rel="noopener ugc nofollow" target="_blank"> <strong class="ll jd">累计和后累计</strong> </a></p><p id="90ee" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">现在我们来看看查询<em class="mf">培训</em>。下面的块执行水平和垂直传播。正如我们在上一节中讨论的，水平传播是我们将信息从每个顶点发送到它的邻居，这是由ACCUM之后的行完成的。它将每个目标顶点(由t.@z_0表示)的特征向量计算为其源顶点(由s.@zeta_0表示)的特征向量之和，并通过e.weight进行加权。它首先对每个顶点上的特征向量应用ReLU激活函数和丢失正则化。然后它将隐藏层特征(由s.@z_0引用)传播到输出层。同样，TigerGraph将根据边和顶点并行化ACCUM和POST-ACCUM块中的计算。</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi of"><img src="../Images/49f9be9c0d5ccd9139092c1c48cd648b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*l4CsxZsxfAhLP022r_pARQ.png"/></div></div></figure><p id="d015" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated"><a class="ae nd" href="https://docs.tigergraph.com/dev/gsql-ref/querying/operators-functions-and-expressions#user-defined-functions" rel="noopener ugc nofollow" target="_blank"> <strong class="ll jd">用户自定义功能</strong> </a></p><p id="c5eb" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">激活函数用C++实现，并导入到TigerGraph用户自定义函数库。下面是ReLU函数(ReLU_ArrayAccum)的实现</p><figure class="mm mn mo mp gt mq gh gi paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="gh gi og"><img src="../Images/8280bbf569b30b7ee8f921e2a7996a8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*b6PhgszPw7wRFQCIrkTTAw.png"/></div></div></figure><h1 id="3b45" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">结论</h1><p id="323d" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">在图形数据库中训练GCN模型利用了图形数据库的分布式计算框架。对于现实应用中的大型图形，这是一个可扩展的解决方案。在本文中，我们解释了GCN如何将每个节点的特征与图特征结合起来，以提高图中节点分类的准确性。我们还展示了一个使用TigerGraph云服务在引用图上训练GCN模型的分步示例。</p><h1 id="5f35" class="kr ks it bd kt ku kv kw kx ky kz la lb ki lc kj ld kl le km lf ko lg kp lh li bi translated">参考:</h1><p id="d1f0" class="pw-post-body-paragraph lj lk it ll b lm ln kd lo lp lq kg lr ls lt lu lv lw lx ly lz ma mb mc md me im bi translated">[1]托马斯。n .基普夫和马克斯·韦林，<em class="mf"> ICLR </em> (2017)</p><p id="3371" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">[2]格洛特和本吉奥(2010年)</p><p id="c433" class="pw-post-body-paragraph lj lk it ll b lm mg kd lo lp mh kg lr ls mi lu lv lw mj ly lz ma mk mc md me im bi translated">*如果“GCN数据库内机器学习(引文图表)”初学者工具包不可用，您可以(1)在步骤1中选择“空白”初学者工具包。(2)按照步骤2和3登录GraphStudio。(3)下载<a class="ae nd" href="https://github.com/ChangranLiu/Machine-Learning-in-TigerGraph/blob/master/GCN/GCNonCitationGraph.tar.gz" rel="noopener ugc nofollow" target="_blank">GCNonCitationGraph.tar.gz</a>和所有的。来自<a class="ae nd" href="https://github.com/ChangranLiu/Machine-Learning-in-TigerGraph/tree/master/GCN" rel="noopener ugc nofollow" target="_blank">https://github . com/changran Liu/Machine-Learning-in-tiger graph/tree/master/GCN</a>的/data文件夹中的csv文件。(4)使用“导入现有解决方案”从GraphStudio主页导入. tar.gz文件。(5)上传所有的。从映射数据到图形页面的csv文件。</p></div></div>    
</body>
</html>