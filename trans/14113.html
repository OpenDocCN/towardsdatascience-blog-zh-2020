<html>
<head>
<title>Overview: State-of-the-Art Machine Learning Algorithms per Discipline &amp; per Task</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">概述:每个学科和每个任务的最先进的机器学习算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/overview-state-of-the-art-machine-learning-algorithms-per-discipline-per-task-c1a16a66b8bb?source=collection_archive---------5-----------------------#2020-09-29">https://towardsdatascience.com/overview-state-of-the-art-machine-learning-algorithms-per-discipline-per-task-c1a16a66b8bb?source=collection_archive---------5-----------------------#2020-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="ad50" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解自然语言处理、计算机视觉、语音识别和推荐系统的最佳算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/259272a326439ba49e11143ee30c149d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PpiIpPzKoSCOQP3AoVtP-A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">CV =计算机视觉，NLP =自然语言处理，RS =推荐系统，SR =语音识别|来源:来自作者。</p></figure><p id="f5b4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">机器学习算法正在兴起。每年都有新的技术出现，超越了当前领先的算法。其中一些只是现有算法的微小进步或组合，而另一些是新创造的，并带来了惊人的进步。对于大多数技术，已经有很好的文章解释了其背后的理论，其中一些还提供了代码和教程实现。目前还没有人提供当前领先算法的概述，所以这个想法出现了，根据所取得的结果(使用性能分数)来呈现每个任务的最佳算法。当然，还有更多的任务，并不是所有的任务都可以呈现。我试图选择最受欢迎的领域和任务，并希望这可能有助于更好地理解。本文将重点讨论计算机视觉、自然语言处理和语音识别。</p><p id="ac23" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">文中介绍了所有的领域、任务和一些算法。如果您只对某个子部分感兴趣，请跳到您想深入了解的部分。</p></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="5aef" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">计算机视觉</h1><p id="1aa1" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">计算机视觉是机器学习中研究最多、最热门的领域之一。它用于解决许多日常问题，并连续涉及多种应用，其中最受欢迎的是自动驾驶汽车的愿景。我们将要研究的任务是<em class="my">语义分割、图像分类和目标检测。</em></p><h2 id="df7d" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">语义分割</h2><p id="d61f" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">语义分割可以被视为在像素级别上理解图像的结构和组件。语义分割方法试图预测图像中的结构和对象。为了更好地理解，可以在下面看到街道场景的语义分段:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nl"><img src="../Images/7ffd90e4085e4c51092e85b43474de92.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XShGSo5wdlVBY0wXzKXJlw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">用SegNet进行语义分割【https://mi.eng.cam.ac.uk/projects/segnet/ T4】</p></figure><p id="57fc" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">目前领先的算法<strong class="la iu"> HRNet-OCR </strong>是由Nvidia的Tao等人在2020年提出的。它实现了85.1%的平均交集/并集(平均IOU)。HRNet-OCR对图像进行缩放，并对每个缩放比例使用密集遮罩。然后，所有尺度的预测“通过在掩模之间执行逐像素乘法，然后在不同尺度之间进行逐像素求和，从而获得最终结果”[1]。</p><p id="c3a5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">查看Github来的技术:<br/><a class="ae nm" href="https://github.com/HRNet/HRNet-Semantic-Segmentation" rel="noopener ugc nofollow" target="_blank">https://github.com/HRNet/HRNet-Semantic-Segmentation</a></p><p id="6b9a" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="b6f8" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2006.06882v1.pdf" rel="noopener ugc nofollow" target="_blank">高效网-L2+NAS-FPN </a> —帕斯卡VOC</li><li id="be6f" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2004.08955v1.pdf" rel="noopener ugc nofollow" target="_blank"> ResNeSt-269 </a> — PASCAL上下文</li><li id="2bc6" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2007.13138v1.pdf" rel="noopener ugc nofollow" target="_blank"> VMVF </a> —ScanNet</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="5029" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">想看更多这样的故事？每天只需要0.13美元。</h1><h2 id="b80b" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated"><a class="ae nm" href="https://medium.com/@hucker.marius/membership" rel="noopener">开始使用</a></h2></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h2 id="0b67" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">图像分类</h2><p id="3469" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">不同于语义分割，图像分类不关注图像上的区域，而是关注图像的整体。这个学科试图通过分配一个标签来对每个图像进行分类。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ob"><img src="../Images/416bb0c3d6cdb91c5892a8f44b3173e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hrR1c0QH1oxNnyafWzbjTQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:图片由作者提供。</p></figure><p id="261d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> FixEfficientNet </strong>已经于2020年4月20日与脸书人工智能研究团队的相应论文一起首次提交[2][3]。它目前是最先进的，在ImageNet数据集上具有最好的结果，480M参数，前1名准确率为88.5%，前5名准确率为98.7%。FixRes是Fix Resolution的简称，它试图为用于训练时间的RoC(分类区域)或用于测试时间的crop保持固定的大小。EfficientNet是CNN维度的复合缩放，提高了准确性和效率。</p><p id="4832" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">欲了解FixEfficientNet的更多信息，<a class="ae nm" rel="noopener" target="_blank" href="/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c">请阅读此</a>。</p><p id="e882" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="4cc8" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1912.11370v3.pdf" rel="noopener ugc nofollow" target="_blank"> BiT-L </a> — CIFAR-10</li><li id="d863" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2007.03347v2.pdf" rel="noopener ugc nofollow" target="_blank">Wide-ResNet-101</a>—STL-10</li><li id="56a4" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2001.09136v4.pdf" rel="noopener ugc nofollow" target="_blank">分支/合并CNN +均质过滤胶囊</a> — MNIST</li></ul><h2 id="90ac" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">目标检测</h2><p id="2070" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">对象检测是识别图像中某一类对象的实例的任务。</p><p id="4418" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">目前领先的物体检测技术是谷歌大脑团队(Tan等人)在2020年首次提出的<strong class="la iu">Efficient-Det D7x</strong>[4]。它实现了74.3的AP50 ( <a class="ae nm" href="https://medium.com/@yanfengliux/the-confusing-metrics-of-ap-and-map-for-object-detection-3113ba0386ef" rel="noopener">了解AP50的更多信息:在50 </a>的固定IoU阈值下的平均精度)和55.1的box AP。Efficient-Det是<strong class="la iu"> EfficientNets </strong>与双向特征金字塔网络(<strong class="la iu"> BiFPNs </strong>)的组合。</p><p id="fd65" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如上面简要解释的那样，<strong class="la iu"> EfficientNet </strong>是CNN维度的复合缩放，它提高了准确性和效率。更多关于EfficientNet的信息，你可以<a class="ae nm" rel="noopener" target="_blank" href="/state-of-the-art-image-classification-algorithm-fixefficientnet-l2-98b93deeb04c">点击这里</a>。</p><p id="bc39" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在计算机视觉中，提高精确度的典型方法是创建具有不同分辨率的同一图像的多个副本。这导致了所谓的金字塔，因为最小的图像被布置为顶层，而最大的图像被布置为底层。要素金字塔网络代表了这样一个金字塔。双向意味着不仅有自上而下的方法，同时也有自下而上的方法。每个双向路径都被用作特征网络层，这导致了bip pn。它有助于提高准确性和速度。有关bip pn的更多信息，<a class="ae nm" href="https://medium.com/@nainaakash012/efficientdet-scalable-and-efficient-object-detection-ea05ccd28427" rel="noopener">点击此处</a>。</p><p id="a21f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="df96" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2008.06439v1.pdf" rel="noopener ugc nofollow" target="_blank">竞技表演</a> —帕斯卡VOC</li><li id="b07d" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1910.04093v1.pdf" rel="noopener ugc nofollow" target="_blank">补丁细化</a> — KITTI Cars Easy</li><li id="f62b" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated">IterDet  — CrowdHuman</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="0206" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">自然语言处理</h1><p id="44f6" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">自然语言处理的常见定义如下:</p><blockquote class="oc od oe"><p id="7fb3" class="ky kz my la b lb lc ju ld le lf jx lg of li lj lk og lm ln lo oh lq lr ls lt im bi translated">NLP是人工智能的一个子领域，它赋予机器阅读、理解和从人类语言中获取意义的能力。</p></blockquote><p id="fa7c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">NLP任务的范围很广，正如定义所揭示的，它们都试图从我们的语言中推断出一些含义，并根据我们的语言及其组成部分进行计算。基于NLP的算法可以在各种应用和行业中找到。仅举几个你可能每天都会遇到的应用程序，如翻译器、社交媒体监控、聊天机器人、垃圾邮件过滤器、微软word或messengers中的语法检查和虚拟助手。</p><h2 id="abe3" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">情感分析</h2><p id="3a4a" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">情感分析是文本挖掘的一个领域，用于对文本数据中的情感进行解释和分类。目前领先的算法之一是<strong class="la iu"> BERT </strong>，它在2019年的SST-5细粒度分类数据集上实现了55.5的准确率。最初的<a class="ae nm" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>由谷歌人工智能团队发布【5】。</p><p id="f19f" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">BERT代表来自变压器的<strong class="la iu">双向编码器表示，并应用变压器技术的双向训练。Transformer技术是一种用于语言建模的注意力模型，以前只应用于一个方向。从左到右或从右到左解析文本。更多细节，请阅读这篇伟大的<a class="ae nm" rel="noopener" target="_blank" href="/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270">文章</a>。</strong></p><p id="93db" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="9307" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1910.10683v3.pdf" rel="noopener ugc nofollow" target="_blank">T5–3B</a>—SST-2二元分类</li><li id="eeca" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://paperswithcode.com/paper/sentiment-classification-using-document" rel="noopener ugc nofollow" target="_blank">NB-加权-BON+dv-余弦</a> — IMDb</li></ul><h2 id="bf19" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">语言建模</h2><p id="55ee" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">语言建模是基于现有文本/先前单词来预测文本中的下一个单词或字母的任务。GPT-2模型被赋予了两个关于生活在安第斯山脉的一群独角兽的句子，它创造了一个惊人的故事。这里可以看<a class="ae nm" href="https://openai.com/blog/better-language-models/" rel="noopener ugc nofollow" target="_blank">。</a></p><p id="a826" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在语言建模中，表现最好的算法之一可以在<strong class="la iu"> Megatron-LM </strong>中找到。这个模型和<a class="ae nm" href="https://arxiv.org/pdf/1909.08053v4.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>是英伟达团队在2019年首次提出的。一个类似GPT-2的模型在83000亿个参数上进行训练。它能够将当前最高水平的15.8分降低到只有10.8分的测试困惑度。使用的数据集是WikiText103 [6]。</p><p id="147b" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该模型利用了变压器网络。在他们的工作中，变形层由一个自我注意块和两层、多层感知机(MLP)组成。在每个块中，使用模型并行性。这有助于减少通信并保持GPU的计算能力。GPU的计算被复制以提高模型的速度。</p><p id="b080" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="90e4" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2005.14165v4.pdf" rel="noopener ugc nofollow" target="_blank">GPT-3</a>——宾州树木银行</li><li id="db94" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated">GPT-2——维基百科2，文本8，环境8</li></ul><h2 id="2780" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">机器翻译</h2><p id="f5be" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">机器翻译被用于谷歌翻译或www.deepl.com翻译等应用中。它用于使用算法将文本翻译成另一种语言。</p><p id="b599" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">这个领域最有前途的算法之一是<strong class="la iu"> Transformer Big +BT。</strong>由谷歌大脑团队于2018年在<a class="ae nm" href="https://arxiv.org/pdf/1808.09381v2.pdf" rel="noopener ugc nofollow" target="_blank">本文</a>中提出。一般来说，变压器是处理序列和机器翻译的最先进技术。转换器不使用循环连接，而是同时解析序列[7]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/df5a5e33539f786e1fd8e9a7bbaceb31.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/1*2COcFNg6M0PzSmHEOj6Ypw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">输入以绿色表示，提供给模型(蓝色)并转换为输出(紫色)。<a class="ae nm" href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/" rel="noopener ugc nofollow" target="_blank"> GIF来源</a></p></figure><p id="1c81" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">正如你在上面的gif中看到的，输入和输出是不同的。这是由于两种不同的语言，例如输入是英语，而输出语言是德语。为了提高速度，并行化是该模型的一个关键方面。这个问题通过使用CNN和注意力模型来解决。<a class="ae nm" href="https://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">自我关注</a>有助于提高速度和对某些单词的关注，而CNN用于并行化[8]。更多关于变形金刚的信息，请阅读这篇<a class="ae nm" rel="noopener" target="_blank" href="/transformers-141e32e69591">伟大的文章</a>。作者应用<strong class="la iu">反向翻译(BT) </strong>进行训练。在这种方法中，训练数据集被翻译成目标语言，并且算法将其翻译回原始语言。然后可以很好地观察表演[7]。</p><p id="86e7" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="0a41" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2003.03977v1.pdf" rel="noopener ugc nofollow" target="_blank">垫子+膝盖</a> — IWSLT2014德语-英语</li><li id="e225" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://openreview.net/pdf?id=HyGhN2A5tm" rel="noopener ugc nofollow" target="_blank"> MADL </a> — WMT2016英德</li><li id="9077" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1606.02891v2.pdf" rel="noopener ugc nofollow" target="_blank">注意力编码器-解码器</a> +BPE — WMT2016德语-英语</li></ul><h2 id="e0c1" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">文本分类</h2><p id="8340" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">文本分类的任务是给一个句子、一篇文章或一个单词分配一个特定的类别。目前在三个不同数据集(DBpedia、AG News和IMDb)上领先的算法是<strong class="la iu"> XLNet。</strong></p><p id="cbaa" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">谷歌人工智能团队在2019年首次展示了<a class="ae nm" href="https://arxiv.org/pdf/1906.08237v2.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>和技术<strong class="la iu"> XLNet </strong>。它在20个任务中改进了领先的算法BERT。<strong class="la iu"> XLNet </strong>首创的方法叫做<strong class="la iu">置换语言建模</strong>。它利用了单词的排列。假设你有三个单词，顺序如下[w1，w2，w3]。然后检索所有排列，这里是3*2*1 = 6个排列。显然，对于长句，这导致了无数的排列。位于预测字(例如w2)之前的所有字用于预测[9]:</p><pre class="kj kk kl km gt oj ok ol om aw on bi"><span id="71b5" class="mz mc it ok b gy oo op l oq or">w3 w1 <strong class="ok iu">w2</strong><br/>w1 <strong class="ok iu">w2</strong> w3<br/>w1 w3 <strong class="ok iu">w2</strong><br/> …</span></pre><p id="5466" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在行1中，w3和w 1用于w2的预测。在行2中，只有w1用于预测，依此类推。为了更好地理解这项技术，你可以在这里阅读更多相关内容。</p><p id="2f15" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="7e9a" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1803.11175v2.pdf" rel="noopener ugc nofollow" target="_blank">使用_T + CNN </a> — TREC-6</li><li id="83b7" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1902.07153v2.pdf" rel="noopener ugc nofollow" target="_blank">SGC</a>—20条新闻</li></ul><h2 id="ba08" class="mz mc it bd md na nb dn mh nc nd dp ml lh ne nf mn ll ng nh mp lp ni nj mr nk bi translated">问题回答</h2><p id="103b" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">问答是训练一个算法来回答问题的任务(通常基于阅读理解)。这项任务是迁移学习的一部分，因为要学习给定的文本数据库，并存储知识以在稍后的时间点回答问题。</p><p id="c04d" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">通过T5–11B，谷歌人工智能团队在四个不同的数据集上实现了最先进的基准测试:GLUE、SuperGLUE、SQuAD和CNN/Daily Mail。T5代表文本到文本转换转换器中的五个T，而11B代表用于训练算法的110亿个数据集。与BERT和其他优秀的算法相比，T5–11B不输出输入句子的标签。相反，正如名称所示，输出也是一个文本字符串[10]。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi os"><img src="../Images/dc55f6ba8db82c55d21ae284fd4c2db2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/1*-Ctw3OaZUmmoETi3AImIsw.gif"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源:<a class="ae nm" href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" rel="noopener ugc nofollow" target="_blank">https://ai . Google blog . com/2020/02/exploring-transfer-learning-with-t5 . html</a></p></figure><p id="9981" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">论文<a class="ae nm" href="https://arxiv.org/pdf/1910.10683v3.pdf" rel="noopener ugc nofollow" target="_blank">的作者</a>已经严格评估和提炼了几十个现有的NLP任务，以将最好的想法应用到他们的模型中。这些包括对模型架构、预训练目标、未标记数据集、训练策略和规模的实验，如作者所述[10]:</p><blockquote class="oc od oe"><p id="24c2" class="ky kz my la b lb lc ju ld le lf jx lg of li lj lk og lm ln lo oh lq lr ls lt im bi translated"><strong class="la iu"> <em class="it">模型架构</em> </strong>，在这里我们发现编码器-解码器模型普遍优于“只有解码器”的语言模型；</p><p id="ec80" class="ky kz my la b lb lc ju ld le lf jx lg of li lj lk og lm ln lo oh lq lr ls lt im bi translated"><strong class="la iu"> <em class="it">预训练目标</em> </strong>，我们确认填空式去噪目标(训练模型以恢复输入中缺失的单词)效果最佳，最重要的因素是计算成本；</p><p id="397e" class="ky kz my la b lb lc ju ld le lf jx lg of li lj lk og lm ln lo oh lq lr ls lt im bi translated"><strong class="la iu"> <em class="it">未标记数据集</em> </strong>，其中我们展示了对域内数据的训练可能是有益的，但是对较小数据集的预训练可能导致有害的过拟合；</p><p id="2164" class="ky kz my la b lb lc ju ld le lf jx lg of li lj lk og lm ln lo oh lq lr ls lt im bi translated"><strong class="la iu"/></p><p id="b414" class="ky kz my la b lb lc ju ld le lf jx lg of li lj lk og lm ln lo oh lq lr ls lt im bi translated">和<strong class="la iu"> <em class="it">缩放</em> </strong>，其中我们比较模型大小、训练时间和集合模型的数量，以确定如何最好地利用固定的计算能力[11]</p></blockquote><p id="53c1" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">完整的T5–11B型号是现有NLP型号(如BERT)的30多倍。</p><p id="5f52" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="cd45" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1910.10683v3.pdf" rel="noopener ugc nofollow" target="_blank">T5–11B</a>—1.1班开发</li><li id="47ff" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated">阿尔伯特上的SA-Net-squad 2.0</li><li id="6d40" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated">坦达-罗伯塔</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="2187" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">推荐系统</h1><p id="a9a9" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">你很可能已经见过并使用过各种各样的推荐系统。你最喜欢的网上商店或平台用它来推荐你可能感兴趣的类似产品。</p><p id="ff96" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该领域目前领先的算法之一是<strong class="la iu">贝叶斯时间SVD++。</strong>它是由谷歌团队在2019年提出的，并在MovieLens100K数据集上达到了SOTA基准。谷歌团队尝试了多种不同的方法和方法组合，直到他们找到贝叶斯矩阵分解和timeSVD++的领先组合。<strong class="la iu"> </strong>使用吉布斯采样训练贝叶斯矩阵分解模型。更多关于这个模型和所有尝试过的方法，你可以在这里找到<a class="ae nm" href="https://arxiv.org/pdf/1905.01395v1.pdf" rel="noopener ugc nofollow" target="_blank"/>【12】。</p><p id="cfb8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="0317" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1911.00936v1.pdf" rel="noopener ugc nofollow" target="_blank">H+鞋面门控</a> —运动镜片20M</li><li id="d003" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1905.03375v1.pdf" rel="noopener ugc nofollow" target="_blank">缓解</a> —百万首歌曲数据集</li><li id="5658" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1905.01395v1.pdf" rel="noopener ugc nofollow" target="_blank">贝叶斯timeSVD++翻转w/有序概率单位回归</a> — MovieLens 1M</li></ul><h1 id="f4db" class="mb mc it bd md me ot mg mh mi ou mk ml jz ov ka mn kc ow kd mp kf ox kg mr ms bi translated">语音识别</h1><p id="288b" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">和推荐系统一样，语音识别也参与了我们的日常生活。越来越多的应用程序以虚拟助手的形式利用语音识别，如Siri、Cortana、Bixby或Alexa。</p><p id="3f31" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该领域的领先算法之一是基于<strong class="la iu"> ContextNet + SpecAugment的带Libri-Light的嘈杂学生训练</strong>，由谷歌团队于2019年首次推出，<a class="ae nm" href="https://arxiv.org/pdf/2005.09629v1.pdf" rel="noopener ugc nofollow" target="_blank">论文</a>【13】。</p><p id="e420" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">顾名思义，这种方法结合了语境和嘈杂的学生训练。上下文网络是一个CNN-RNN转换器。该模型由用于输入音频的音频编码器、用于产生输入标签的标签编码器和用于解码的两者的联合网络组成。对于标签编码器，使用LSTM，音频编码器基于CNN。嘈杂的学生训练是一种半监督学习，使用未标记的数据来提高准确性[13]。</p><blockquote class="oc od oe"><p id="e9d5" class="ky kz my la b lb lc ju ld le lf jx lg of li lj lk og lm ln lo oh lq lr ls lt im bi translated">在有噪声的学生训练中，连续训练一系列模型，使得对于每个模型，该系列中的前一个模型充当数据集的未标记部分上的教师模型。嘈杂的学生训练的显著特征是利用增强，其中教师通过读入干净的输入来产生高质量的标签，而学生被迫用大量增强的输入特征来复制这些标签。”[13]</p></blockquote><p id="5ac8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">Libri光指的是未标记的音频数据集，模型在该数据集上被训练，并且该数据集是从音频书籍中导出的。</p><p id="8f55" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">其他顶层技术(方法—数据集):</p><ul class=""><li id="89a7" class="nn no it la b lb lc le lf lh np ll nq lp nr lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1703.02136v1.pdf" rel="noopener ugc nofollow" target="_blank"> ResNet + BiLSTMs声学模型</a> —配电盘+ Hub500</li><li id="f840" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1811.07453v2.pdf" rel="noopener ugc nofollow" target="_blank">LiGRU+Dropout+batch norm+one phone Reg</a>—TIMIT</li><li id="d9e1" class="nn no it la b lb nw le nx lh ny ll nz lp oa lt ns nt nu nv bi translated"><a class="ae nm" href="https://arxiv.org/pdf/2006.11477v2.pdf" rel="noopener ugc nofollow" target="_blank">大型-10h-LV-60k </a> — Libri-Light测试-清洁</li></ul></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><h1 id="aaf0" class="mb mc it bd md me mf mg mh mi mj mk ml jz mm ka mn kc mo kd mp kf mq kg mr ms bi translated">结论</h1><p id="eaa6" class="pw-post-body-paragraph ky kz it la b lb mt ju ld le mu jx lg lh mv lj lk ll mw ln lo lp mx lr ls lt im bi translated">过去十年在多个学科和任务方面取得了突破。新的技术、算法和应用已经被发现和开发，而我们仍处于开始阶段。这主要是通过两项发展实现的:1)不断增长的数据库，这使得为算法提供足够的数据成为可能；2)处理器、RAM和显卡的技术发展，使得训练需要更多计算能力的更复杂的算法成为可能。此外，随着数据科学投资的增加以及越来越多的人对数据科学和机器学习领域感兴趣，最先进的算法的半衰期也在缩短。连续，这篇文章可能已经过时一年。但是现在，这些领先的技术有助于创造越来越好的算法。</p><p id="fe87" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">如果你知道其他应该添加的方法或学科，你可以评论或联系我。感谢您的反馈，希望您喜欢这篇文章！</p><div class="oy oz gp gr pa pb"><a href="https://medium.com/@hucker.marius/membership" rel="noopener follow" target="_blank"><div class="pc ab fo"><div class="pd ab pe cl cj pf"><h2 class="bd iu gy z fp pg fr fs ph fu fw is bi translated">通过我的推荐链接加入Medium-Hucker Marius</h2><div class="pi l"><h3 class="bd b gy z fp pg fr fs ph fu fw dk translated">作为一个媒体会员，你的会员费的一部分会给你阅读的作家，你可以完全接触到每一个故事…</h3></div><div class="pj l"><p class="bd b dl z fp pg fr fs ph fu fw dk translated">medium.com</p></div></div><div class="pk l"><div class="pl l pm pn po pk pp ks pb"/></div></div></a></div></div><div class="ab cl lu lv hx lw" role="separator"><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz ma"/><span class="lx bw bk ly lz"/></div><div class="im in io ip iq"><p id="1df3" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la iu"> <em class="my">参考文献:</em> </strong></p><p id="871e" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[1]陶，a .，萨普拉，k .，&amp;卡坦扎罗，B. (2020)。语义切分的分层多尺度注意。<em class="my">ArXiv:2005.10821【Cs】</em>。<a class="ae nm" href="http://arxiv.org/abs/2005.10821" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/2005.10821</a></p><p id="8045" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[2]h .图夫龙、a .韦达尔迪、m .杜泽和h .杰古(2020年b)。修正训练-测试分辨率差异。ArXiv:2003.08237 [Cs] 。<a class="ae nm" href="http://arxiv.org/abs/2003.08237" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/2003.08237</a></p><p id="58e6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[3]h .图夫龙、a .韦达尔迪、m .杜泽和h .杰古(2020年a)。修复列车测试分辨率差异。<em class="my">ArXiv:1906.06423【Cs】</em>。<a class="ae nm" href="http://arxiv.org/abs/1906.06423" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1906.06423</a></p><p id="51e0" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1911.09070v7.pdf" rel="noopener ugc nofollow" target="_blank">【4】</a>谭，m，庞，r，&amp;乐，秦文伟(2020)。EfficientDet:可扩展且高效的对象检测。<em class="my">ArXiv:1911.09070【Cs，Eess】</em>。<a class="ae nm" href="http://arxiv.org/abs/1911.09070" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1911.09070</a></p><p id="a8b5" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nm" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank">【5】</a>Devlin，j .，Chang，m-w .，Lee，k .，&amp; Toutanova，K. (2019)。BERT:用于语言理解的深度双向转换器的预训练。<em class="my">ArXiv:1810.04805【Cs】</em>。【http://arxiv.org/abs/1810.04805 T4】</p><p id="4cd8" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[6] Shoeybi，m .，Patwary，m .，Puri，r .，LeGresley，p .，Casper，j .，&amp; Catanzaro，B. (2020年)。威震天-LM:使用模型并行性训练数十亿参数语言模型。<em class="my">ArXiv:1909.08053【Cs】</em>。<a class="ae nm" href="http://arxiv.org/abs/1909.08053" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1909.08053</a></p><p id="026c" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[7]艾杜诺夫，s .，奥特，m .，奥利，m .，&amp;格兰吉尔，D. (2018)。理解大规模回译。<em class="my">ArXiv:1808.09381【Cs】</em>。<a class="ae nm" href="http://arxiv.org/abs/1808.09381" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1808.09381</a></p><p id="c488" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[8] Vaswani，a .，Shazeer，n .，Parmar，n .，Uszkoreit，j .，Jones，l .，Gomez，A. N .，Kaiser，l .，&amp; Polosukhin，I. (2017)。你需要的只是关注。<em class="my">ArXiv:1706.03762【Cs】</em>。<a class="ae nm" href="http://arxiv.org/abs/1706.03762" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1706.03762</a></p><p id="8545" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[9]h .图夫龙、a .韦达尔迪、m .杜泽和h .杰古(2020年b)。修正训练-测试分辨率差异。ArXiv:2003.08237 [Cs] 。<a class="ae nm" href="http://arxiv.org/abs/2003.08237" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/2003.08237</a></p><p id="dfc6" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[10] Raffel，c .，Shazeer，n .，Roberts，a .，Lee，k .，Narang，s .，Matena，m .，周，y .，Li，w .，和刘，P. J. (2020)。用统一的文本到文本转换器探索迁移学习的局限性。<em class="my"> ArXiv:1910.10683 [Cs，Stat] </em>。<a class="ae nm" href="http://arxiv.org/abs/1910.10683" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1910.10683</a></p><p id="1771" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><a class="ae nm" href="https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html" rel="noopener ugc nofollow" target="_blank">【11】https://ai . Google blog . com/2020/02/exploring-transfer-learning-with-t5 . html</a></p><p id="00d4" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[12] Rendle，s .，Zhang，l .，&amp; Koren，Y. (2019)。评估基线的困难:推荐系统的研究。<em class="my">ArXiv:1905.01395【Cs】</em>。<a class="ae nm" href="http://arxiv.org/abs/1905.01395" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1905.01395</a></p><p id="d004" class="pw-post-body-paragraph ky kz it la b lb lc ju ld le lf jx lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">[13] <a class="ae nm" href="https://arxiv.org/pdf/1905.01395v1.pdf" rel="noopener ugc nofollow" target="_blank"> </a>朴德生、张、杨、贾、杨、韩、魏、邱、陈正忠、李、吴正荣、&amp;乐、秦文武(2020)。改进自动语音识别的嘈杂学生训练。<em class="my">ArXiv:2005.09629【Cs，Eess】【http://arxiv.org/abs/2005.09629 T4】</em></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="pq pr l"/></div></figure></div></div>    
</body>
</html>