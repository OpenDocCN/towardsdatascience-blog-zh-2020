<html>
<head>
<title>Resampling Methods for Inference Analysis</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">推理分析的重采样方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/resampling-methods-for-inference-analysis-e75fecfefcb2?source=collection_archive---------26-----------------------#2020-11-03">https://towardsdatascience.com/resampling-methods-for-inference-analysis-e75fecfefcb2?source=collection_archive---------26-----------------------#2020-11-03</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5c1f" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">当你有一个样本，但你想了解人口</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/f16aafa81d1c4f1da5c57203a0895d76.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*spbjq1djB54mAfw_Pco--Q.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://www.pexels.com/photo/high-angle-photography-of-people-in-ground-950902/" rel="noopener ugc nofollow" target="_blank">来源</a></p></figure><p id="7c11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">大多数时候，我们被要求得出对整个群体都有效的结论。但通常我们拥有的是来自样本的数据集，样本是我们收集数据的特定群体。<br/> <br/>在理想世界中，样本是<strong class="lb iu">随机选取的</strong>和<strong class="lb iu">代表</strong>人群的子集。使用示例实际上有很多好处，比如实用性、成本效益、节省时间和可管理性。<br/> <br/>尽管有这些优势，我们需要小心的是<a class="ae ky" href="https://en.wikipedia.org/wiki/Sampling_error" rel="noopener ugc nofollow" target="_blank"> <strong class="lb iu">采样误差</strong> </a> <strong class="lb iu">！</strong>🚨</p><p id="3a99" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">抽样误差是总体参数和根据样本计算的统计值之间的差异(如总体平均值和样本平均值之间的差异)。因为样本是总体的子集，所以它们不包括总体的所有成员。因此，从样本计算的统计数据(如平均值、中值、标准差、分位数等)通常不同于真实的总体参数。</p><p id="164c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">考虑到样本被确定为代表整个总体，样本和总体统计之间的差异被认为是<strong class="lb iu">误差</strong>。</p><p id="84d2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了克服采样误差，我们可以遵循以下重采样方法。</p><ol class=""><li id="5eca" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">拔靴带</li><li id="a348" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">刀切重采样</li><li id="e190" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">排列测试</li></ol><p id="3708" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在阅读本文的同时，我鼓励您查看我的GitHub上的<a class="ae ky" href="https://github.com/Idilismiguzel/data_analysis/blob/main/resampling-methods/Resampling-Methods.ipynb" rel="noopener ugc nofollow" target="_blank"> Jupyter笔记本</a>以获得完整的分析和代码。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="0223" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated">1.拔靴带</h1><p id="8089" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">自举是一种从原始样本创建样本<em class="nn">并替换</em>的方法。由于使用替换 完成了<strong class="lb iu"> <em class="nn">操作，每个数据点随后被选取的概率相等。我们可以引导<em class="nn"> n </em>次(比如1000次)，计算并记录这<em class="nn"> n </em>个样本中每一个的期望估计值(即平均值)。最后，我们可以找到期望估计值的分布。</em></strong></p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/76092bcc4d56e16a0693a594db2ab46b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xN6F71f5ZOcX3X_s9s1PTQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="907a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">📢bootstrapping的一般使用案例是寻找置信区间的稳健估计、总体参数的标准误差，如平均值、中值、相关系数、回归系数等。</p><p id="7220" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了说明Python中的自举，我将使用来自Kaggle的<a class="ae ky" href="https://www.kaggle.com/aungpyaeap/fish-market" rel="noopener ugc nofollow" target="_blank">鱼市场数据集</a>。该数据集由鱼市场销售的7种常见的不同鱼类组成，我将重点关注“蟑螂”鱼。我还将选择“长度1”作为属性。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="0a1b" class="nu mr it nq b gy nv nw l nx ny">data = pd.read_csv('./Fish.csv')<br/>data = data.loc[data["Species"] == "Roach"]["Length1"]</span><span id="baac" class="nu mr it nq b gy nz nw l nx ny">pd.DataFrame({'values': data.describe()}).reset_index()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/8f0f89462fe70d3181e20fd114abfef6.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/1*7ssiBUJQ2Rr4BnUQfIzsJA.png"/></div></figure><p id="eb43" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如上所述，我们可以用<code class="fe ob oc od nq b">np.percentile(data, [2.5,97.5]).</code>的95%置信区间<code class="fe ob oc od nq b">data.mean(),</code>计算样本均值</p><p id="cd5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，通过从样本分布到总体分布，我们做了几个隐藏的假设，例如:“长度1”值的分布是正态分布，置信区间是对称的。在大多数情况下，这些假设可能不正确。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="7645" class="nu mr it nq b gy nv nw l nx ny">mean = data.mean()<br/>confidence_int = np.percentile(data, [2.5, 97.5])</span></pre><blockquote class="oe of og"><p id="e01c" class="kz la nn lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated">样本均值= 20.65，95%置信区间= [14.61，27.36]</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/ec680d9347f9f873bc3331c52c4f4905.png" data-original-src="https://miro.medium.com/v2/resize:fit:868/format:webp/1*qyzXcEEWc8IM6PfIpZqhSw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有95%置信区间的长度1值的分布</p></figure><p id="5df3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">因此，我们应该使用bootstrap来寻找均值和置信区间。👇</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="c996" class="nu mr it nq b gy nv nw l nx ny">mean_lengths, n = [], 1000</span><span id="9685" class="nu mr it nq b gy nz nw l nx ny">for i in range(n):<br/>    sample = np.random.choice(data["Length1"], <br/>                              replace=True, <br/>                              size=len(data))<br/>    sample_mean = sample.mean()<br/>    mean_lengths.append(sample_mean)<br/>    <br/><br/>boot_mean = np.mean(mean_lengths)<br/>boot_ci = np.percentile(mean_lengths, [2.5, 97.5])</span></pre><blockquote class="oe of og"><p id="87bc" class="kz la nn lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated">自助平均值= 20.60，95%置信区间=[19.22±22.07]</p></blockquote><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/0fbf02ba8238a9c77d0c0d763027d573.png" data-original-src="https://miro.medium.com/v2/resize:fit:856/format:webp/1*eCEXvUkdNeg7pu_88YQcTg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">具有95%置信区间的自举样本均值的分布</p></figure><h1 id="02fe" class="mq mr it bd ms mt om mv mw mx on mz na jz oo ka nc kc op kd ne kf oq kg ng nh bi translated">2.刀切重采样</h1><p id="4779" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">刀切重采样技术基于通过系统地<strong class="lb iu"> <em class="nn">在原始数据集中留下一个观察值</em> </strong>来创建样本。我们应该计算每个样本的期望值，然后找出所有值的分布。</p><blockquote class="or"><p id="38e9" class="os ot it bd ou ov ow ox oy oz pa lu dk translated">作为一个例子，如果给定一个大小为<em class="pb"> n </em>的样本，那么重叠估计是通过合计每个<em class="pb"> (n-1) </em>样本的估计统计量得到的。</p></blockquote><figure class="pd pe pf pg ph kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi pc"><img src="../Images/ccf641c5703ffaf91c1732285f9b1dac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZAxgZopLP139LiSMnN8COw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><p id="9ced" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">📢刀切重采样的一般用例是寻找方差和偏差。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="6349" class="nu mr it nq b gy nv nw l nx ny">mean_lengths, n = [], len(data)<br/>index = np.arange(n)</span><span id="4abc" class="nu mr it nq b gy nz nw l nx ny">for i in range(n):<br/>    jk_sample = data[index != i]<br/>    mean_lengths.append(jk_sample.mean())</span><span id="844d" class="nu mr it nq b gy nz nw l nx ny">mean_lengths_jk = np.mean(np.array(mean_lengths))<br/>jk_variance = (n-1)*np.var(mean_lengths)</span></pre><blockquote class="oe of og"><p id="e9de" class="kz la nn lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated">平均值的重叠估计= 20.64 <br/>方差的重叠估计= 0.59</p></blockquote><h1 id="35dd" class="mq mr it bd ms mt om mv mw mx on mz na jz oo ka nc kc op kd ne kf oq kg ng nh bi translated">3.排列测试</h1><p id="f292" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">排列检验是一种统计显著性检验，它试图在不对数据做出强假设的情况下获得检验统计量的分布(在<a class="ae ky" href="https://en.wikipedia.org/wiki/Null_hypothesis" rel="noopener ugc nofollow" target="_blank">零假设</a>下)。</p><p id="a65b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设我们有两个样本，我们想测试这两个样本是否有不同的特征(即平均值)。我们可以计算两个样本的平均值，并决定它们是否不同。但是用这种方法分析没有统计学意义，因为我们没有整个人口的数据，只有其中的一部分。</p><p id="217d" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，我们可以执行置换测试，其工作方式如下:</p><ol class=""><li id="919a" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">将两个样本合并成一个数据集。</li><li id="f237" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">混洗合并的数据集，并将其随机重新采样为2个数据集(大小与之前的样本相同)。</li><li id="d9d8" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">计算测试统计数据(即平均值之间的差异)并记录数值。</li><li id="a564" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">重复上述步骤n次(比如说10000次)。</li><li id="80d1" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">将原始检验统计量与记录值进行比较，如果原始检验统计量与置换记录吻合得很好，那么检验统计量确实没有不同，样本均值之间的差异仅是由于偶然因素造成的<strong class="lb iu">。如果原始统计位于最大置换记录之外，则意味着两个样本之间存在<strong class="lb iu">显著差异</strong>。</strong></li></ol><p id="2538" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了说明Python中的置换测试，我将再次使用Kaggle的<a class="ae ky" href="https://www.kaggle.com/aungpyaeap/fish-market" rel="noopener ugc nofollow" target="_blank">鱼市场数据集</a>。这一次，我将通过选择“长度1”&amp;“长度2”属性来关注“蟑螂”鱼。</p><p id="f96c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">💬我将调查这两个值的平均值是否有显著差异，或者是由于偶然因素。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi pi"><img src="../Images/7ed41689c7b45797be41bb1bdf2706e9.png" data-original-src="https://miro.medium.com/v2/resize:fit:262/format:webp/1*EMUIvuiFK2Xwli_epKqKog.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据集中的前5行</p></figure><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="19f5" class="nu mr it nq b gy nv nw l nx ny">data["Length1"].mean()<br/>data["Length2"].mean()</span></pre><blockquote class="oe of og"><p id="b6f8" class="kz la nn lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated">长度平均值1: 20.65 <br/>长度平均值2: 22.27</p></blockquote><p id="515f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们正在研究两个样本均值(-1.62)之间的差异是偶然的还是统计上显著的。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="76ca" class="nu mr it nq b gy nv nw l nx ny">--&gt; Step 1: Combine datasets<br/>sample1 = data["Length1"]<br/>sample2 = data["Length2"]<br/>data = np.concatenate([sample1, sample2])</span><span id="92b8" class="nu mr it nq b gy nz nw l nx ny">--&gt; Step 2: Shuffle and randomly resample into 2 datasets<br/>perm = np.array([np.random.permutation(len(sample1) + len(sample2)) for i in range(10000)])<br/>permuted_1_db = data[perm[:, :len(sample1)]]<br/>permuted_2_db = data[perm[:, len(sample1):]]</span><span id="8bf8" class="nu mr it nq b gy nz nw l nx ny">--&gt; Step 3: Calculate the test statistics<br/>samples = np.mean(permuted_1_db, axis=1) - np.mean(permuted_2_db, axis=1)</span><span id="7978" class="nu mr it nq b gy nz nw l nx ny">--&gt; Step 4: Repeat it n times<br/>Done in step 2 with for loop</span><span id="fc06" class="nu mr it nq b gy nz nw l nx ny">--&gt; Step 5: Compare the original test stat with the recorded values<br/>test_stat = np.mean(sample1) - np.mean(sample2)<br/>p_val = 2*np.sum(samples &gt;= np.abs(test_stat))/10000<br/>print("p-value = {}".format(p_val))</span></pre><blockquote class="oe of og"><p id="4cd7" class="kz la nn lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated">test_statistic = -1.62 <br/> p值= 0.15</p></blockquote><p id="b80e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">p值告诉我们，在15%的情况下，我们应该期望在两个样本之间达到相似的平均差异。</p><p id="3648" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果你想了解更多关于排列检验和假设检验的知识，你也可以阅读我的文章<a class="ae ky" rel="noopener" target="_blank" href="/a-guide-to-a-b-testing-how-to-formulate-design-and-interpret-f820cc62e21a">a/b检验指南</a>(附below)⚡</p><div class="pj pk gp gr pl pm"><a rel="noopener follow" target="_blank" href="/a-guide-to-a-b-testing-how-to-formulate-design-and-interpret-f820cc62e21a"><div class="pn ab fo"><div class="po ab pp cl cj pq"><h2 class="bd iu gy z fp pr fr fs ps fu fw is bi translated">A/B测试指南——如何制定、设计和解释</h2><div class="pt l"><h3 class="bd b gy z fp pr fr fs ps fu fw dk translated">用Python实现</h3></div><div class="pu l"><p class="bd b dl z fp pr fr fs ps fu fw dk translated">towardsdatascience.com</p></div></div><div class="pv l"><div class="pw l px py pz pv qa ks pm"/></div></div></a></div></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="eec1" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated"><strong class="ak">奖金</strong></h1><p id="43b2" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">如果您正在执行相关性分析以了解数据集中变量之间的关系有多强，那么分析中包括的一个好东西是<strong class="lb iu">相关系数的自举置信区间</strong>。</p><p id="72c0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了用Python展示，我将再次使用<a class="ae ky" href="https://www.kaggle.com/aungpyaeap/fish-market" rel="noopener ugc nofollow" target="_blank">鱼市场数据集</a>，通过选择“length 1”&amp;“Weight”属性来关注“Roach”鱼。</p><p id="8778" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">💬我将研究这两种属性之间的关系。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oa"><img src="../Images/e80901755388cb2ebbf6434294c4b3d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:248/format:webp/1*jkZQtxhnYDOs2ZbeiQzCWA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">数据中有代表性的两行</p></figure><p id="3cd4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在用<code class="fe ob oc od nq b">data.corr()</code>引导之前，我们可以计算属性之间的相关系数。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi qb"><img src="../Images/2db352ca05ae517c75f1ffcf913de2d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:418/format:webp/1*3WzAz6nTvDODb3r9lYF-zA.png"/></div></figure><p id="0bc3" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">看起来在我们的样本中,“长度1”和“重量”之间有90%的正相关。但是正如我们之前讨论的，这90%代表了当前的样本，而不是整个人口。因此，我们可以计算1000次bootstrapped样本的95%置信区间。</p><pre class="kj kk kl km gt np nq nr ns aw nt bi"><span id="1618" class="nu mr it nq b gy nv nw l nx ny">data_size, lw_corr = data.shape[0], []</span><span id="48e0" class="nu mr it nq b gy nz nw l nx ny">for i in range(1000):<br/>    tmp_df = data.sample(n=data_size, replace=True)<br/>    lw_corr.append(tmp_df["Weight"].corr(tmp_df["Length1"]))</span><span id="eaa8" class="nu mr it nq b gy nz nw l nx ny">corr_ci = np.percentile(lw_corr, [2.5, 97.5])</span></pre><blockquote class="oe of og"><p id="e263" class="kz la nn lb b lc ld ju le lf lg jx lh oh lj lk ll oi ln lo lp oj lr ls lt lu im bi translated">相关系数置信区间:[0.77，0.98]</p></blockquote><p id="3680" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这意味着在95%的自举样本中，“长度1”和“重量”之间的相关系数保持在0.77和0.98之间。</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><h1 id="e10e" class="mq mr it bd ms mt mu mv mw mx my mz na jz nb ka nc kc nd kd ne kf nf kg ng nh bi translated"><strong class="ak">总结</strong></h1><p id="5480" class="pw-post-body-paragraph kz la it lb b lc ni ju le lf nj jx lh li nk lk ll lm nl lo lp lq nm ls lt lu im bi translated">在本文中，我们介绍了三种重采样方法来消除分析中的采样偏差问题。通过这样做，我们不仅可以提取关于总体参数的更精确的估计，而且可以量化我们估计中的不确定性，例如增加置信区间。利用我们今天拥有的计算能力，我们可以在几行代码中对初始样本进行多次重采样。</p><p id="ad4f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我希望你喜欢阅读这篇文章，并发现它对你的分析有用！</p></div><div class="ab cl mj mk hx ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="im in io ip iq"><p id="0ae2" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><em class="nn">如果你喜欢这篇文章，你可以</em> <strong class="lb iu"> <em class="nn"> </em> </strong> <a class="ae ky" href="https://medium.com/@idilismiguzel" rel="noopener"> <strong class="lb iu"> <em class="nn">在这里阅读我的其他文章</em></strong></a><strong class="lb iu"><em class="nn"/></strong><em class="nn">和</em> <a class="ae ky" href="http://medium.com/@idilismiguzel/follow" rel="noopener"> <strong class="lb iu"> <em class="nn">关注我上媒</em></strong></a><strong class="lb iu"><em class="nn"/></strong>如果有任何问题或建议，请告诉我。✨</p><p id="e4ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">喜欢这篇文章吗？ <a class="ae ky" href="https://idilismiguzel.medium.com/membership" rel="noopener"> <strong class="lb iu">成为会员求更！</strong> </a></p></div></div>    
</body>
</html>