<html>
<head>
<title>Federated Learning: A Simple Implementation of FedAvg (Federated Averaging) with PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">联邦学习:用PyTorch简单实现FedAvg(联邦平均)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/federated-learning-a-simple-implementation-of-fedavg-federated-averaging-with-pytorch-90187c9c9577?source=collection_archive---------6-----------------------#2020-09-24">https://towardsdatascience.com/federated-learning-a-simple-implementation-of-fedavg-federated-averaging-with-pytorch-90187c9c9577?source=collection_archive---------6-----------------------#2020-09-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="61a3" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><figure class="gl gn jx jy jz ka gh gi paragraph-image"><div role="button" tabindex="0" class="kb kc di kd bf ke"><div class="gh gi jw"><img src="../Images/d0f5077737b052c146c293d3fd5916d2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*5-x6S44IhloUifMhqkpYMQ.jpeg"/></div></div><p class="kh ki gj gh gi kj kk bd b be z dk translated"><a class="ae kl" href="https://unsplash.com/@jdent?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">杰森·登特</a>在<a class="ae kl" href="https://unsplash.com/s/photos/privacy?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="5610" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">手机、平板电脑和智能手表等移动设备现在是主要的计算设备，已经成为许多人不可或缺的一部分。由于结合了丰富的用户交互和强大的传感器，这些设备承载了大量有价值的私人数据。基于这些数据训练的模型可以显著提高智能应用程序的可用性和功能。然而，这些数据的敏感性意味着也有一些风险和责任[1]。在这一点上，联邦学习(FL)的概念开始发挥作用。</p><p id="8b1b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在FL中，每个客户分散地训练它的模型。换句话说，模型训练过程是为每个客户单独进行的。只有学习到的模型参数被发送到可信中心，以组合和馈送聚合的主模型。然后可信中心将聚合的主模型发回给这些客户端，这个过程就这样循环下去[2]。</p><p id="1739" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在这种情况下，我使用IID(独立同分布)数据准备了一个简单的实现，以展示如何将运行在不同节点上的数百个不同模型的参数与FedAvg方法结合起来，以及该模型是否会给出合理的结果。该实现是在MNIST数据集上进行的。MNIST数据集包含数字从0到9的28 * 28像素灰度图像[3]。</p><figure class="ll lm ln lo gt ka gh gi paragraph-image"><div class="gh gi lk"><img src="../Images/b8f2f0202b3aa417457b91450d317670.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*7tRuEBQleYASpCUW8nns-w.png"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">来自MNIST数据集的手写数字(图片由作者提供*)</p></figure><ul class=""><li id="894c" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated">MNIST数据集并不平等地包含每个标签。因此，为了满足IID要求，数据集被分组、混洗，然后分布，使得每个节点包含相同数量的每个标签。</li><li id="3602" class="lp lq iq ko b kp ly kt lz kx ma lb mb lf mc lj lu lv lw lx bi translated">为分类过程创建了一个简单的两层模型。</li><li id="50b1" class="lp lq iq ko b kp ly kt lz kx ma lb mb lf mc lj lu lv lw lx bi translated">定义了用于FedAvg的函数。</li></ul><p id="cb16" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这里，一次迭代完成如下。</p><ol class=""><li id="236d" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj md lv lw lx bi translated">由于主模型的参数和节点中所有局部模型的参数都是随机初始化的，所以所有这些参数都将互不相同。为此，主模型在节点中的本地模型的训练开始之前将其参数发送到节点。</li><li id="b12d" class="lp lq iq ko b kp ly kt lz kx ma lb mb lf mc lj md lv lw lx bi translated">通过使用这些参数，节点开始在它们自己的数据上训练它们的本地模型。</li><li id="2d40" class="lp lq iq ko b kp ly kt lz kx ma lb mb lf mc lj md lv lw lx bi translated">每个节点在训练它自己的模型时更新它的参数。训练过程完成后，每个节点将其参数发送到主模型。</li><li id="f6d3" class="lp lq iq ko b kp ly kt lz kx ma lb mb lf mc lj md lv lw lx bi translated">主模型取这些参数的平均值，并将它们设置为新的权重参数，并将它们传递回节点，用于下一次迭代。</li></ol><p id="9b23" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">上面的流程是针对一次迭代的。这种迭代可以不断重复，以提高主模型的性能。</p><p id="88e3" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">注:</strong>这里的目的不是为了提高分类算法的性能，而是将联邦学习得到的模型与集中式模型的性能进行比较。如果您愿意，可以使用更复杂的模型或调整超参数来提高性能。</p><p id="ad78" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果你准备好了，我们开始吧！</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="me mf l"/></div><p class="kh ki gj gh gi kj kk bd b be z dk translated">GIF由<a class="ae kl" href="https://giphy.com/gifs/europapark-fun-looping-xUOwGdA2o7E4TPJICQ" rel="noopener ugc nofollow" target="_blank">欧洲公园</a>在<a class="ae kl" href="https://giphy.com/" rel="noopener ugc nofollow" target="_blank"> giphy </a>上发布</p></figure><h1 id="3f4a" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">功能解释</h1><p id="1b16" class="pw-post-body-paragraph km kn iq ko b kp ne kr ks kt nf kv kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated"><strong class="ko ja">数据分发功能</strong></p><ul class=""><li id="7e4c" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">【split _ and _ shuffle _ labels(y _ data，seed，amount): </em> </strong>数据集不包含相同数量的每个标签。为了将数据作为IID分布到各个节点，必须采集相同数量的数据。该函数根据每个标签给出的数量对它们进行分组，并在自身内部打乱顺序。请注意，这里混洗的是数据的索引，我们将在将来检索数据时使用它们。但是这些索引需要重新设置以避免关键错误。因此，定义了一个新列，并在那里保留了混排索引。</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><ul class=""><li id="729e" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">get _ iid _ sub samples _ indexes(label _ dict，number_of_samples，amount): </em> </strong>该函数将每个节点中的索引用每个标签的相同数量进行划分。(这里索引仍然是分布式的，而不是数据)</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><ul class=""><li id="ab84" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">create _ iid _ sub samples(sample _ dict，x_data，y_data，x_name，y_name): </em> </strong>该函数将x和y数据分发给字典中的节点。</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><p id="a817" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">FedAvg</strong>的功能</p><ul class=""><li id="ac83" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">create _ model _ optimizer _ criterion _ dict(number _ of _ samples):</em></strong>该函数为每个节点创建一个模型、优化器和损失函数。</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><ul class=""><li id="4e5f" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">get _ averaged _ weights(model _ dict，number_of_samples): </em> </strong>该函数取单个节点权重的平均值。</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><ul class=""><li id="a781" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">set _ averaged _ weights _ as _ main _ model _ weights _ and _ update _ main _ model(main _ model，model_dict，number_of_samples): </em> </strong>该函数将单个节点的平均权重发送到主模型，并将其设置为主模型的新权重。(调用def get _ averaged _ weights(model _ dict，number_of_samples))</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><ul class=""><li id="133c" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">compare _ local _ and _ merged _ model _ performance(number _ of _ samples:</em></strong>该函数比较主模型和每个节点上运行的局部模型的精度。</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><ul class=""><li id="a110" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">send _ main _ model _ to _ nodes _ and _ update _ model_dict(main _ model，model _ dict，number_of_samples): </em> </strong>该函数将主模型的参数发送给节点。</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><ul class=""><li id="32cc" class="lp lq iq ko b kp kq kt ku kx lr lb ls lf lt lj lu lv lw lx bi translated"><strong class="ko ja"><em class="nj">start _ train _ end _ node _ process _ without _ print():</em></strong>该函数在节点中训练单个局部模型。</li></ul><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure></div><div class="ab cl nl nm hu nn" role="separator"><span class="no bw bk np nq nr"/><span class="no bw bk np nq nr"/><span class="no bw bk np nq"/></div><div class="ij ik il im in"><h1 id="f29d" class="mg mh iq bd mi mj ns ml mm mn nt mp mq mr nu mt mu mv nv mx my mz nw nb nc nd bi translated">基于所有训练数据的集中式模型的性能如何？</h1><p id="24e0" class="pw-post-body-paragraph km kn iq ko b kp ne kr ks kt nf kv kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">首先，让我们检查一下，如果数据根本不分布到节点上，集中式模型的性能会如何？</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><pre class="ll lm ln lo gt nx ny nz oa aw ob bi"><span id="f68d" class="oc mh iq ny b gy od oe l of og"> — — — Centralized Model — — — <br/>epoch: 1 | train accuracy: 0.8743 | test accuracy: 0.9437<br/>epoch: 2 | train accuracy: 0.9567 | test accuracy: 0.9654<br/>epoch: 3 | train accuracy: 0.9712 | test accuracy: 0.9701<br/>epoch: 4 | train accuracy: 0.9785 | test accuracy: 0.9738<br/>epoch: 5 | train accuracy: 0.9834 | test accuracy: 0.9713<br/>epoch: 6 | train accuracy: 0.9864 | test accuracy: 0.9768<br/>epoch: 7 | train accuracy: 0.9898 | test accuracy: 0.9763<br/>epoch: 8 | train accuracy: 0.9923 | test accuracy: 0.9804<br/>epoch: 9 | train accuracy: 0.9941 | test accuracy: 0.9784<br/>epoch: 10 | train accuracy: 0.9959 | test accuracy: 0.9792<br/> — — — Training finished — — -</span></pre><p id="cf64" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">此示例中使用的模型非常简单，可以执行不同的改进来提高模型性能，例如使用更复杂的模型、增加历元或超参数调整。然而，这里的目的是比较主模型的性能，该主模型是通过将根据它们自己的数据训练的局部模型的参数与根据所有训练数据训练的集中模型相结合而形成的。通过这种方式，我们可以深入了解联合学习的能力。</p><p id="25a9" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，开始我们的第一次迭代</p><p id="a5d0" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">数据被分发到节点</strong></p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><p id="5e3d" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">主模型被创建</strong></p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><p id="1b6a" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">定义节点中的模型、优化器和损失函数</strong></p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><p id="7b7b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">字典的关键字变得可重复</strong></p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><p id="e70b" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">主模型的参数被发送到节点</strong> <br/>由于主模型的参数和节点中所有局部模型的参数都是随机初始化的，所以这些参数会互不相同。为此，主模型在节点中的本地模型的训练开始之前将其参数发送到节点。你可以查看下面的重量。</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><p id="64e8" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><strong class="ko ja">节点中的模型被训练</strong></p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><h1 id="15bd" class="mg mh iq bd mi mj mk ml mm mn mo mp mq mr ms mt mu mv mw mx my mz na nb nc nd bi translated">让我们比较一下联邦主模型和集中式模型的性能</h1><p id="b788" class="pw-post-body-paragraph km kn iq ko b kp ne kr ks kt nf kv kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated"><strong class="ko ja">第一次迭代前联合主模型与集中式模型(对所有测试数据)</strong> <br/>由于主模型是随机初始化的，且尚未对其采取任何行动，因此在第一次迭代前，其性能非常差。在第一次迭代之后，主模型的精度提高到了%85。</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><pre class="ll lm ln lo gt nx ny nz oa aw ob bi"><span id="6f88" class="oc mh iq ny b gy od oe l of og">Before 1st iteration main model accuracy on all test data: 0.1180<br/>After 1st iteration main model accuracy on all test data: 0.8529<br/>Centralized model accuracy on all test data: 0.9790</span></pre><p id="df9f" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这是一次迭代，我们可以将主模型的参数发送回节点，并重复上述步骤。现在让我们检查当我们重复迭代10次以上时，主模型的性能是如何提高的。</p><figure class="ll lm ln lo gt ka"><div class="bz fp l di"><div class="nk mf l"/></div></figure><pre class="ll lm ln lo gt nx ny nz oa aw ob bi"><span id="5c4f" class="oc mh iq ny b gy od oe l of og">Iteration 2 : main_model accuracy on all test data:  0.8928<br/>Iteration 3 : main_model accuracy on all test data:  0.9073<br/>Iteration 4 : main_model accuracy on all test data:  0.9150<br/>Iteration 5 : main_model accuracy on all test data:  0.9209<br/>Iteration 6 : main_model accuracy on all test data:  0.9273<br/>Iteration 7 : main_model accuracy on all test data:  0.9321<br/>Iteration 8 : main_model accuracy on all test data:  0.9358<br/>Iteration 9 : main_model accuracy on all test data:  0.9382<br/>Iteration 10 : main_model accuracy on all test data:  0.9411<br/>Iteration 11 : main_model accuracy on all test data:  0.9431</span></pre><p id="2e11" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">集中式模型的准确度被计算为大约98%。用FedAvg方法得到的主模型的准确率从85%开始提高到94%。在这种情况下，我们可以说，虽然FedAvg方法得到的主模型是在没有看到数据的情况下训练出来的，但其性能不可小觑。</p><p id="da91" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">可以访问<a class="ae kl" href="https://github.com/eceisik/fl_public/blob/master/fedavg_mnist_iid.ipynb" rel="noopener ugc nofollow" target="_blank">https://github . com/ECE isik/fl _ public/blob/master/fed avg _ mnist _ iid . ipynb</a>查看完整实现。</p><p id="b7c1" class="pw-post-body-paragraph km kn iq ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">*您可以访问github页面。</p><blockquote class="oh oi oj"><p id="4c0a" class="km kn nj ko b kp kq kr ks kt ku kv kw ok ky kz la ol lc ld le om lg lh li lj ij bi translated">[1]j . konen，H. B. McMahan，D. Ramage和P. Richtárik，“联邦优化:分布式机器学习用于设备智能”，第1–38页，2016年。</p><p id="543a" class="km kn nj ko b kp kq kr ks kt ku kv kw ok ky kz la ol lc ld le om lg lh li lj ij bi translated">[2] H. B. Mcmahan和D. Ramage，“从分散数据中进行深度网络的通信高效学习”，第54卷，2017年。</p><p id="e24e" class="km kn nj ko b kp kq kr ks kt ku kv kw ok ky kz la ol lc ld le om lg lh li lj ij bi translated">[3] Y. LeCun、L. Bottou、Y. Bengio和P. Haffner。"基于梯度的学习应用于文档识别."IEEE会议录，86(11):2278–2324，1998年11月。</p></blockquote></div></div>    
</body>
</html>