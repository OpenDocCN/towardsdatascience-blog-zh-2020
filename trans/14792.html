<html>
<head>
<title>Sampling Large Graphs in PyTorch Geometric</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">PyTorch几何图形中的大型图形采样</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/sampling-large-graphs-in-pytorch-geometric-97a6119c41f9?source=collection_archive---------24-----------------------#2020-10-12">https://towardsdatascience.com/sampling-large-graphs-in-pytorch-geometric-97a6119c41f9?source=collection_archive---------24-----------------------#2020-10-12</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="52dd" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">大型图上的图形深度学习技术</h2></div><p id="67d4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有时，我们会遇到大型图形，迫使我们超出GPU或CPU的可用内存。在这些情况下，我们可以利用图形采样技术。<a class="ae le" href="https://pytorch-geometric.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> PyTorch Geometric </a>是一个图形深度学习库，允许我们轻松实现许多图形神经网络架构。该库包含许多标准的图形深度学习数据集，如Cora、Citeseer和Pubmed。但是最近图形开放数据集中出现了使用大规模网络的趋势，如<a class="ae le" href="https://ogb.stanford.edu/" rel="noopener ugc nofollow" target="_blank">开放图形基准</a> (OGB) [3]。在OGB，各种数据集从ogbn-arxiv (169，343个节点)这样的“小型”网络一直到ogbn-papers100M (111，059，956个节点)这样的“大型”数据集。也许ogbn-arxiv可以适合内存，如果你只是用一个小的GCN或其他东西做一个节点分类，但是尝试任何超出这个范围的东西，或者在OGB使用一个中到大的数据集，你可能不得不求助于对图形进行采样。</p><p id="edeb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">有多种方法可以对大型图表进行采样，我将尝试介绍两种主要的方法。</p><ol class=""><li id="75d0" class="lf lg it kk b kl km ko kp kr lh kv li kz lj ld lk ll lm ln bi translated">邻居采样器</li></ol><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi lo"><img src="../Images/f635d05d8685ca24e9e9a62e399de780.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iUapI5tP8TLxkW2QbBAN4g.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">来自3层邻域采样器的二部图草图</p></figure><p id="2dec" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">2.GraphSAINTSampler</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi me"><img src="../Images/501004ecb5c9b1cd3026f99843351a23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2an3NjbfB5wV1d8PuCvf1A.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">来自GraphSAINTSampler小批量的子图采样器的草图</p></figure><p id="bad9" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu">neighborhood sampler</strong>类来自GraphSAGE paper，<a class="ae le" href="https://arxiv.org/pdf/1706.02216.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="mf">大型图形上的归纳表示学习</em></a><em class="mf"/>【2】<em class="mf">。</em>如果你之前没有使用过SAGEConv，你可以把它想象成学习一个基于节点的邻域输出节点嵌入的函数，而不是直接学习所有的节点嵌入。这使得它对归纳任务特别有用，因为你可以通过它从未见过的GNN节点。</p><p id="7c10" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我画了一个3层的GNN邻居样本的抽象视图，每个层都被分成一个二分图邻居样本。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mg"><img src="../Images/42b9daf72f76fd910919adf116573587.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z-hTIFm_OnUY4gDjNPvCeA.jpeg"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">邻域采样的三层GNN示意图</p></figure><p id="a080" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">我试图用蓝色画出源节点，用红色画出目标节点。如您所见，目标节点也有自循环，因此它们出现在二分图的左侧和右侧。下面是代码的样子:</p><pre class="lp lq lr ls gt mh mi mj mk aw ml bi"><span id="136b" class="mm mn it mi b gy mo mp l mq mr">train_loader = NeighborSampler(data.edge_index, node_idx=train_idx, <br/>                               sizes=[15, 10, 5], batch_size=1024, <br/>                               shuffle=<strong class="mi iu">True</strong>, num_workers=12)</span></pre><p id="60d6" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ms mt mu mi b">sizes</code>指定每个源节点要采样的邻居数量。想象一下，从我们想要计算嵌入的节点集开始(这些是上图第3层中最后的红色节点)。然后，我们计算超参数指定的所有样本，最终返回给我们——相反。这意味着当我们遍历所有层时，我们最终只得到我们感兴趣的节点嵌入。</p><p id="563c" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><em class="mf">注意</em>:每个小批量中的节点id是大图中的原始节点id。该采样器本身不对子图进行采样，而是对邻域进行采样，以学习聚合函数。</p><p id="66c1" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">从ogbn-products数据集上PyTorch Geometric中的<a class="ae le" href="https://github.com/rusty1s/pytorch_geometric/blob/master/examples/ogbn_products_sage.py" rel="noopener ugc nofollow" target="_blank"> GraphSAGE示例</a>中，我们可以看到<code class="fe ms mt mu mi b">train_loader</code>由<code class="fe ms mt mu mi b">batch_size</code>、<code class="fe ms mt mu mi b">n_id</code>和<code class="fe ms mt mu mi b">adjs</code>组成。</p><pre class="lp lq lr ls gt mh mi mj mk aw ml bi"><span id="750a" class="mm mn it mi b gy mo mp l mq mr"><strong class="mi iu">for</strong> batch_size, n_id, adjs <strong class="mi iu">in</strong> train_loader:<br/>    ...<br/>    out = model(x[n_id], adjs)<br/>    ...</span></pre><p id="88b2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><code class="fe ms mt mu mi b">n_id</code>是采样过程中使用的每个节点的所有节点id，包括采样的邻居节点和源节点。通过传递我们的模型<code class="fe ms mt mu mi b">x[n_id]</code>,我们只隔离了在这一批计算中使用的那些节点的节点特征向量。<code class="fe ms mt mu mi b">adjs</code>中有3个<code class="fe ms mt mu mi b">adj</code>，由一个<code class="fe ms mt mu mi b">edge_index</code>、<code class="fe ms mt mu mi b">e_id</code>和<code class="fe ms mt mu mi b">size</code>组成。因此，在PyTorch几何模型的SAGE模型中，我们有:</p><pre class="lp lq lr ls gt mh mi mj mk aw ml bi"><span id="119c" class="mm mn it mi b gy mo mp l mq mr"><strong class="mi iu">def</strong> forward(self, x, adjs): <br/>    <strong class="mi iu">for</strong> i, (edge_index, _, size) <strong class="mi iu">in</strong> enumerate(adjs): <br/>        x_target = x[:size[1]] <br/>        x = self.convs[i]((x, x_target), edge_index)            <br/>        <strong class="mi iu">if</strong> i != self.num_layers - 1:                <br/>            x = F.relu(x) <br/>            x = F.dropout(x, p=0.5, training=self.training) <br/>    <strong class="mi iu">return</strong> x.log_softmax(dim=-1)</span></pre><p id="751f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">现在你可以看到<code class="fe ms mt mu mi b">adjs</code>中的三个二分图分别被传递到三个卷积层。</p><p id="5def" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">这种方法的一个可能的缺点是，我们实际上并没有从训练数据中为每一批抽取子图。采样器试图模仿在训练数据集网络上的GNN卷积，而不是在每次迭代中获取实际样本。这可能是有益的，这样就不会使你的训练循环产生偏差，但是如果你正在做一些简单的分类或者链接预测之外的事情，我会遇到一些关于索引的问题。然而，从另一个角度来看，与子图采样相比，这种方法可能是有益的，因为我们减少了训练数据的偏差。</p><p id="d8d8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> GraphSAINTSampler </strong>允许您处理原始训练数据集的实际子图，并重写从0到<em class="mf"> n </em>的节点id，其中<em class="mf"> n </em>是子图中的节点数。</p><p id="d038" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GraphSAINTSampler父类有三个子类:GraphSAINTNodeSampler、GraphSAINTEdgeSampler和GraphSAINTRandomWalkSampler。这些类中的每一个都使用它们各自的采样方案来计算节点的重要性，这转化为采样的概率分布[5]。这个初始采样器就像一个预处理步骤，估计被采样的<em class="mf"> V </em>中的节点<em class="mf"> v </em>和<em class="mf"> E </em>中的边<em class="mf"> e </em>的概率。该概率稍后被用作子图的归一化因子[4]。</p><p id="3026" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">下面是PyTorch Geometric中的<a class="ae le" href="https://github.com/rusty1s/pytorch_geometric/blob/master/examples/graph_saint.py" rel="noopener ugc nofollow" target="_blank"> graph_saint示例</a>中的GraphSAINTRandomWalkSampler示例。</p><pre class="lp lq lr ls gt mh mi mj mk aw ml bi"><span id="bf50" class="mm mn it mi b gy mo mp l mq mr">loader = GraphSAINTRandomWalkSampler(data, batch_size=6000, <br/>                                     walk_length=2, num_steps=5, <br/>                                     sample_coverage=100, <br/>                                     save_dir=dataset.processed_dir, <br/>                                     num_workers=4)</span></pre><p id="26ca" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请记住，根据您设置超参数的方式，加载器可能不会加载整个数据集。<code class="fe ms mt mu mi b">batch_size</code>超参数是每批抽样的行走次数。例如，使用Citeseer数据集和<code class="fe ms mt mu mi b">batch_size = 1</code>、<code class="fe ms mt mu mi b">walk_length = 1</code>和<code class="fe ms mt mu mi b">num_steps = 1</code>，我们得到1个包含2个节点的数据样本。使用<code class="fe ms mt mu mi b">batch_size = 10</code>,我们得到1个有20个节点的数据样本。使用<code class="fe ms mt mu mi b">batch_size = 100</code>,我们得到大约200个节点——在每次迭代中可能会改变，例如189、191等。<code class="fe ms mt mu mi b">num_steps</code>超参数是每个时期的迭代次数。因此，如果我们将<code class="fe ms mt mu mi b">num_steps</code>增加到<code class="fe ms mt mu mi b">2</code>，那么节点的数量将增加到大约380，其中有一个<code class="fe ms mt mu mi b">batch_size = 100</code>和一个<code class="fe ms mt mu mi b">walk_length = 1</code>。<code class="fe ms mt mu mi b">walk_length</code>超参数指的是采样器每次随机行走的长度，返回节点数量的结果将根据网络的分类性而有很大的不同。这实际上编译了PyTorch Geometric的<code class="fe ms mt mu mi b">torch_sparse</code>库中稀疏张量表示上的随机行走的C++实现(以及随后的cuda实现)。请参阅关于使用自定义C++操作符扩展TorchScript的<a class="ae le" href="https://pytorch.org/tutorials/advanced/torch_script_custom_ops.html" rel="noopener ugc nofollow" target="_blank"> PyTorch教程</a>了解更多信息。</p><figure class="lp lq lr ls gt lt gh gi paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="gh gi mv"><img src="../Images/c1313ac64564b1c075e843c84665e50c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JlhvlahmMzaGOvGGlKh41Q.png"/></div></div><p class="ma mb gj gh gi mc md bd b be z dk translated">Citeseer数据集上各种超参数的GraphSAINT数据加载器中的节点数</p></figure><p id="95ae" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">GraphSAINT论文最重要的方面之一是计算归一化统计量，以减少每个子图样本中的偏差。GraphSAINTSampler计算这些统计数据，这部分由<code class="fe ms mt mu mi b">sample_coverage</code>超参数控制。得到的统计数据作为<code class="fe ms mt mu mi b">data</code>对象的一个<code class="fe ms mt mu mi b">edge_norm</code>属性返回。我们可以在用<code class="fe ms mt mu mi b">edge_norm</code>属性正向传递我们的图形神经网络之前修改<code class="fe ms mt mu mi b">edge_weight</code>属性。</p><pre class="lp lq lr ls gt mh mi mj mk aw ml bi"><span id="77e4" class="mm mn it mi b gy mo mp l mq mr">edge_weight = data.edge_norm * data.edge_weight            <br/>out = model(data.x, data.edge_index, edge_weight)</span></pre></div><div class="ab cl mw mx hx my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="im in io ip iq"><p id="db81" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[1]费伊先生。<a class="ae le" href="https://pytorch-geometric.readthedocs.io/en/latest/index.html" rel="noopener ugc nofollow" target="_blank"> PyTorch几何</a>。图形深度学习库。</p><p id="2da5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[2] W. Hamilton等人，<a class="ae le" href="https://arxiv.org/abs/1706.02216" rel="noopener ugc nofollow" target="_blank">大型图上的归纳表征学习</a> (2017)。</p><p id="82b8" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[3] W .胡等著<a class="ae le" href="https://ogb.stanford.edu/" rel="noopener ugc nofollow" target="_blank">开图基准</a> (2020)。</p><p id="7b5e" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">[4] H. Zeng等，<a class="ae le" href="https://arxiv.org/abs/1907.04931" rel="noopener ugc nofollow" target="_blank"> GraphSAINT:基于图抽样的归纳学习方法</a> (2020)</p><p id="c4b4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">5布朗斯坦先生。<a class="ae le" rel="noopener" target="_blank" href="/simple-scalable-graph-neural-networks-7eb04f366d07">简单可扩展图形神经网络</a> (2020)。</p></div></div>    
</body>
</html>