<html>
<head>
<title>Comparing Modern Scalable Hyperparameter Tuning Methods</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">比较现代可扩展超参数调整方法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/comparing-modern-scalable-hyperparameter-tuning-methods-dfe9661e947f?source=collection_archive---------23-----------------------#2020-09-28">https://towardsdatascience.com/comparing-modern-scalable-hyperparameter-tuning-methods-dfe9661e947f?source=collection_archive---------23-----------------------#2020-09-28</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="7d79" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">随机搜索、使用超点的贝叶斯搜索、结合异步超带的贝叶斯搜索和基于群体的训练的比较</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7202fc9902d5b3bb36a6e75ef98162dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4210PNxC__BXf01nV7eK8A.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">来源—<a class="ae ky" href="https://pixabay.com/photos/excavators-bucket-wheel-excavators-1050501/" rel="noopener ugc nofollow" target="_blank">https://pix abay . com/photos/挖掘机-铲斗-车轮-挖掘机-1050501/ </a></p></figure><p id="8bf6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在本帖中，我们将比较以下超参数优化方法。</p><ul class=""><li id="1291" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">随机搜索</li><li id="d5fb" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用超点的贝叶斯搜索</li><li id="c019" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">结合异步超带的贝叶斯搜索</li><li id="7676" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">基于人口的培训</li></ul><h2 id="e812" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">实验</h2><p id="2263" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们将在MNIST数据集上训练一个简单的DCGAN，并优化模型以最大化初始得分。</p><p id="939f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将使用Ray Tune来执行这些实验，并在W&amp;B仪表板上跟踪结果。</p><p id="e62b" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我还在我的频道上做了一个视频，深入解释了这个实验-</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nh ni l"/></div></figure><p id="27bd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated"><a class="ae ky" href="https://wandb.ai/wandb/DistHyperOpt/reports/Modern-Scalable-Hyperparameter-Tuning-Methods--VmlldzoyMTQxODM?accessToken=nsw4hlcncv7ucazd6z8zvm8amu7ltx6zkka5vsoikola3lm7m1m3zqi1r02u2hce" rel="noopener ugc nofollow" target="_blank">链接到实时仪表盘</a></p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="97d9" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">搜索空间</h2><p id="0d6f" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">为了使比较公平，我们将对所有实验使用相同的搜索空间。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ni l"/></div></figure><h1 id="1a39" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">随机搜索</h1><p id="48e1" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">让我们在搜索空间中执行随机搜索，看看它的优化效果如何。这也将作为我们比较的基准指标。我们的实验设置有2个GPU和4个CPU。我们将在多个GPU上并行化操作。如果您指定了<code class="fe oc od oe of b">resources_per_trail</code>，光线调节会自动为您执行此操作。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ni l"/></div></figure><p id="0d93" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们看看结果</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/06f6ba6a9861ba351a162bfa458a890e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZdU9C3WdYNV5bLRdmGr4kg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="810d" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">推理</h2><p id="2d85" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">正如所料，我们得到了不同的结果。</p><ul class=""><li id="b4e5" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated"><strong class="lb iu">一些型号确实优化了</strong>，因为调谐器运气好，选择了正确的超参数集</li><li id="1042" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">但是一些模型的<strong class="lb iu">初始得分图仍然是平坦的</strong>，因为它们由于不好的超参数值而没有优化。</li><li id="6d50" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">因此，当使用随机搜索时，您可能最终会达到最优值，但是<strong class="lb iu">您最终肯定会在不增加任何价值的运行中浪费大量资源</strong>。</li></ul><h1 id="e644" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">超点贝叶斯搜索</h1><p id="82d4" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">贝叶斯超参数调整背后的基本思想是<strong class="lb iu">在选择超参数</strong>时不是完全随机的，而是使用来自先前运行的<strong class="lb iu">信息来选择下一次运行的超参数。Tune支持实现贝叶斯搜索算法的HyperOpt。这是你怎么做的。</strong></p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ni l"/></div></figure><p id="0c41" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">结果看起来是这样的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oh"><img src="../Images/8afb037883e39755ad5417cee05ae04b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WJVuxaAZ601uj3GNSzfasw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="d6f8" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">推理</h2><ul class=""><li id="48d9" class="lv lw it lb b lc nc lf nd li oi lm oj lq ok lu ma mb mc md bi translated">与之前的运行相比有显著的改进，因为只有一条平曲线。</li><li id="6338" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">这意味着搜索算法基于先前运行的结果选择超参数值。</li><li id="b506" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">平均而言，运行比随机搜索表现更好</li><li id="5223" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">可以通过更早地终止不良运行来避免资源浪费。</li></ul><h1 id="bcd1" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">异步超带贝叶斯搜索</h1><p id="70b5" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">异步超带的想法是<strong class="lb iu">消除或终止表现不佳的运行</strong>。将这种方法与贝叶斯搜索结合起来是有意义的，看看我们是否可以在没有优化的运行中进一步减少资源的浪费。我们只需要在代码中做一点小小的改动来适应Hyperband。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ni l"/></div></figure><p id="d386" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们看看这是如何执行的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ol"><img src="../Images/4d02ac2be89bedcad074310d12a283c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Hww1r2zrVElXeK6_lojtg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="c867" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">推理</h2><ul class=""><li id="2ca7" class="lv lw it lb b lc nc lf nd li oi lm oj lq ok lu ma mb mc md bi translated">20次运行中只有2次在规定的时期内执行，而其他运行则提前终止。</li><li id="4d55" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">所达到的最高精度仍然略高于没有Hyperband调度程序的运行。</li><li id="4b2c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">因此，通过在训练过程的早期终止不良运行，我们不仅加快了调优工作，还节省了计算资源。</li></ul><h1 id="e7d7" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">基于人口的培训</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi om"><img src="../Images/4e0280830902df461f06c0edba36bd7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MXTeOTxoAPnIXSAT8E153Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来源—<a class="ae ky" href="https://wandb.ai/wandb/DistHyperOpt/reports/Modern-Scalable-Hyperparameter-Tuning-Methods--VmlldzoyMTQxODM?accessToken=nsw4hlcncv7ucazd6z8zvm8amu7ltx6zkka5vsoikola3lm7m1m3zqi1r02u2hce" rel="noopener ugc nofollow" target="_blank">https://wandb . ai/wandb/distroopt/reports/Modern-Scalable-Hyperparameter-Tuning-Methods-VmlldzoyMTQxODM</a></p></figure><p id="470f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们将讨论的最后一个调优算法是由Deepmind research引入的基于群体的训练(PBT)。通俗地说，算法背后的基本思想是:</p><ul class=""><li id="a682" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">对于给定的时间步长(或迭代次数)t，对一些样本运行优化过程</li><li id="d5ed" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">在每T次迭代之后，比较运行，并将良好运行的权重复制到不良运行，并改变它们的超参数值以接近良好运行的值。</li><li id="6706" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">终止表现最差的运行。尽管算法背后的想法似乎很简单，但从头开始构建它需要大量复杂的优化数学。<strong class="lb iu"> Tune提供了SOTA PBT算法的可扩展且易于使用的实现</strong></li></ul><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="nq ni l"/></div></figure><p id="35f0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在让我们看看结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi on"><img src="../Images/69e20ee6c31c5b4141e1c4c053d15986.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RKW3Z2fjjAVUTzarm6wrWg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h2 id="d707" class="mj mk it bd ml mm mn dn mo mp mq dp mr li ms mt mu lm mv mw mx lq my mz na nb bi translated">推理</h2><p id="54a3" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">结果看起来相当令人惊讶。这些结果有许多独特的因素。</p><ul class=""><li id="2af8" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">几乎所有的运行都达到了最佳点</li><li id="d27b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">最高分(6.29)是由一次跑步获得的</li><li id="72ea" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">随着实验的进行，开始时表现不佳或异常的运行也收敛了。</li><li id="93db" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">没有运行具有平坦的初始得分图</li><li id="e18d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">一些表现不佳的运行在过程中被停止</li><li id="6ba8" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">因此，<strong class="lb iu">没有资源被浪费在不良运行上</strong></li></ul><h1 id="867f" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">PBT是如何优化从错误的超参数值开始的运行的？</h1><p id="aaa0" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">答案是由PBT调度程序完成的<strong class="lb iu">超参数突变</strong>。在每一个<code class="fe oc od oe of b">T</code>时间步之后，该算法还变异超参数的值，以最大化期望的度量。下面是PBT调度程序在这个实验中是如何改变参数的。</p><h1 id="51d4" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">超参数突变</h1><p id="1285" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">现在让我们看看超参数是如何被PBT算法调整来最大化初始得分的</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oo"><img src="../Images/781ab3ccc44b82d6ae209592abde02f4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2QXiYa9GG_-iJ7UdQ5L_KA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi og"><img src="../Images/d1f0f407ad9696524c043c0d7f98b7d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DzR5mkR4oSGZbiMMgBoQ9Q.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="db40" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">推理</h1><ul class=""><li id="33a2" class="lv lw it lb b lc nc lf nd li oi lm oj lq ok lu ma mb mc md bi translated">超参数值在整个实验过程中不断调整。</li><li id="c32f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">以坏的超参数值开始的运行很快被更新。</li><li id="e59a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">PBT根据<strong class="lb iu">探索和利用</strong>方法运行，探索良好参数值的空间，并通过更新不良运行来利用。</li></ul><h1 id="f41d" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">减少运行次数</h1><p id="4938" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">我们现在<strong class="lb iu">将运行次数减少到5次</strong>，以便给PBT制造困难。让我们看看它在这种受限的情况下表现如何。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi op"><img src="../Images/d094766f0ca9522f76a780d9337528d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Oa6o6GMuDsLF883XhG3EuQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="dce2" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">推理</h1><ul class=""><li id="ef59" class="lv lw it lb b lc nc lf nd li oi lm oj lq ok lu ma mb mc md bi translated">即使将运行次数减少到5次，PBT optimizer仍然优于随机搜索和贝叶斯优化。</li><li id="6606" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">正如预期的那样，表现不佳的运行在训练过程的早期就被终止了</li></ul><h1 id="3961" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">比较各次运行的平均初始得分</h1><p id="8486" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">以下是平均盗梦分数的最终比较结果。我们对5次运行集进行了平均:</p><ul class=""><li id="0902" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">随机搜索— 10次运行(作业类型—随机)</li><li id="0390" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">贝叶斯搜索— 10次运行(工作类型—mnist-hyperpt)</li><li id="f756" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用Hyperband的贝叶斯搜索-20次运行(工作类型-mnist-SHA2-hyperpt)</li><li id="07d0" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">PBT调度程序— 10次运行(作业类型— mnist-pbt2)</li><li id="9cc3" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">PBT调度程序— 5次运行(作业类型— mnist-pbt3)</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oq"><img src="../Images/80ffa405d08721931abd607d70863e23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SbIPGq4twzah3c8HJy5SgQ.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者图片</p></figure><h1 id="5ada" class="nr mk it bd ml ns nt nu mo nv nw nx mr jz ny ka mu kc nz kd mx kf oa kg na ob bi translated">结尾注释</h1><p id="42a5" class="pw-post-body-paragraph kz la it lb b lc nc ju le lf nd jx lh li ne lk ll lm nf lo lp lq ng ls lt lu im bi translated">如果你喜欢读这篇文章，你可以在<a class="ae ky" href="https://twitter.com/ayushex" rel="noopener ugc nofollow" target="_blank">推特</a>上关注我，获取更多更新。我还在我的youtube频道上制作深度学习视频。</p></div></div>    
</body>
</html>