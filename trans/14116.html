<html>
<head>
<title>How to Calculate the Number of Parameters in Keras Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何计算Keras模型中的参数个数</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/how-to-calculate-the-number-of-parameters-in-keras-models-710683dae0ca?source=collection_archive---------8-----------------------#2020-09-29">https://towardsdatascience.com/how-to-calculate-the-number-of-parameters-in-keras-models-710683dae0ca?source=collection_archive---------8-----------------------#2020-09-29</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="fe31" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">了解您的顺序Keras模型的摘要</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/ab6bfe1f50e75f9ca9fbbe12bf187ae3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*zJBL7B7k-V3-sfbD"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://unsplash.com/@artifactflash?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">戈登·威廉姆斯</a>在<a class="ae ky" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h1 id="c5ca" class="kz la it bd lb lc ld le lf lg lh li lj jz lk ka ll kc lm kd ln kf lo kg lp lq bi translated">介绍</h1><p id="f1a5" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">尽管新的ML框架正在出现，keras模型仍然是许多数据科学家的最爱。对于新的学习者来说，他们可能有的一个主要问题是通过遵循特定的教程来理解他们正在构建的模型。为了将我们的讨论放在一个环境中，让我们假设我们正在使用MNIST数据集构建一个Conv2D模型。以下代码向您展示了Python代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mn mo l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">Keras Conv2D模型</p></figure><ul class=""><li id="7290" class="mp mq it lt b lu mr lx ms ma mt me mu mi mv mm mw mx my mz bi translated">如果你不熟悉MNIST数据集，它是由0-9位数字组成的图像集合。这些图像是灰度级的，因此每个图像可以用28×28×1的输入形状来表示，如第5行所示。</li><li id="4837" class="mp mq it lt b lu na lx nb ma nc me nd mi ne mm mw mx my mz bi translated">请注意，本文的目的不是向您介绍卷积网络的工作原理，因此对这些主题的覆盖范围将是最小的。正如你所见，我们的模型包括一个堆栈的2D卷积网络层和最大池层。</li><li id="ac6f" class="mp mq it lt b lu na lx nb ma nc me nd mi ne mm mw mx my mz bi translated">在模型的末尾，我们创建了一个密集层，最后输出10个激活了softmax的节点。节点数对应于模型预测的位数。</li><li id="cffd" class="mp mq it lt b lu na lx nb ma nc me nd mi ne mm mw mx my mz bi translated"><code class="fe nf ng nh ni b">summary()</code>函数将为模型创建一个摘要，这是本文的重点。</li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="a313" class="nq la it bd lb nr ns dn lf nt nu dp lj ma nv nw ll me nx ny ln mi nz oa lp ob bi translated">模型摘要</h2><p id="30a3" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">下图显示了<code class="fe nf ng nh ni b">summary()</code>函数的输出。每一行代表一个层，每个层都有唯一的名称，这样我们可以毫无歧义地引用这些层。正如您所看到的，我们在前面的代码片段中添加到模型中的层都包含在下图中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="mn mo l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">模型摘要</p></figure><ul class=""><li id="a7ec" class="mp mq it lt b lu mr lx ms ma mt me mu mi mv mm mw mx my mz bi translated">每个层都有一个输出，其形状显示在“输出形状”列中。每一层的输出成为下一层的输入。</li><li id="1eb1" class="mp mq it lt b lu na lx nb ma nc me nd mi ne mm mw mx my mz bi translated">“Param #”列显示了为每层训练的参数数量。</li><li id="b087" class="mp mq it lt b lu na lx nb ma nc me nd mi ne mm mw mx my mz bi translated">参数总数显示在最后，等于可训练和不可训练参数的数量。在这个模型中，所有的层都是可训练的。为了不使文章复杂化，我们不打算操纵某些层的可训练性。出于好奇，在Keras中，我们可以选择不训练特定的层，这样做的话，一定数量的参数将不可训练。</li></ul></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="754b" class="kz la it bd lb lc oc le lf lg od li lj jz oe ka ll kc of kd ln kf og kg lp lq bi translated">参数计算</h1><h2 id="30d9" class="nq la it bd lb nr ns dn lf nt nu dp lj ma nv nw ll me nx ny ln mi nz oa lp ob bi translated"><strong class="ak"> MaxPooling2D层</strong></h2><p id="4752" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">先说简单的。您可以注意到，所有MaxPooling2D层的参数数量都是0。原因是这一层什么都不学。它的作用是降低模型的复杂性，并通过找到每个2×2池的最大值来提取局部特征。</p><p id="0de9" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma oh mc md me oi mg mh mi oj mk ml mm im bi translated">如前所述，MaxPooling2D层使用前一层的输出。因此，<code class="fe nf ng nh ni b">max_pooling2d</code>层的输入具有从<code class="fe nf ng nh ni b">conv2d</code>层输出的(26，26，32)形状。最大池应用于形状为(26，26)的每个过滤器(n=32)。在模型中，对于<code class="fe nf ng nh ni b">max_pooling2d</code>层，池的大小是2×2，因此数据的形状将变成(13，13)，也就是(26 / 2，26 / 2)。</p><p id="70ca" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma oh mc md me oi mg mh mi oj mk ml mm im bi translated">同样，对于第二个MaxPooling2D层(即<code class="fe nf ng nh ni b">max_pooling2d_1</code>)，输入形状为(11，11，64)。通过应用2 x 2池，产生的输出形状变为(5，5，64)，如“输出形状”列所示。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="613b" class="nq la it bd lb nr ns dn lf nt nu dp lj ma nv nw ll me nx ny ln mi nz oa lp ob bi translated">Conv2D层</h2><p id="7774" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在我们的模型中，我们有三个Conv2D层，这些层的参数计算遵循相同的原则，如下式所示。数字1表示与我们正在学习的每个滤波器相关的偏差。</p><pre class="kj kk kl km gt ok ni ol om aw on bi"><span id="a06d" class="nq la it ni b gy oo op l oq or">param_number = output_channel_number * (input_channel_number * kernel_height * kernel_width + 1)</span></pre><p id="0b4a" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma oh mc md me oi mg mh mi oj mk ml mm im bi translated">将此公式应用于第一个Conv2D层(即<code class="fe nf ng nh ni b">conv2d</code>，我们可以用32 * (1 * 3 * 3 + 1) = 320计算出参数个数，与模型总结一致。输入通道号是1，因为输入数据形状是28 x 28 x 1，数字1是输入通道。</p><p id="9297" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma oh mc md me oi mg mh mi oj mk ml mm im bi translated">对于第二个Conv2D层(即<code class="fe nf ng nh ni b">conv2d_1</code>)，我们有如下计算:64 * (32 * 3 * 3 + 1) = 18496，与该层的模型摘要中显示的数字一致。这里需要注意的两件事是，输出通道号是64，如模型构建中所指定的，输入通道号是来自先前MaxPooling2D层的32(即<code class="fe nf ng nh ni b">max_pooling2d</code>)。</p><p id="7f57" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma oh mc md me oi mg mh mi oj mk ml mm im bi translated">以类似的方式，我们可以计算第三Conv2D层的参数数量(即<code class="fe nf ng nh ni b">conv2d_2</code> ): 64 * (64 * 3 * 3 + 1) = 36928，与模型摘要一致。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="57c5" class="nq la it bd lb nr ns dn lf nt nu dp lj ma nv nw ll me nx ny ln mi nz oa lp ob bi translated">展平图层</h2><p id="1787" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">展平的层不学习任何东西，因此参数的数量是0。然而，知道如何确定输出是很有趣的。如你所见，<code class="fe nf ng nh ni b">flatten</code>层的输入具有(3，3，64)的形状。展平层只是展平输入数据，因此输出形状是通过使用3 * 3 * 64(即576，与<code class="fe nf ng nh ni b">flatten</code>层的输出形状中显示的数字一致)连接所有现有参数来使用它们。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h2 id="0da7" class="nq la it bd lb nr ns dn lf nt nu dp lj ma nv nw ll me nx ny ln mi nz oa lp ob bi translated">致密层</h2><p id="013f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">我们的模型中有两个密集层。参数数值的计算使用以下公式。</p><pre class="kj kk kl km gt ok ni ol om aw on bi"><span id="c338" class="nq la it ni b gy oo op l oq or">param_number = output_channel_number * (input_channel_number + 1)</span></pre><p id="bfef" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma oh mc md me oi mg mh mi oj mk ml mm im bi translated">应用这个公式，我们可以计算致密层的参数数目。对于第一密集层(即<code class="fe nf ng nh ni b">dense</code>)，输入通道数是576，而输出通道数是64，因此参数数是64 * (576 + 1) = 36928。</p><p id="7e30" class="pw-post-body-paragraph lr ls it lt b lu mr ju lw lx ms jx lz ma oh mc md me oi mg mh mi oj mk ml mm im bi translated">对于第二密集层(即<code class="fe nf ng nh ni b">dense_1</code>)，输入和输出通道数分别为64和10。因此，参数的数量是10 * (64 + 1) = 650，与模型摘要中显示的数量一致。</p></div><div class="ab cl nj nk hx nl" role="separator"><span class="nm bw bk nn no np"/><span class="nm bw bk nn no np"/><span class="nm bw bk nn no"/></div><div class="im in io ip iq"><h1 id="122d" class="kz la it bd lb lc oc le lf lg od li lj jz oe ka ll kc of kd ln kf og kg lp lq bi translated">结论</h1><p id="bf8f" class="pw-post-body-paragraph lr ls it lt b lu lv ju lw lx ly jx lz ma mb mc md me mf mg mh mi mj mk ml mm im bi translated">在本文中，我们回顾了如何理解Keras模型中的参数数量。具体来说，我们使用Conv2D模型进行演示。虽然您的模型可能不同，但计算参数数量的原则是相同的-公式应该连接输入和输出数据，并定位模型的定型位置。</p></div></div>    
</body>
</html>