<html>
<head>
<title>An Intuitive Look at GANs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">对GANs的直观了解</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/an-intuitive-look-at-gans-1aa35e27cb52?source=collection_archive---------39-----------------------#2020-11-15">https://towardsdatascience.com/an-intuitive-look-at-gans-1aa35e27cb52?source=collection_archive---------39-----------------------#2020-11-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="e689" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">学习GANs如何工作背后的直觉，而不需要复杂的数学方程。</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/e288a0edd954b65d69b0cebe667cca7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*m5qRNRP9gZoLmQY-"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马里奥·高在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h1 id="6c12" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">介绍</h1><p id="4f57" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">自Goodfellow等人于2014年在<a class="ae kv" href="http://papers.nips.cc/paper/5423-generative-adversarial-nets" rel="noopener ugc nofollow" target="_blank"> NIPS </a>推出GANs(生成对抗网络)以来，GANs已经在深度学习和计算机视觉领域掀起了风暴。GANs的主要思想是同时训练两个模型；一个生成器模型<strong class="lq ir"> <em class="mk"> G </em> </strong>基于随机噪声生成样本，另一个鉴别器模型<strong class="lq ir"> <em class="mk"> D </em> </strong>确定样本是真实的还是由<strong class="lq ir"> <em class="mk"> G </em> </strong>生成的。</p><p id="fd35" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">这篇文章将介绍GANs工作背后的直觉，而不会过多地钻研损失函数、概率分布和数学。重点是对GANs如何运作有一个很好的顶层理解。鉴于GANs越来越受欢迎，重要的是任何人都能够在不预先加载太多复杂信息的情况下开始他们的深度学习之旅！对于完整的解释，<a class="ae kv" href="https://medium.com/@joseph.rocca" rel="noopener">约瑟夫·罗卡</a>有一大篇<a class="ae kv" rel="noopener" target="_blank" href="/understanding-generative-adversarial-networks-gans-cd6e4651a29">T21一篇</a>关于它！</p><p id="f08e" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">训练GAN框架类似于两个玩家的最小-最大游戏。<strong class="lq ir"> <em class="mk"> G </em> </strong>不断改进，生成更逼真、质量更好的图像。<strong class="lq ir"> <em class="mk"> D </em> </strong>提高了确定图像是否由<strong class="lq ir"> <em class="mk"> G </em> </strong>创建的能力。训练GAN可以完全通过反向传播来完成，这极大地简化了训练过程。通常，通过从<strong class="lq ir"> <em class="mk"> G </em> </strong>到<strong class="lq ir"> <em class="mk"> D </em> </strong>的定期切换来执行训练，以防止两个模型中的巨大性能差距。</p><h1 id="b63a" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">发电机模型</h1><p id="7ee2" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">发生器模型通常由一系列上采样和卷积层组成。一种常见的架构是DC(深度卷积)-GAN网络，由<a class="ae kv" href="https://arxiv.org/search/cs?searchtype=author&amp;query=Radford%2C+A" rel="noopener ugc nofollow" target="_blank">亚历克·拉德福德</a>等人在<a class="ae kv" href="https://dblp.org/db/conf/iclr/iclr2016.html" rel="noopener ugc nofollow" target="_blank"> ICLR 2016 </a>上展示。DCGAN框架可以在下面找到。如果你见过其他常见的CNN框架，GAN结构非常类似于标准的CNN分类器，只是它是水平“翻转”的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mq"><img src="../Images/10b4cc5d546acd5024576f9e9a7c45a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k14oQ6lI__zetNmjxDSSeQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">来自https://arxiv.org/abs/1511.06434<a class="ae kv" href="https://arxiv.org/abs/1511.06434" rel="noopener ugc nofollow" target="_blank">的DCGAN架构</a></p></figure><p id="c337" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">提供给发电机网络的输入在图中标记为“100z”。这意味着采样了100个点，创建了长度为100的潜在向量。“z”还表示这些点是从单位正态分布中取样的。因此，我们可以将生成器网络视为执行从潜在空间到训练数据的映射的函数。</p><p id="9665" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">我们可以把潜在空间(100维)想象成基于高斯分布的固定分布。生成器网络从这个潜在空间中随机采样点，并将其映射到图像空间(64 x 64 x 3维)。在所有可能图像的空间中，存在描述在输入训练数据中找到的图像的更小的子空间。鉴别器将对生成器进行处罚，因为它通过对抗性损失函数创建了不属于训练数据分布(非“真实”)的图像。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mr"><img src="../Images/449a953da33ab88d03ea9fa5141b9d66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x8XngG0Ltfa-MCcj6eLdAg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">生成器的映射功能，由作者生成图像</p></figure><h1 id="b7ea" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">鉴别器模型</h1><p id="ff6e" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">鉴别器通常具有类似于标准CNN分类器的框架，例如VGG。鉴别器的目的是学习根据图像是来自训练数据还是由<strong class="lq ir"> <em class="mk"> G </em> </strong>生成来将输入图像分类为真实或虚假。看下图，鉴别器的目的是学习红色虚线。因此，它将能够根据该输入数据分布来分类真实和伪造的图像。如果提供的图像位于红色空间之外，它们将被归类为“假的”。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ms"><img src="../Images/52a5af77868fd37e4b6d5743c6c46472.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*i0CBlThRAjlIoBIKvjnHeg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">鉴别学习，作者图片</p></figure><h1 id="bacc" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">g和D串联</h1><p id="32d6" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">在GAN框架中，<strong class="lq ir"> <em class="mk"> G </em> </strong>和<strong class="lq ir"> <em class="mk"> D </em> </strong>模型必须一起训练。这两种模型的改进最终会产生更好、更真实的图像。一个好的鉴别器模型可以完美地捕捉训练数据分布。这允许发生器具有良好的“参考”空间，因为发生器的训练高度依赖于鉴别器输出。</p><p id="d739" class="pw-post-body-paragraph lo lp iq lq b lr ml jr lt lu mm ju lw lx mn lz ma mb mo md me mf mp mh mi mj ij bi translated">如果鉴别器没有很好地捕捉到训练数据分布，生成的与训练图像不相似的图像将被归类为“真实的”,这将降低模型性能！</p><h1 id="bd6f" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">限制</h1><p id="0859" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">很明显，这个简单的GAN框架只能产生类似于训练数据分布的图像。因此，需要大量的训练数据！此外，甘的训练还有许多障碍。一个常见的问题是模式崩溃，即生成器模型学习将多个潜在向量映射到一个单独的图像。这极大地影响了GAN框架的多样性。</p><h1 id="0891" class="kw kx iq bd ky kz la lb lc ld le lf lg jw lh jx li jz lj ka lk kc ll kd lm ln bi translated">结论</h1><p id="6e9f" class="pw-post-body-paragraph lo lp iq lq b lr ls jr lt lu lv ju lw lx ly lz ma mb mc md me mf mg mh mi mj ij bi translated">近年来有许多解决这些问题的GANs的变化和发展。其中包括改进的损失函数和为特定任务定制的专门框架，如超分辨率或图像到图像的翻译。</p></div></div>    
</body>
</html>