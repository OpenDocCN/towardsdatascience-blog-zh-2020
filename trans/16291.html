<html>
<head>
<title>Why XGBoost can’t solve all your problems.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">为什么XGBoost不能解决你所有的问题。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/why-xgboost-cant-solve-all-your-problems-b5003a62d12a?source=collection_archive---------9-----------------------#2020-11-10">https://towardsdatascience.com/why-xgboost-cant-solve-all-your-problems-b5003a62d12a?source=collection_archive---------9-----------------------#2020-11-10</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="9cb0" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/getting-started" rel="noopener" target="_blank">入门</a></h2><div class=""/><div class=""><h2 id="5206" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">XGBoost和其他基于树的算法的一个关键限制。</h2></div><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi kr"><img src="../Images/f83d44819fdd208026d095e5c6fccf65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*py3aitkpgm_YK_t0ktTx6Q.jpeg"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">由<a class="ae lh" href="https://unsplash.com/@drkolomiyets?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">谢尔盖·科洛米耶茨</a>在<a class="ae lh" href="https://unsplash.com/s/photos/tree-algorithms?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="5a7c" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果你曾经在Kaggle上参加过机器学习比赛，或者浏览过数据科学社区撰写的文章或论坛，你可能听说过XGBoost。这种算法已经赢得了许多Kaggle竞赛，并且有许多基准研究表明XGBoost始终优于其他算法。XGBoost是并行的，并且比其他梯度增强实现运行得更快，这一事实增加了它的吸引力。</p><p id="3024" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于那些不熟悉这个工具的人来说，<a class="ae lh" href="https://xgboost.readthedocs.io/en/latest/" rel="noopener ugc nofollow" target="_blank"> XGBoost </a>(代表“极端梯度提升”)是一个高度优化的框架，用于<a class="ae lh" href="https://en.wikipedia.org/wiki/Gradient_boosting" rel="noopener ugc nofollow" target="_blank">梯度提升</a>，<strong class="lk jd">一种迭代地组合几个弱学习器(如决策树)的预测的算法，以产生一个更强大、更健壮的模型</strong>。自2014年问世以来，XGBoost已经成为许多数据科学家和机器学习实践者的首选算法。</p><blockquote class="me mf mg"><p id="564f" class="li lj mh lk b ll lm kd ln lo lp kg lq mi ls lt lu mj lw lx ly mk ma mb mc md im bi translated"><em class="it">“有疑问的时候用XGBoost”——</em><a class="ae lh" href="https://www.kaggle.com/c/avito-context-ad-clicks" rel="noopener ugc nofollow" target="_blank"><em class="it">Avito</em></a><em class="it">上下文Ad点击预测比赛上Kaggle </em></p></blockquote><p id="ffb7" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这听起来可能好得难以置信，对吗？XGBoost对于许多任务来说无疑是强大而有用的，但是有一个问题…事实上，这个问题不仅影响XGBoost，而且影响所有基于树的算法。</p></div><div class="ab cl ml mm hx mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="im in io ip iq"><h1 id="ea3a" class="ms mt it bd mu mv mw mx my mz na nb nc ki nd kj ne kl nf km ng ko nh kp ni nj bi translated">基于树的模型不擅长外推</h1><p id="63f2" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">这可能是所有基于树的模型固有的根本缺陷。不管你有一个决策树，一个有100棵树的随机森林，还是一个有1000棵树的XGBoost模型。由于基于树的模型划分任何给定问题的输入空间的方法，这些算法在进行预测时很大程度上<strong class="lk jd">无法外推超出训练数据</strong>限制的目标值。在分类任务中，这通常不是一个大问题，但在涉及预测连续输出的回归任务中，这绝对是一个限制。</p><p id="4d66" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果训练数据集只包含0到100之间的目标值，则基于树的回归模型将很难预测出该范围之外的值。以下是一些预测性任务的例子，在这些任务中，外推很重要，而XGBoost可能并不奏效…</p><h2 id="4c65" class="np mt it bd mu nq nr dn my ns nt dp nc lr nu nv ne lv nw nx ng lz ny nz ni iz bi translated">预测气候变化对全球气温的影响</h2><p id="7fc6" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">在过去的100年里，全球气温上升的速度越来越快。想象一下，试图使用1900年到2020年的数据来预测未来20年的全球气温。像XGBoost这样的基于树的算法将受到今天全球最高温度的限制。如果气温继续上升，该模型肯定会低估未来20年全球气温的上升。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oa"><img src="../Images/5f50dfd633edeb48983622b8fde918a2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XzxBgNLtd93pwwiAqT3uQ.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">从1880年到2020年的全球温度异常。来源:<a class="ae lh" href="https://climate.nasa.gov/vital-signs/global-temperature/" rel="noopener ugc nofollow" target="_blank">美国宇航局GISS </a></p></figure><h2 id="8419" class="np mt it bd mu nq nr dn my ns nt dp nc lr nu nv ne lv nw nx ng lz ny nz ni iz bi translated">预测股票市场指数(如标准普尔500)的价格</h2><p id="f292" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">如果我们观察一个受欢迎的股票市场指数如标准普尔500在过去50年的趋势，我们会发现该指数的价格经历了高点和低点，但最终会随着时间的推移而上涨。事实上，根据历史数据，标准普尔500的平均年回报率约为10%，这意味着价格平均每年上涨约10%。尝试使用XGBoost预测标准普尔500的价格，您会发现它可能会预测价格下降，但无法捕捉数据中的整体上升趋势。公平地说，预测股票市场价格是一个极其困难的问题，即使是机器学习也没有解决，但关键是，XGBoost无法预测超出训练数据中存在的范围的价格上涨。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ob"><img src="../Images/e12a37b820abe8eb26c405e0d47ffb29.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JNTpZmVsyoZlTnKcWoEOIg.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">标准普尔500历史价格。来源:标准普尔转载自multpl.com的<a class="ae lh" href="https://www.multpl.com/s-p-500-historical-prices" rel="noopener ugc nofollow" target="_blank">。</a></p></figure><h2 id="ace8" class="np mt it bd mu nq nr dn my ns nt dp nc lr nu nv ne lv nw nx ng lz ny nz ni iz bi translated">预测网络流量</h2><p id="e5b9" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">这个任务是我几年前参加的下面这个<a class="ae lh" href="https://www.kaggle.com/c/web-traffic-time-series-forecasting" rel="noopener ugc nofollow" target="_blank"> Kaggle比赛</a>的目标。正如XGBoost可能无法捕捉全球气温或股票价格的增长趋势一样，如果一个网页正在传播，那么即使增长趋势很明显，XGBoost也可能无法预测该页面的流量增长。</p><h1 id="46d3" class="ms mt it bd mu mv oc mx my mz od nb nc ki oe kj ne kl of km ng ko og kp ni nj bi translated"><strong class="ak">树木不擅长外推背后的数学原理</strong></h1><p id="6732" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">决策树获取输入空间并将其划分为子部分，每个子部分对应一个单一的输出值。即使在回归问题中，决策树也使用有限的规则集来输出有限的可能值集中的一个值。由于这个原因，用于回归的决策树总是难以对连续函数建模。考虑下面的例子，决策树可以用来预测房子的价格。请记住，我下面创建的数据集是完全虚构的，并且只用于证明一个观点。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oh"><img src="../Images/e9d14bfbe2d2dcba60cc26c56f32b9dd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BAIvE9fa8WDU2sBWEEzU8A.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">一个简单的房价数据集。</p></figure><p id="8585" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">如果我们使用这个小数据集来训练决策树，下面的树可能最终成为我们预测房价的模型。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi oi"><img src="../Images/7b34e685fcb81b8585ff6d7c939ef6bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7ceiokUSwDD7St68ifNBrw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">一种简单的房价预测决策树。</p></figure><p id="1a25" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">显然，这不是一个很好的模型或数据集，但它展示了决策树回归的一个基本问题。根据数据集，似乎卧室的数量和房子的大小与其价格正相关。换句话说，有更多卧室的大房子比有更少卧室的小房子要贵。这似乎合乎逻辑，但决策树永远不会预测低于20万美元的价格或高于55万美元的价格，因为它已经<strong class="lk jd">将无限的输入空间划分为有限的可能性集</strong>。由于决策树回归模型根据平均值为树叶赋值，请注意，由于有两栋4000平方英尺的三居室房屋，决策树预测了这两栋房屋在这种情况下的平均价格($550，000)。即使数据集中存在价值600，000美元的房子，决策树也无法识别价值600，000美元的房子。</p><p id="b668" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">即使像XGBoost这样的模型计算了1000个决策树的加权平均值，每个决策树也将被限制为仅预测一组范围的值，因此，加权平均值也被限制为取决于训练数据的预定范围的值。</p><h1 id="d8c5" class="ms mt it bd mu mv oc mx my mz od nb nc ki oe kj ne kl of km ng ko og kp ni nj bi translated">基于树的模型擅长做什么</h1><p id="e713" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">虽然基于树的模型不擅长外推，但它们仍然擅长解决广泛的机器学习问题。XGBoost通常不能很好地预测未来，但它非常适合以下任务:</p><ul class=""><li id="501c" class="oj ok it lk b ll lm lo lp lr ol lv om lz on md oo op oq or bi translated"><strong class="lk jd">分类问题，尤其是那些与现实世界业务问题相关的问题</strong>，如欺诈检测或客户流失预测。许多决策树的组合的基于规则的逻辑可以检测用于处理这些分类问题的合理的和可解释的模式。</li><li id="35ed" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated"><strong class="lk jd">有许多分类变量的情况</strong>。决策树基于规则的逻辑能够很好地处理包括具有诸如<em class="mh">是/否、真/假、</em>或<em class="mh">小型/中型/大型等类别的特征的数据。</em></li><li id="3b5c" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated"><strong class="lk jd">训练集中存在的目标值的范围或分布可以预期与真实世界测试数据的范围或分布相似的问题。</strong>这个条件可以适用于几乎每一个训练数据被正确采样的机器学习问题。一般来说，<em class="mh">机器学习模型的质量受到训练数据质量的限制</em>。如果数据集中房屋的价格范围在30万美元到40万美元之间，则无法训练XGBoost有效预测房价。显然会有很多房子比训练集中的房子更便宜也更贵。对于像预测房价这样的问题，你可以用更好的训练数据来解决这个问题，但是如果你试图预测未来的股票价格，XGBoost根本就行不通，因为我们对未来目标值的范围一无所知。</li></ul><h1 id="a604" class="ms mt it bd mu mv oc mx my mz od nb nc ki oe kj ne kl of km ng ko og kp ni nj bi translated">你应该用什么来代替推断</h1><p id="b411" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">对于预测或任何涉及外推的机器学习问题，<strong class="lk jd">神经网络通常会优于基于树的方法</strong>。与基于树的算法不同，神经网络能够拟合任何连续函数，从而允许它们捕捉数据中的复杂趋势。在神经网络背后的理论中，这种说法被称为<a class="ae lh" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" rel="noopener ugc nofollow" target="_blank"> <strong class="lk jd">通用逼近定理</strong> </a>。这个定理本质上是说<strong class="lk jd">一个</strong> <strong class="lk jd">神经网络只要有一个任意大小的隐藏层，就能以任何期望的精度水平逼近任何连续函数</strong>。基于这个定理，神经网络可以捕捉股票价格的上升趋势或全球气温的上升，并可以预测训练数据范围之外的值。</p><figure class="ks kt ku kv gt kw gh gi paragraph-image"><div role="button" tabindex="0" class="kx ky di kz bf la"><div class="gh gi ox"><img src="../Images/96dfef812aa052f08525383f003c4f66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Ng8B1UCAOHF7OKBiBXiUw.png"/></div></div><p class="ld le gj gh gi lf lg bd b be z dk translated">只有一个任意大小的隐藏层的神经网络可以逼近任何连续函数。作者使用<a class="ae lh" href="http://alexlenail.me/NN-SVG/LeNet.html" rel="noopener ugc nofollow" target="_blank"> NN SVG </a>创建的图像。</p></figure><p id="6873" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">对于时间序列预测问题，如预测全球气温，具有LSTM(长短期记忆)单元的递归神经网络可以非常有效。事实上，LSTMs通常可以很好地处理序列数据，我甚至在本文的<a class="ae lh" rel="noopener" target="_blank" href="/fake-news-classification-with-recurrent-convolutional-neural-networks-4a081ff69f1a">中使用它们进行文本分类。</a></p><h2 id="a3e4" class="np mt it bd mu nq nr dn my ns nt dp nc lr nu nv ne lv nw nx ng lz ny nz ni iz bi translated">这是否意味着神经网络比XGBoost更好？</h2><p id="d1f6" class="pw-post-body-paragraph li lj it lk b ll nk kd ln lo nl kg lq lr nm lt lu lv nn lx ly lz no mb mc md im bi translated">不，不一定。对于某些问题，神经网络比XGBoost更好，但肯定不是所有问题。在机器学习中，没有免费的午餐，任何算法的优势都需要付出代价。</p><p id="d6f2" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">事实上，虽然神经网络的泛化能力是一个优势，但它也是一个弱点，因为神经网络可以拟合任何函数，也可以很容易地过度拟合训练数据。神经网络也倾向于需要大量的训练数据来做出合理的预测。有趣的是，<strong class="lk jd">与基于树的算法相比，使神经网络如此强大的复杂性也使它们更加难以解释和诠释</strong>。</p><p id="6e7a" class="pw-post-body-paragraph li lj it lk b ll lm kd ln lo lp kg lq lr ls lt lu lv lw lx ly lz ma mb mc md im bi translated">这个故事的寓意是<strong class="lk jd">不是所有的算法都是平等的，但是每个算法都有缺陷，没有一个算法在所有机器学习问题和商业用例中都是普遍优越的</strong>。</p><h1 id="bae9" class="ms mt it bd mu mv oc mx my mz od nb nc ki oe kj ne kl of km ng ko og kp ni nj bi translated">摘要</h1><ul class=""><li id="df07" class="oj ok it lk b ll nk lo nl lr oy lv oz lz pa md oo op oq or bi translated">XGBoost是一个非常复杂的算法，但是像其他基于树的算法一样，当涉及到外推的任务时，它就有所欠缺。</li><li id="7d41" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated">对于各种各样的现实世界的机器学习问题，XGBoost仍然是一个很好的选择。</li><li id="47a1" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated">神经网络，尤其是具有LSTMs的递归神经网络通常更适合于时间序列预测任务。</li><li id="6dba" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md oo op oq or bi translated">机器学习中没有免费的午餐，每种算法都有自己的优缺点。</li></ul><h1 id="d5f7" class="ms mt it bd mu mv oc mx my mz od nb nc ki oe kj ne kl of km ng ko og kp ni nj bi translated">来源</h1><ol class=""><li id="b2eb" class="oj ok it lk b ll nk lo nl lr oy lv oz lz pa md pb op oq or bi translated">T.陈，C. Guestrin，<a class="ae lh" href="https://arxiv.org/abs/1603.02754" rel="noopener ugc nofollow" target="_blank"> XGBoost:一个可扩展的树增强系统</a>，(2016)，第22届ACM SIGKDD国际会议。</li><li id="4f69" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md pb op oq or bi translated">Kaggle，<a class="ae lh" href="https://www.kaggle.com/c/avito-context-ad-clicks" rel="noopener ugc nofollow" target="_blank"> Avito上下文广告点击量</a>，(2015)，Kaggle比赛。</li><li id="dbe9" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md pb op oq or bi translated">美国宇航局戈达德太空研究所(GISS)，<a class="ae lh" href="https://climate.nasa.gov/vital-signs/global-temperature/" rel="noopener ugc nofollow" target="_blank">全球气温</a>，(2020)，《全球气候变化:地球的生命体征》。</li><li id="341e" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md pb op oq or bi translated">标准普尔，<a class="ae lh" href="https://www.multpl.com/s-p-500-historical-prices" rel="noopener ugc nofollow" target="_blank"> S &amp; P 500历史价格</a>，(2020)，multpl.com。</li><li id="c827" class="oj ok it lk b ll os lo ot lr ou lv ov lz ow md pb op oq or bi translated">维基百科，<a class="ae lh" href="https://en.wikipedia.org/wiki/Universal_approximation_theorem" rel="noopener ugc nofollow" target="_blank">通用逼近定理</a>，(2020)，维基百科免费百科。</li></ol></div></div>    
</body>
</html>