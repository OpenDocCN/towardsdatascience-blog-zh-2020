<html>
<head>
<title>Mastering TensorFlow Tensors in 5 Easy Steps</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">通过5个简单的步骤掌握TensorFlow张量</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/mastering-tensorflow-tensors-in-5-easy-steps-35f21998bb86?source=collection_archive---------7-----------------------#2020-10-08">https://towardsdatascience.com/mastering-tensorflow-tensors-in-5-easy-steps-35f21998bb86?source=collection_archive---------7-----------------------#2020-10-08</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><h2 id="1206" class="ir is it bd b dl iu iv iw ix iy iz dk ja translated" aria-label="kicker paragraph"><a class="ae ep" rel="noopener" target="_blank" href="/beginners-guide-to-tensorflow-2-x-for-deep-learning-applications-c7ebd0dcfbee"> ← Part 1 </a> |深度学习用TensorFlow 2。X —第2部分| <a class="ae ep" rel="noopener" target="_blank" href="/mastering-tensorflow-variables-in-5-easy-step-5ba8062a1756">第3部分→ </a> | <a class="ae ep" rel="noopener" target="_blank" href="/eager-execution-vs-graph-execution-which-is-better-38162ea4dbf6">第4部分→ </a></h2><div class=""/><div class=""><h2 id="a9db" class="pw-subtitle-paragraph jz jc it bd b ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq dk translated">了解TensorFlow的构建模块如何在底层工作，并了解如何充分利用张量对象|使用TensorFlow 2.x进行深度学习</h2></div><p id="f83f" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如果你正在阅读这篇文章，我确信我们有着相似的兴趣，并且正在/将要从事相似的行业。那么我们就通过<a class="ae lo" href="https://linkedin.com/in/orhangaziyalcin/" rel="noopener ugc nofollow" target="_blank"><em class="ln">Linkedin</em></a><em class="ln">来连线吧！请不要犹豫发送联系请求！</em><a class="ae lo" href="https://linkedin.com/in/orhangaziyalcin/" rel="noopener ugc nofollow" target="_blank"><em class="ln">Orhan g . Yal n—Linkedin</em></a></p><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi lp"><img src="../Images/c3958d390b567be41e39bcaa48ec1312.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*8baaCUu0Tr275l2B"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">照片由<a class="ae lo" href="https://unsplash.com/@estherrj?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Esther Jiao </a>在<a class="ae lo" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄</p></figure><p id="cd87" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">在本帖中，我们将深入TensorFlow张量的细节。我们将通过这五个简单的步骤涵盖Tensorflow中与张量相关的所有主题:</p><ul class=""><li id="e91b" class="mf mg it kt b ku kv kx ky la mh le mi li mj lm mk ml mm mn bi translated"><strong class="kt jd">第一步:张量的定义→ </strong>什么是张量？</li><li id="2b0f" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm mk ml mm mn bi translated"><strong class="kt jd">步骤二:创建张量→ </strong>创建张量对象的函数</li><li id="0edd" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm mk ml mm mn bi translated"><strong class="kt jd">第三步:张量的资格→ </strong>张量对象的特性和特征</li><li id="a1e4" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm mk ml mm mn bi translated"><strong class="kt jd">步骤四:张量运算→ </strong>索引、基本张量运算、形状操作和广播</li><li id="114f" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm mk ml mm mn bi translated"><strong class="kt jd">第五步:特殊张量类型→ </strong>除常规张量以外的特殊张量类型</li></ul><p id="1182" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">开始吧！</p><h1 id="8792" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">张量的定义:什么是张量？</h1><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi nl"><img src="../Images/dbaa14b3733c129a99887ac5775b77ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*u8IDwY95zdEABtLscGqYYg.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图一。秩3张量的可视化(作者提供图片)</p></figure><p id="936c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">张量是TensorFlow的多维数组，类型统一。它们非常类似于NumPy数组，并且是不可变的，这意味着它们一旦创建就不能被更改。您只能使用编辑内容创建新副本。</p><p id="26bc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们看看张量如何与代码示例一起工作。但是首先，要使用TensorFlow对象，我们需要导入<a class="ae lo" href="http://tensorflow.org" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>库。我们经常在TensorFlow中使用<a class="ae lo" href="http://numpy.org" rel="noopener ugc nofollow" target="_blank"> NumPy </a>，所以我们也用下面几行来导入NumPy:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><h1 id="22e4" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">张量的创建:创建张量对象</h1><p id="16c4" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">有几种方法可以创建一个<code class="fe nt nu nv nw b">tf.Tensor</code>对象。先说几个例子。您可以使用几个张量流函数创建张量对象，如下例所示:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">tf.constant、tf.ones、tf.zeros和tf.range是一些可用于创建张量对象的函数</p></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="7df9" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:</strong><br/>tf.Tensor([[1 2 3 4 5]], shape=(1, 5), dtype=int32)<br/>tf.Tensor([[1. 1. 1. 1. 1.]], shape=(1, 5), dtype=float32) <br/>tf.Tensor([[0. 0. 0. 0. 0.]], shape=(1, 5), dtype=float32) <br/>tf.Tensor([1 2 3 4 5], shape=(5,), dtype=int32)</span></pre><p id="423b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如你所见，我们用三种不同的函数创建了形状为<code class="fe nt nu nv nw b">(1, 5)</code>的张量对象，并用<code class="fe nt nu nv nw b">tf.range()</code>函数创建了形状为<code class="fe nt nu nv nw b">(5, )</code>的第四个张量对象。注意，<code class="fe nt nu nv nw b">tf.ones</code>和<code class="fe nt nu nv nw b">tf.zeros</code>接受形状作为必需的参数，因为它们的元素值是预先确定的。</p><h1 id="2f85" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">张量的资格:张量对象的特性和特征</h1><p id="9e64" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">TensorFlow张量是作为<code class="fe nt nu nv nw b">tf.Tensor</code>对象创建的，它们有几个特征。首先，他们有一个基于维度数量的排名。其次，它们有一个形状，一个由所有维度的长度组成的列表。所有张量都有一个大小，即一个张量中元素的总数。最后，它们的元素都记录在统一的数据类型(data type)中。让我们仔细看看这些特性。</p><h2 id="91ee" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">等级系统和维度</h2><p id="3c6e" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">张量根据其维数进行分类:</p><ul class=""><li id="bfee" class="mf mg it kt b ku kv kx ky la mh le mi li mj lm mk ml mm mn bi translated"><strong class="kt jd"> Rank-0(标量)张量:</strong>包含单值且无轴的张量(0维)；</li><li id="2a1b" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm mk ml mm mn bi translated"><strong class="kt jd">秩-1张量:</strong>包含单轴(1维)值列表的张量；</li><li id="5a06" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm mk ml mm mn bi translated"><strong class="kt jd">秩-2张量:</strong>包含2轴(2维)的张量；和</li><li id="4707" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm mk ml mm mn bi translated"><strong class="kt jd">秩N张量:</strong>包含N轴(N维)的张量。</li></ul><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi oq"><img src="../Images/ad57fe194557ea288e14819e47060533.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W6s_CPw3y2K9S2cgYpLaBQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图二。秩1张量|秩2张量|秩3张量(图由作者提供)</p></figure><p id="84f6" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">例如，我们可以通过将一个三级嵌套列表对象传递给<code class="fe nt nu nv nw b">tf.constant</code>函数来创建一个秩为3的张量。对于本例，我们可以将数字拆分成一个三级嵌套列表，每级包含三个元素:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div><p class="mb mc gj gh gi md me bd b be z dk translated">创建秩3张量对象的代码</p></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="9153" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>tf.Tensor( [[[ 0  1  2]   <br/>             [ 3  4  5]]   <br/>             <br/>            [[ 6  7  8]   <br/>             [ 9 10 11]]],<br/>  shape=(2, 2, 3), dtype=int32)</span></pre><p id="b091" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以用`. ndim '属性查看我们的` rank_3_tensor '对象当前拥有的维数。</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="9613" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>The number of dimensions in our Tensor object is 3</span></pre><h2 id="dbc8" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">形状</h2><p id="46c5" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">形状特征是每个张量都有的另一个属性。它以列表的形式显示每个维度的大小。我们可以查看用<code class="fe nt nu nv nw b">.shape</code>属性创建的<code class="fe nt nu nv nw b">rank_3_tensor</code>对象的形状，如下所示:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="6d49" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>The shape of our Tensor object is (2, 2, 3)</span></pre><p id="02ce" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">如你所见，我们的张量在第一层有2个元素，在第二层有2个元素，在第三层有3个元素。</p><h2 id="10ae" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">大小</h2><p id="742c" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">大小是张量的另一个特征，它意味着张量的元素总数。我们不能用张量对象的一个属性来度量大小。相反，我们需要使用<code class="fe nt nu nv nw b">tf.size()</code>函数。最后，我们将使用实例函数<code class="fe nt nu nv nw b">.numpy() </code>将输出转换为NumPy，以获得可读性更好的结果:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="733a" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>The size of our Tensor object is 12</span></pre><h2 id="cc5d" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">数据类型</h2><p id="cf83" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">张量通常包含数字数据类型，如floats和ints，但也可能包含许多其他数据类型，如复数和字符串。</p><p id="eb5a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">然而，每个张量对象必须以单一的统一数据类型存储其所有元素。因此，我们也可以使用<code class="fe nt nu nv nw b">.dtype</code>属性查看为特定张量对象选择的数据类型，如下所示:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="2900" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>The data type selected for this Tensor object is &lt;dtype: 'int32'&gt;</span></pre><h1 id="9010" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">张量运算</h1><h2 id="86ea" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">索引</h2><p id="cac0" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">索引是项目在序列中位置的数字表示。这个序列可以引用很多东西:一个列表、一个字符串或者任意的值序列。</p><p id="7d91" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">TensorFlow也遵循标准的Python索引规则，类似于列表索引或NumPy数组索引。</p><p id="cb6b" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">关于索引的一些规则:</p><ol class=""><li id="1676" class="mf mg it kt b ku kv kx ky la mh le mi li mj lm or ml mm mn bi translated">索引从零(0)开始。</li><li id="7666" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">负索引("-n ")值表示从末尾向后计数。</li><li id="c746" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">冒号(":")用于切片:<code class="fe nt nu nv nw b">start:stop:step</code>。</li><li id="1aaa" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">逗号(“，”)用于到达更深的层次。</li></ol><p id="8746" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们用下面的代码行创建一个<code class="fe nt nu nv nw b">rank_1_tensor</code>:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="5e89" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:</strong> <br/>tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11], <br/>  shape=(12,), dtype=int32)</span></pre><p id="ed7c" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">测试我们的第一、第二和第三条规则:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="15e5" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:</strong> <br/>First element is: 0 <br/>Last element is: 11 <br/>Elements in between the 1st and the last are: [ 1  2  3  4  5  6  7  8  9 10]</span></pre><p id="828d" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，让我们用下面的代码创建我们的<code class="fe nt nu nv nw b">rank_2_tensor</code>对象:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="682b" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>tf.Tensor( [[ 0  1  2  3  4  5]  <br/>            [ 6  7  8  9 10 11]], shape=(2, 6), dtype=int32)</span></pre><p id="d920" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">用几个例子来测试第四条规则:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="5ebb" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:</strong> <br/>The first element of the first level is: [0 1 2 3 4 5] <br/>The second element of the first level is: [ 6  7  8  9 10 11] <br/>The first element of the second level is: 0 <br/>The third element of the second level is: 2</span></pre><p id="c304" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">现在，我们已经介绍了索引的基础知识，所以让我们来看看可以在张量上进行的基本操作。</p><h2 id="c141" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">张量的基本运算</h2><p id="c05b" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">您可以轻松地对张量进行基本的数学运算，例如:</p><ol class=""><li id="9fd7" class="mf mg it kt b ku kv kx ky la mh le mi li mj lm or ml mm mn bi translated">添加</li><li id="6514" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">逐元素乘法</li><li id="2a6a" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">矩阵乘法</li><li id="2efa" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">寻找最大值或最小值</li><li id="b0ec" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">寻找Max元素的索引</li><li id="3b68" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">计算Softmax值</li></ol><p id="d8db" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们来看看这些操作的运行情况。我们将创建两个张量对象并应用这些操作。</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="7dec" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们可以从加法开始。</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="befa" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>tf.Tensor( [[ 3.  7.]  <br/>            [11. 15.]], shape=(2, 2), dtype=float32)</span></pre><p id="6769" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们继续逐元素乘法。</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="b265" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>tf.Tensor( [[ 2. 12.]  <br/>            [30. 56.]], shape=(2, 2), dtype=float32)</span></pre><p id="0217" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">我们也可以做矩阵乘法:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="c740" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>tf.Tensor( [[22. 34.]  <br/>            [46. 74.]], shape=(2, 2), dtype=float32)</span></pre><blockquote class="os"><p id="8f12" class="ot ou it bd ov ow ox oy oz pa pb lm dk translated"><strong class="ak">注:</strong> Matmul运算奠定了深度学习算法的核心。因此，尽管您不会直接使用matmul，但了解这些操作是至关重要的。</p></blockquote><p id="9fbe" class="pw-post-body-paragraph kr ks it kt b ku pc kd kw kx pd kg kz la pe lc ld le pf lg lh li pg lk ll lm im bi translated">我们上面列出的其他操作的例子:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="f640" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:</strong><br/>The Max value of the tensor object b is: 7.0 <br/>The index position of the Max of the tensor object b is: [1 1] <br/>The softmax computation result of the tensor object b is: [[0.11920291 0.880797  ]  [0.11920291 0.880797  ]]</span></pre><h2 id="957a" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">操纵形状</h2><p id="848a" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">就像在NumPy数组和pandas数据帧中一样，你也可以改变张量对象的形状。</p><p id="9f31" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">tf.reshape操作非常快，因为不需要复制底层数据。对于整形操作，我们可以使用<code class="fe nt nu nv nw b">tf.reshape()</code>功能。让我们在代码中使用<code class="fe nt nu nv nw b">tf.reshape</code>函数:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="df5a" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>The shape of our initial Tensor object is: (1, 6) <br/>The shape of our initial Tensor object is: (6, 1) <br/>The shape of our initial Tensor object is: (3, 2) <br/>The shape of our flattened Tensor object is: tf.Tensor([1 2 3 4 5 6], shape=(6,), dtype=int32)</span></pre><p id="f6b4" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">正如你所看到的，我们可以很容易地重塑我们的张量对象。但是要注意，在做重塑操作的时候，一个开发者一定要讲道理。否则，张量可能会混淆，甚至会产生错误。所以，小心点😀。</p><h2 id="aa39" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">广播</h2><p id="7212" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">当我们尝试使用多个张量对象进行组合运算时，较小的张量可以自动伸展以适应较大的张量，就像NumPy数组一样。例如，当您试图将一个标量张量与一个秩为2的张量相乘时，该标量被拉伸以乘以每个秩为2的张量元素。请参见下面的示例:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="91d8" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>tf.Tensor( [[ 5 10]  <br/>            [15 20]], shape=(2, 2), dtype=int32)</span></pre><p id="6e9a" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">多亏了广播，在张量上做数学运算的时候不用担心大小匹配的问题。</p><h1 id="db4b" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">特殊类型的张量</h1><p id="4c08" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">我们倾向于生成矩形的张量，并将数值存储为元素。但是，TensorFlow也支持不规则或特殊的张量类型，它们是:</p><ol class=""><li id="ba60" class="mf mg it kt b ku kv kx ky la mh le mi li mj lm or ml mm mn bi translated">参差张量</li><li id="04c0" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">弦张量</li><li id="74f9" class="mf mg it kt b ku mo kx mp la mq le mr li ms lm or ml mm mn bi translated">稀疏张量</li></ol><figure class="lq lr ls lt gt lu gh gi paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="gh gi ph"><img src="../Images/d5e8ea7d1fb858c2303199e890746495.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4bthotX6DLZOrhh99ftDGQ.png"/></div></div><p class="mb mc gj gh gi md me bd b be z dk translated">图3。参差张量|弦张量|稀疏张量(作者提供图片)</p></figure><p id="76aa" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">让我们仔细看看它们分别是什么。</p><h2 id="b358" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">参差张量</h2><p id="0843" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">不规则张量是沿着尺寸轴具有不同数量元素的张量，如图x所示。</p><p id="2a24" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">您可以构建一个不规则张量，如下所示:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="7b0f" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:<br/></strong>&lt;tf.RaggedTensor [[1, 2, 3], <br/>                  [4, 5], <br/>                  [6]]&gt;</span></pre><h2 id="6c4f" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">弦张量</h2><p id="1f69" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">字符串张量就是张量，存储字符串对象。我们可以创建一个弦张量，就像你创建一个常规的张量对象一样。但是，我们将字符串对象作为元素传递，而不是数字对象，如下所示:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="b58f" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:</strong><br/>tf.Tensor([b'With this' <br/>           b'code, I am' <br/>           b'creating a String Tensor'],<br/>  shape=(3,), dtype=string)</span></pre><h2 id="100a" class="ob mu it bd mv og oh dn mz oi oj dp nd la ok ol nf le om on nh li oo op nj iz bi translated">稀疏张量</h2><p id="134a" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">最后，稀疏张量是针对稀疏数据的矩形张量。当数据中有空洞(即空值)时，稀疏张量就是要处理的对象。创建稀疏张量有点耗时，应该更主流。但是，这里有一个例子:</p><figure class="lq lr ls lt gt lu"><div class="bz fp l di"><div class="nm nn l"/></div></figure><pre class="lq lr ls lt gt nx nw ny nz aw oa bi"><span id="588f" class="ob mu it nw b gy oc od l oe of"><strong class="nw jd">Output:</strong><br/>tf.Tensor( [[ 25   0   0   0   0]<br/>            [  0   0   0   0   0]<br/>            [  0   0  50   0   0]<br/>            [  0   0   0   0   0]<br/>            [  0   0   0   0 100]], shape=(5, 5), dtype=int32)</span></pre><h1 id="f8ea" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">恭喜</h1><p id="9944" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">我们已经成功地介绍了张量流张量对象的基础知识。</p><blockquote class="pi pj pk"><p id="442d" class="kr ks ln kt b ku kv kd kw kx ky kg kz pl lb lc ld pm lf lg lh pn lj lk ll lm im bi translated">给自己一个鼓励！</p></blockquote><p id="e5ea" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">这应该会给你很大的信心，因为你现在对TensorFlow框架的构建模块有了更多的了解。</p><p id="9f30" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">查看本教程系列的第1部分:</p><div class="po pp gp gr pq pr"><a href="https://link.medium.com/yJp16uPoqab" rel="noopener follow" target="_blank"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">深度学习应用TensorFlow 2.x初学者指南</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">了解TensorFlow平台以及它能为机器学习专家提供什么</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">link.medium.com</p></div></div><div class="qa l"><div class="qb l qc qd qe qa qf lz pr"/></div></div></a></div><p id="6dbc" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">继续<a class="ae lo" rel="noopener" target="_blank" href="/mastering-tensorflow-variables-in-5-easy-step-5ba8062a1756">系列的第三部分</a>:</p><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/mastering-tensorflow-variables-in-5-easy-step-5ba8062a1756"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">用5个简单的步骤掌握TensorFlow“变量”</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">了解如何使用张量流变量，它们与普通张量对象的区别，以及它们何时优于…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qg l qc qd qe qa qf lz pr"/></div></div></a></div><h1 id="ec08" class="mt mu it bd mv mw mx my mz na nb nc nd ki ne kj nf kl ng km nh ko ni kp nj nk bi translated">订阅邮件列表获取完整代码</h1><p id="3115" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">如果你想获得Google Colab的全部代码和我的其他最新内容，可以考虑订阅邮件列表:</p><blockquote class="os"><p id="85c4" class="ot ou it bd ov ow qh qi qj qk ql lm dk translated"><a class="ae lo" href="http://eepurl.com/hd6Xfv" rel="noopener ugc nofollow" target="_blank">立即订阅</a></p></blockquote><h1 id="45c4" class="mt mu it bd mv mw mx my mz na nb nc nd ki qm kj nf kl qn km nh ko qo kp nj nk bi translated">喜欢这篇文章吗？</h1><p id="75cc" class="pw-post-body-paragraph kr ks it kt b ku no kd kw kx np kg kz la nq lc ld le nr lg lh li ns lk ll lm im bi translated">如果你喜欢这篇文章，可以考虑看看我的其他类似文章:</p><p id="91de" class="pw-post-body-paragraph kr ks it kt b ku kv kd kw kx ky kg kz la lb lc ld le lf lg lh li lj lk ll lm im bi translated">最后，如果你对应用深度学习教程感兴趣，可以看看我的一些文章:</p><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">使用MNIST数据集在10分钟内完成图像分类</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">利用TensorFlow和Keras |监督深度学习使用卷积神经网络来分类手写数字</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qp l qc qd qe qa qf lz pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/image-generation-in-10-minutes-with-generative-adversarial-networks-c2afc56bfa3b"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">利用生成性对抗网络在10分钟内生成图像</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">使用无监督深度学习生成手写数字与深度卷积甘斯使用张量流和…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qq l qc qd qe qa qf lz pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/image-noise-reduction-in-10-minutes-with-convolutional-autoencoders-d16219d2956a"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">使用卷积自动编码器在10分钟内降低图像噪声</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">在时尚MNIST的帮助下，使用深度卷积自动编码器清洁(或去噪)有噪声的图像</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.com</p></div></div><div class="qa l"><div class="qr l qc qd qe qa qf lz pr"/></div></div></a></div><div class="po pp gp gr pq pr"><a rel="noopener follow" target="_blank" href="/using-recurrent-neural-networks-to-predict-bitcoin-btc-prices-c4ff70f9f3e4"><div class="ps ab fo"><div class="pt ab pu cl cj pv"><h2 class="bd jd gy z fp pw fr fs px fu fw jc bi translated">使用递归神经网络预测比特币(BTC)价格</h2><div class="py l"><h3 class="bd b gy z fp pw fr fs px fu fw dk translated">如果你能以某种方式预测明天的比特币(BTC)价格，这不是很棒吗？加密货币市场有…</h3></div><div class="pz l"><p class="bd b dl z fp pw fr fs px fu fw dk translated">towardsdatascience.comm</p></div></div><div class="qa l"><div class="qs l qc qd qe qa qf lz pr"/></div></div></a></div></div></div>    
</body>
</html>