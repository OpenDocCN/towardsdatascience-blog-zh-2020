<html>
<head>
<title>Anomaly Detection in Time Series Sensor Data</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">时间序列传感器数据中的异常检测</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/anomaly-detection-in-time-series-sensor-data-86fd52e62538?source=collection_archive---------0-----------------------#2020-09-26">https://towardsdatascience.com/anomaly-detection-in-time-series-sensor-data-86fd52e62538?source=collection_archive---------0-----------------------#2020-09-26</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><figure class="ip iq gp gr ir is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi io"><img src="../Images/3221a4d32c51f6a5d9c762eb0389845c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*ILUJj0eMAFtrSblq"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">威尔·梅尔斯在<a class="ae jd" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍照</p></figure><div class=""/><blockquote class="kd ke kf"><p id="02f9" class="kg kh ki kj b kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le ij bi translated">异常检测包括识别数据集中与标准的差异、偏差和异常。它有时被称为离群点检测。</p></blockquote></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><p id="9c74" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">异常检测不是一个新概念或新技术，它已经存在很多年了，是机器学习的一个常见应用。其使用案例的真实示例包括(但不限于)检测欺诈交易、欺诈性保险索赔、检测异常设备行为的网络攻击。</p><p id="8495" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">在本文中，我将重点介绍异常检测在制造业中的应用，我认为与其他行业相比，制造业在有效利用机器学习技术方面远远落后。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="eff4" class="lp lq jg bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">问题描述</h1><p id="270c" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">制造业被认为是重工业，其中他们倾向于使用各种类型的重型机械，如巨型电机、泵、管道、熔炉、传送带、拖运卡车、推土机、平地机和电铲等。这些通常被认为是他们运营中最重要的资产。因此，这些设备的完整性和可靠性通常是其资产管理计划的核心焦点。</p><p id="df0d" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">他们如此关注这些资产的主要原因是，这些设备的故障通常会导致生产损失，从而导致数十万美元(如果不是数百万美元的话)的损失，这取决于运营的大小和规模。因此，对于制造工厂的维护经理来说，这是一件非常重要的事情，他们需要与高技能的可靠性工程师一起运行一个强大的资产管理框架，以确保这些关键资产的可靠性和可用性。</p><p id="3a92" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">因此，提前检测异常情况并降低风险的能力是一项非常有价值的能力，可进一步防止计划外停机、不必要的维护(基于条件的维护与强制维护),还能更有效地管理这些资产的关键部件。计划外停机造成的生产损失、不必要的维护成本以及关键部件的过剩或短缺都会转化为严重的经济损失。</p><p id="5815" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">在这篇文章中，我将使用Scikit-learn(又名sklearn)在Python中实现不同的异常检测技术，我们的目标是使用无监督学习算法在泵的时间序列传感器读数中搜索异常。我们开始吧！</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="00ee" class="lp lq jg bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">数据</h1><p id="1c62" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">很难从制造业中找到这种特定用例的公开数据，但我能够找到一个不完美的数据。数据集包含来自安装在泵上的53个传感器的传感器读数，以测量泵的各种行为。这个数据集可以在<a class="ae jd" href="https://www.kaggle.com/nphantawee/pump-sensor-data" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="da10" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">首先，我将使用以下代码和Kaggle API下载数据</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="cd23" class="nb lq jg mx b gy nc nd l ne nf">!kaggle datasets download -d nphantawee/pump-sensor-data</span></pre><p id="adf7" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">下载完成后，用下面的代码将CSV文件读入pandas数据帧，并检查数据的细节。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7cdf" class="nb lq jg mx b gy nc nd l ne nf">df = pd.read_csv('sensor.csv')<br/>df.info()</span><span id="f650" class="nb lq jg mx b gy ng nd l ne nf">&lt;class 'pandas.core.frame.DataFrame'&gt;<br/>RangeIndex: 220320 entries, 0 to 220319<br/>Data columns (total 55 columns):<br/> #   Column          Non-Null Count   Dtype  <br/>---  ------          --------------   -----  <br/> 0   Unnamed: 0      220320 non-null  int64  <br/> 1   timestamp       220320 non-null  object <br/> 2   sensor_00       210112 non-null  float64<br/> 3   sensor_01       219951 non-null  float64<br/> 4   sensor_02       220301 non-null  float64<br/> 5   sensor_03       220301 non-null  float64<br/> 6   sensor_04       220301 non-null  float64<br/> 7   sensor_05       220301 non-null  float64<br/> 8   sensor_06       215522 non-null  float64<br/> 9   sensor_07       214869 non-null  float64<br/> 10  sensor_08       215213 non-null  float64<br/> 11  sensor_09       215725 non-null  float64<br/> 12  sensor_10       220301 non-null  float64<br/> 13  sensor_11       220301 non-null  float64<br/> 14  sensor_12       220301 non-null  float64<br/> 15  sensor_13       220301 non-null  float64<br/> 16  sensor_14       220299 non-null  float64<br/> 17  sensor_15       0 non-null       float64<br/> 18  sensor_16       220289 non-null  float64<br/> 19  sensor_17       220274 non-null  float64<br/> 20  sensor_18       220274 non-null  float64<br/> 21  sensor_19       220304 non-null  float64<br/> 22  sensor_20       220304 non-null  float64<br/> 23  sensor_21       220304 non-null  float64<br/> 24  sensor_22       220279 non-null  float64<br/> 25  sensor_23       220304 non-null  float64<br/> 26  sensor_24       220304 non-null  float64<br/> 27  sensor_25       220284 non-null  float64<br/> 28  sensor_26       220300 non-null  float64<br/> 29  sensor_27       220304 non-null  float64<br/> 30  sensor_28       220304 non-null  float64<br/> 31  sensor_29       220248 non-null  float64<br/> 32  sensor_30       220059 non-null  float64<br/> 33  sensor_31       220304 non-null  float64<br/> 34  sensor_32       220252 non-null  float64<br/> 35  sensor_33       220304 non-null  float64<br/> 36  sensor_34       220304 non-null  float64<br/> 37  sensor_35       220304 non-null  float64<br/> 38  sensor_36       220304 non-null  float64<br/> 39  sensor_37       220304 non-null  float64<br/> 40  sensor_38       220293 non-null  float64<br/> 41  sensor_39       220293 non-null  float64<br/> 42  sensor_40       220293 non-null  float64<br/> 43  sensor_41       220293 non-null  float64<br/> 44  sensor_42       220293 non-null  float64<br/> 45  sensor_43       220293 non-null  float64<br/> 46  sensor_44       220293 non-null  float64<br/> 47  sensor_45       220293 non-null  float64<br/> 48  sensor_46       220293 non-null  float64<br/> 49  sensor_47       220293 non-null  float64<br/> 50  sensor_48       220293 non-null  float64<br/> 51  sensor_49       220293 non-null  float64<br/> 52  sensor_50       143303 non-null  float64<br/> 53  sensor_51       204937 non-null  float64<br/> 54  machine_status  220320 non-null  object <br/>dtypes: float64(52), int64(1), object(2)<br/>memory usage: 92.5+ MB</span></pre><p id="b17e" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">我们已经可以看到，数据需要一些清理，有丢失的值，一个空列和一个数据类型不正确的时间戳。因此，我将应用以下步骤来整理数据集。</p><ul class=""><li id="f424" class="nh ni jg kj b kk kl ko kp lm nj ln nk lo nl le nm nn no np bi translated">移除多余的列</li><li id="0665" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated">删除重复项</li><li id="0592" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated">处理缺失值</li><li id="e986" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated">将数据类型转换为正确的数据类型</li></ul><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d557" class="nb lq jg mx b gy nc nd l ne nf"># Drop duplicates<br/>df = df.drop_duplicates()<br/># Entire "sensor_15" column is NaN therefore remove it from data<br/>del df['sensor_15']<br/># Let's convert the data type of timestamp column to datatime format<br/>import warnings<br/>warnings.filterwarnings("ignore")<br/>df_tidy['date'] = pd.to_datetime(df_tidy['timestamp'])<br/>del df_tidy['timestamp']</span></pre><p id="901c" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">接下来，让我们处理缺失值，为此，我们首先查看缺失值的列，并查看缺失数据的百分比。为此，我将编写一个计算缺失值百分比的函数，这样我就可以在整个笔记本中多次使用同一个函数。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="7412" class="nb lq jg mx b gy nc nd l ne nf"># Function that calculates the percentage of missing values<br/>def calc_percent_NAs(df):<br/>    nans = pd.DataFrame(df.isnull().sum().sort_values(ascending=False)/len(df), columns=['percent']) <br/>    idx = nans['percent'] &gt; 0<br/>    return nans[idx]</span><span id="5365" class="nb lq jg mx b gy ng nd l ne nf"># Let's use above function to look at top ten columns with NaNs<br/>calc_percent_NAs(df).head(10)</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/655f606cdce449f1204ccc7f2831fdd2.png" data-original-src="https://miro.medium.com/v2/resize:fit:320/format:webp/1*i9kHKsM6CYnce5e-bnFECQ.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">每列缺失值的百分比</p></figure><p id="aa08" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">经过一些分析后，我决定用它们的平均值来估算一些缺失的值，并去掉其余的。在数据争论过程之后，我最终整理的数据如下所示，并为下一步探索性数据分析做好了准备。tidy数据集有52个传感器，机器状态列包含三个类别(正常、损坏、恢复),分别代表泵的正常运行、损坏和恢复状态，然后是日期时间列，代表时间戳。</p><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nw"><img src="../Images/a7dd80000c59dc6c4f6bc4fc49a9da15.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DVMdxtamLsPSi128Aqg30Q.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">整齐数据的前10行</p></figure></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="cd51" class="lp lq jg bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">探索性数据分析</h1><p id="a5bb" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">既然我们已经清理了数据，我们可以开始探索以熟悉数据集。</p><p id="fb24" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">在一些定量EDA之上，我执行了额外的图形EDA来寻找趋势和任何奇怪的行为。特别是，有趣的是看到传感器读数随着时间的变化而变化，机器状态“损坏”用红色标记在同一图表上。这样，我们可以清楚地看到泵何时出现故障，以及这如何反映在传感器读数中。下面的代码为每个传感器绘制了上面提到的图表，但是让我们看看sensor_00的图表。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="01e4" class="nb lq jg mx b gy nc nd l ne nf"># Extract the readings from the BROKEN state of the pump<br/>broken = df[df['machine_status']=='BROKEN']<br/># Extract the names of the numerical columns<br/>df2 = df.drop(['machine_status'], axis=1)<br/>names=df2.columns<br/># Plot time series for each sensor with BROKEN state marked with X in red color<br/>for name in names:<br/>    _ = plt.figure(figsize=(18,3))<br/>    _ = plt.plot(broken[name], linestyle='none', marker='X', color='red', markersize=12)<br/>    _ = plt.plot(df[name], color='blue')<br/>    _ = plt.title(name)<br/>    plt.show()</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi nx"><img src="../Images/a2b8a495f7a6469658a556c03dcccb3d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Wglro6pDH3g2vfVmCojWGw.png"/></div></div></figure><p id="e6c9" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">从上面的图中可以清楚地看到，代表泵损坏状态的红色标记与传感器读数的观察到的干扰完全重叠。现在我们有了一个很好的直觉，当泵坏了和正常运行时，每个传感器读数是如何表现的。</p><h1 id="fae6" class="lp lq jg bd lr ls ny lu lv lw nz ly lz ma oa mc md me ob mg mh mi oc mk ml mm bi translated">平稳性和自相关性</h1><p id="eee0" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">在时间序列分析中，重要的是数据是平稳的，没有自相关。平稳性是指数据的平均值和标准偏差随时间变化的行为，具有这种行为的数据被认为是不平稳的。另一方面，自相关是指数据在不同时间段内与其自身相关的数据行为。下一步，我将直观地检查数据集中每个特征的稳定性，下面的代码将完成这一任务。稍后，我们还将执行Dickey Fuller测试来定量验证观察到的平稳性。此外，在将特征输入聚类算法以检测异常之前，我们将检查特征的自相关性。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="d129" class="nb lq jg mx b gy nc nd l ne nf"># Resample the entire dataset by daily average<br/>rollmean = df.resample(rule='D').mean()<br/>rollstd = df.resample(rule='D').std()<br/># Plot time series for each sensor with its mean and standard deviation<br/>for name in names:<br/>    _ = plt.figure(figsize=(18,3))<br/>    _ = plt.plot(df[name], color='blue', label='Original')<br/>    _ = plt.plot(rollmean[name], color='red', label='Rolling Mean')<br/>    _ = plt.plot(rollstd[name], color='black', label='Rolling Std' )<br/>    _ = plt.legend(loc='best')<br/>    _ = plt.title(name)<br/>    plt.show()</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi od"><img src="../Images/12b7ed604a9acd734b242885f21df65a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SrzE3SSFExkenH3aqhUZug.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">时间序列看起来相当稳定</p></figure><p id="bac6" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">查看其中一个传感器(在本例中为sensor_17)的读数，注意数据实际上看起来非常稳定，滚动平均值和标准偏差似乎不随时间变化，除非在预期的泵停机期间。该数据集中的大多数传感器都是这种情况，但在训练数据之前必须应用各种变换方法来使数据稳定的情况下，情况可能并不总是如此。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="23d2" class="lp lq jg bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">预处理和降维</h1><p id="c617" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">用所有52个传感器/特征来训练模型在计算上非常昂贵，并且效率不高。因此，我将采用主成分分析(PCA)技术来提取用于建模的新特征。为了正确应用PCA，必须对数据进行缩放和标准化。这是因为PCA和大多数学习算法都是基于距离的算法。如果从整洁数据的前10行注意到，每个特征的值的大小是不一致的。有些值非常小，而有些值非常大。我将使用管道库执行以下步骤。</p><ol class=""><li id="f292" class="nh ni jg kj b kk kl ko kp lm nj ln nk lo nl le oe nn no np bi translated">缩放数据</li><li id="880f" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">执行主成分分析，并根据惯性查看最重要的主成分</li></ol><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="40a9" class="nb lq jg mx b gy nc nd l ne nf"># Standardize/scale the dataset and apply PCA<br/>from sklearn.preprocessing import StandardScaler<br/>from sklearn.decomposition import PCA<br/>from sklearn.pipeline import make_pipeline<br/># Extract the names of the numerical columns<br/>df2 = df.drop(['machine_status'], axis=1)<br/>names=df2.columns<br/>x = df[names]<br/>scaler = StandardScaler()<br/>pca = PCA()<br/>pipeline = make_pipeline(scaler, pca)<br/>pipeline.fit(x)</span><span id="aa33" class="nb lq jg mx b gy ng nd l ne nf"># Plot the principal components against their inertia</span><span id="8db6" class="nb lq jg mx b gy ng nd l ne nf">features = range(pca.n_components_)<br/>_ = plt.figure(figsize=(15, 5))<br/>_ = plt.bar(features, pca.explained_variance_)<br/>_ = plt.xlabel('PCA feature')<br/>_ = plt.ylabel('Variance')<br/>_ = plt.xticks(features)<br/>_ = plt.title("Importance of the Principal Components based on inertia")<br/>plt.show()</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi of"><img src="../Images/9897260f8ac45a3334bf7cc8403a941f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AvAWvDTtuQ5Fc8kEkj-EYw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">根据图表，前两个组件是最重要的</p></figure><p id="41bc" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">根据上述重要性图中PCA提取的特征，似乎前两个主成分是最重要的。因此，作为下一步，我将使用2个组件执行PCA，这将是我在模型训练中使用的特征。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="3c2c" class="nb lq jg mx b gy nc nd l ne nf"># Calculate PCA with 2 components<br/>pca = PCA(n_components=2)<br/>principalComponents = pca.fit_transform(x)<br/>principalDf = pd.DataFrame(data = principalComponents, columns = ['pc1', 'pc2'])</span></pre><p id="cfb0" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">现在，我将再次检查这两个主成分的平稳性和自相关性，以确保它们是平稳的，不是自相关的。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="fbb3" class="nb lq jg mx b gy nc nd l ne nf">from statsmodels.tsa.stattools import adfuller<br/># Run Augmented Dickey Fuller Test<br/>result = adfuller(principalDf['pc1'])<br/># Print p-value<br/>print(result[1])</span></pre><p id="2545" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">对第一个主成分运行Dickey Fuller测试，我得到的p值为5.4536849418486247e-05，这是一个非常小的数字(远小于0.05)。因此，我会拒绝零假设，说数据是平稳的。我对第二个组件执行了同样的操作，得到了类似的结果。所以两个主成分都是静止的，这就是我想要的。</p><p id="10cf" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">现在，让我们检查这两个主成分的自相关性。有两种方法可以做到:使用pandas autocorr()方法或ACF绘图。在这种情况下，我将使用后者来快速直观地验证没有自相关。下面的代码就是这样做的。</p><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="f7d6" class="nb lq jg mx b gy nc nd l ne nf"># Plot ACF<br/>from statsmodels.graphics.tsaplots import plot_acf<br/>plot_acf(pca1.dropna(), lags=20, alpha=0.05)</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi og"><img src="../Images/9c99f7b6111b5b3a3416493a3af6da6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:674/format:webp/1*rLmtB7PDvR6gbb7Zr8x-eA.png"/></div></div></figure><p id="dec9" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">假设我的PCA的新特征是稳定的，并且不是自相关的，我已经准备好建模了。</p></div><div class="ab cl lf lg hu lh" role="separator"><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk ll"/><span class="li bw bk lj lk"/></div><div class="ij ik il im in"><h1 id="4808" class="lp lq jg bd lr ls lt lu lv lw lx ly lz ma mb mc md me mf mg mh mi mj mk ml mm bi translated">建模</h1><p id="3337" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">在这一步中，我将执行以下学习算法来检测异常。</p><ol class=""><li id="317c" class="nh ni jg kj b kk kl ko kp lm nj ln nk lo nl le oe nn no np bi translated">基准模型:四分位距(IQR)</li><li id="4168" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">k均值聚类</li><li id="09e6" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">隔离森林</li></ol><p id="1642" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">让我们开始用这些算法进行训练。</p><h2 id="ce3b" class="nb lq jg bd lr oh oi dn lv oj ok dp lz lm ol om md ln on oo mh lo op oq ml or bi translated">四分位间距</h2><p id="3fdc" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">策略:</p><ol class=""><li id="bc6d" class="nh ni jg kj b kk kl ko kp lm nj ln nk lo nl le oe nn no np bi translated">计算IQR，即第75(Q3)和第25th)百分位数之间的差值。</li><li id="febe" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">计算异常值的上限和下限。</li><li id="ce9f" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">过滤超出上限和下限的数据点，并将其标记为异常值。</li><li id="f7b8" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">最后，在时间序列数据(本例中是sensor_11的读数)的顶部绘制异常值</li></ol><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="a120" class="nb lq jg mx b gy nc nd l ne nf"># Calculate IQR for the 1st principal component (pc1)</span><span id="aa4e" class="nb lq jg mx b gy ng nd l ne nf">q1_pc1, q3_pc1 = df['pc1'].quantile([0.25, 0.75])<br/>iqr_pc1 = q3_pc1 - q1_pc1</span><span id="7003" class="nb lq jg mx b gy ng nd l ne nf"># Calculate upper and lower bounds for outlier for pc1</span><span id="f0ae" class="nb lq jg mx b gy ng nd l ne nf">lower_pc1 = q1_pc1 - (1.5*iqr_pc1)<br/>upper_pc1 = q3_pc1 + (1.5*iqr_pc1)</span><span id="1f4c" class="nb lq jg mx b gy ng nd l ne nf"># Filter out the outliers from the pc1</span><span id="aa48" class="nb lq jg mx b gy ng nd l ne nf">df['anomaly_pc1'] = ((df['pc1']&gt;upper_pc1) | (df['pc1']&lt;lower_pc1)).astype('int')</span><span id="4898" class="nb lq jg mx b gy ng nd l ne nf"># Calculate IQR for the 2nd principal component (pc2)<br/>q1_pc2, q3_pc2 = df['pc2'].quantile([0.25, 0.75])<br/>iqr_pc2 = q3_pc2 - q1_pc2</span><span id="a946" class="nb lq jg mx b gy ng nd l ne nf"># Calculate upper and lower bounds for outlier for pc2</span><span id="486f" class="nb lq jg mx b gy ng nd l ne nf">lower_pc2 = q1_pc2 - (1.5*iqr_pc2)<br/>upper_pc2 = q3_pc2 + (1.5*iqr_pc2)</span><span id="40ea" class="nb lq jg mx b gy ng nd l ne nf"># Filter out the outliers from the pc2</span><span id="130f" class="nb lq jg mx b gy ng nd l ne nf">df['anomaly_pc2'] = ((df['pc2']&gt;upper_pc2) | (df['pc2']&lt;lower_pc2)).astype('int')</span><span id="39c8" class="nb lq jg mx b gy ng nd l ne nf"># Let's plot the outliers from pc1 on top of the sensor_11 and see where they occured in the time series</span><span id="7a42" class="nb lq jg mx b gy ng nd l ne nf">a = df[df['anomaly_pc1'] == 1] #anomaly<br/>_ = plt.figure(figsize=(18,6))<br/>_ = plt.plot(df['sensor_11'], color='blue', label='Normal')<br/>_ = plt.plot(a['sensor_11'], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')<br/>_ = plt.xlabel('Date and Time')<br/>_ = plt.ylabel('Sensor Reading')<br/>_ = plt.title('Sensor_11 Anomalies')<br/>_ = plt.legend(loc='best')<br/>plt.show();</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi os"><img src="../Images/0e75273d7b69f76fae712ee1d68be537.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DRSsylpWYp-oJqYbs5jCow.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">用红色标记的异常</p></figure><p id="1118" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">如上所述，异常是在泵发生故障之前检测到的。对于操作员来说，这可能是一个非常有价值的信息，可以在泵实际停止工作之前正确地关闭泵。让我们看看是否能从接下来的两个算法中检测到相似的异常模式。</p><h2 id="b202" class="nb lq jg bd lr oh oi dn lv oj ok dp lz lm ol om md ln on oo mh lo op oq ml or bi translated">k均值聚类</h2><p id="66c1" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">策略:</p><ol class=""><li id="47cc" class="nh ni jg kj b kk kl ko kp lm nj ln nk lo nl le oe nn no np bi translated">计算每个点与其最近质心之间的距离。最大的距离被认为是异常。</li><li id="03c8" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">我们使用outliers_fraction为算法提供关于数据集中离群值比例的信息。不同数据集的情况可能有所不同。然而，作为一个开始的数字，我估计outliers_fraction=0.13 (13%的df是outliers，如图所示)。</li><li id="6f42" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">使用离群值分数计算离群值的数量。</li><li id="a2c6" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">将阈值设置为这些异常值的最小距离。</li><li id="7e88" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">anomaly1的异常结果包含上述方法簇(0:正常，1:异常)。</li><li id="7718" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">用时序视图可视化异常。</li></ol><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="8e4b" class="nb lq jg mx b gy nc nd l ne nf"># Import necessary libraries<br/>from sklearn.cluster import KMeans<br/># I will start k-means clustering with k=2 as I already know that there are 3 classes of "NORMAL" vs <br/># "NOT NORMAL" which are combination of BROKEN" and"RECOVERING"</span><span id="4dd7" class="nb lq jg mx b gy ng nd l ne nf">kmeans = KMeans(n_clusters=2, random_state=42)<br/>kmeans.fit(principalDf.values)<br/>labels = kmeans.predict(principalDf.values)<br/>unique_elements, counts_elements = np.unique(labels, return_counts=True)<br/>clusters = np.asarray((unique_elements, counts_elements))</span><span id="b53f" class="nb lq jg mx b gy ng nd l ne nf"># Write a function that calculates distance between each point and the centroid of the closest cluster</span><span id="b90a" class="nb lq jg mx b gy ng nd l ne nf">def getDistanceByPoint(data, model):<br/>    """ Function that calculates the distance between a point and centroid of a cluster, <br/>            returns the distances in pandas series"""<br/>    distance = []<br/>    for i in range(0,len(data)):<br/>        Xa = np.array(data.loc[i])<br/>        Xb = model.cluster_centers_[model.labels_[i]-1]<br/>        distance.append(np.linalg.norm(Xa-Xb))<br/>    return pd.Series(distance, index=data.index)</span><span id="b836" class="nb lq jg mx b gy ng nd l ne nf"># Assume that 13% of the entire data set are anomalies </span><span id="a346" class="nb lq jg mx b gy ng nd l ne nf">outliers_fraction = 0.13</span><span id="2b4f" class="nb lq jg mx b gy ng nd l ne nf"># get the distance between each point and its nearest centroid. The biggest distances are considered as anomaly</span><span id="8b07" class="nb lq jg mx b gy ng nd l ne nf">distance = getDistanceByPoint(principalDf, kmeans)</span><span id="845f" class="nb lq jg mx b gy ng nd l ne nf"># number of observations that equate to the 13% of the entire data set</span><span id="4bb6" class="nb lq jg mx b gy ng nd l ne nf">number_of_outliers = int(outliers_fraction*len(distance))</span><span id="ba75" class="nb lq jg mx b gy ng nd l ne nf"># Take the minimum of the largest 13% of the distances as the threshold</span><span id="f182" class="nb lq jg mx b gy ng nd l ne nf">threshold = distance.nlargest(number_of_outliers).min()</span><span id="fb03" class="nb lq jg mx b gy ng nd l ne nf"># anomaly1 contain the anomaly result of the above method Cluster (0:normal, 1:anomaly) </span><span id="6c9d" class="nb lq jg mx b gy ng nd l ne nf">principalDf['anomaly1'] = (distance &gt;= threshold).astype(int)</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ot"><img src="../Images/14c0b8b860b479dbe000c3acd054cb72.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UsToS8_mHQ-7smhHZL8RVw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">异常用红色标记</p></figure><h2 id="ca23" class="nb lq jg bd lr oh oi dn lv oj ok dp lz lm ol om md ln on oo mh lo op oq ml or bi translated">隔离森林</h2><pre class="ms mt mu mv gt mw mx my mz aw na bi"><span id="059d" class="nb lq jg mx b gy nc nd l ne nf"># Import IsolationForest</span><span id="afac" class="nb lq jg mx b gy ng nd l ne nf">from sklearn.ensemble import IsolationForest</span><span id="86bb" class="nb lq jg mx b gy ng nd l ne nf"># Assume that 13% of the entire data set are anomalies<br/> <br/>outliers_fraction = 0.13</span><span id="003c" class="nb lq jg mx b gy ng nd l ne nf">model =  IsolationForest(contamination=outliers_fraction)<br/>model.fit(principalDf.values) <br/>principalDf['anomaly2'] = pd.Series(model.predict(principalDf.values))</span><span id="078a" class="nb lq jg mx b gy ng nd l ne nf"># visualization<br/>df['anomaly2'] = pd.Series(principalDf['anomaly2'].values, index=df.index)<br/>a = df.loc[df['anomaly2'] == -1] #anomaly<br/>_ = plt.figure(figsize=(18,6))<br/>_ = plt.plot(df['sensor_11'], color='blue', label='Normal')<br/>_ = plt.plot(a['sensor_11'], linestyle='none', marker='X', color='red', markersize=12, label='Anomaly')<br/>_ = plt.xlabel('Date and Time')<br/>_ = plt.ylabel('Sensor Reading')<br/>_ = plt.title('Sensor_11 Anomalies')<br/>_ = plt.legend(loc='best')<br/>plt.show();</span></pre><figure class="ms mt mu mv gt is gh gi paragraph-image"><div role="button" tabindex="0" class="it iu di iv bf iw"><div class="gh gi ou"><img src="../Images/931f46626cf67dd5b1285264d35c0582.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iqwbUyATzS9DQMMehPjiuw.png"/></div></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">用红色标记的异常</p></figure><h2 id="fb14" class="nb lq jg bd lr oh oi dn lv oj ok dp lz lm ol om md ln on oo mh lo op oq ml or bi translated">模型评估</h2><p id="ab1c" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">有趣的是，这三个模型都发现了许多相似的异常现象。仅仅从视觉上看上面的图表，人们可以很容易地得出结论，隔离林可能比其他两个检测到更多的异常。然而，下面的表格显示，相反，IQR检测到的异常比K-Means和隔离森林要多得多。</p><figure class="ms mt mu mv gt is gh gi paragraph-image"><div class="gh gi ov"><img src="../Images/b2c9d929ddf00c26a1acf9b9b10b77d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1018/format:webp/1*Bdyc0oMg8ds7OM9e63RVfA.png"/></div><p class="iz ja gj gh gi jb jc bd b be z dk translated">每个模型检测到的异常数量</p></figure><p id="9c42" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">你认为这是为什么？当其他两个模型检测分布在不同时间段的异常时，IQR是否主要检测相距较近的异常？IQR比其他两位更科学吗？我们如何定义准确性？现在，让我把这些问题留给你去思考。我将在以后的帖子中更详细地写关于模型评估的更多内容。</p><h1 id="21d6" class="lp lq jg bd lr ls ny lu lv lw nz ly lz ma oa mc md me ob mg mh mi oc mk ml mm bi translated">结论</h1><p id="bb8a" class="pw-post-body-paragraph kg kh jg kj b kk mn km kn ko mo kq kr lm mp ku kv ln mq ky kz lo mr lc ld le ij bi translated">到目前为止，我们已经用三种不同的方法进行了异常检测。在此过程中，我们经历了常用数据科学流程的大部分步骤，包括以下步骤:</p><ol class=""><li id="834c" class="nh ni jg kj b kk kl ko kp lm nj ln nk lo nl le oe nn no np bi translated"><strong class="kj jh">问题识别</strong></li><li id="3370" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated"><strong class="kj jh">数据角力</strong></li><li id="e1d2" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated"><strong class="kj jh">探索性数据分析</strong></li><li id="f411" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated"><strong class="kj jh">预处理和训练数据开发</strong></li><li id="d90e" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated"><strong class="kj jh">建模</strong></li><li id="817b" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">证明文件</li></ol><p id="285c" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">在这个项目中，我面临的一个挑战是，使用无监督学习算法训练异常检测模型具有如此大的数据集，在计算上可能非常昂贵。例如，我不能用这些数据正确地训练SVM，因为它花了很长时间来训练模型，却没有成功。</p><p id="b1f2" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">我建议接下来采取以下步骤，其中前3步侧重于改进模型，后两步则是让事情变得真实:</p><ol class=""><li id="04fa" class="nh ni jg kj b kk kl ko kp lm nj ln nk lo nl le oe nn no np bi translated">利用高级特征工程技术进行特征选择</li><li id="bce2" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">高级超参数调谐</li><li id="0eaf" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">实现其他学习算法，如SVM，DBSCAN等。</li><li id="4c74" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated">使用给定测试集的最佳模型预测机器状态—砰！</li><li id="2d09" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le oe nn no np bi translated"><strong class="kj jh">将最佳模型部署到生产中——DOUBLE BAM！</strong></li></ol><p id="5bfe" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">除了实施上述步骤，我将继续改进模型，并计划在未来的另一篇文章中分享结果。</p><p id="3daa" class="pw-post-body-paragraph kg kh jg kj b kk kl km kn ko kp kq kr lm kt ku kv ln kx ky kz lo lb lc ld le ij bi translated">Jupyter笔记本可以在<a class="ae jd" href="https://github.com/bauyrjanj/Anomaly_Detection/tree/master/models" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到详情。享受检测异常，让我们在LinkedIn 上联系。</p><h2 id="3e18" class="nb lq jg bd lr oh oi dn lv oj ok dp lz lm ol om md ln on oo mh lo op oq ml or bi translated">在线参考和有用的资料</h2><ul class=""><li id="0a87" class="nh ni jg kj b kk mn ko mo lm ow ln ox lo oy le nm nn no np bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/detecting-stationarity-in-time-series-data-d29e0a21e638">检测时间序列数据的平稳性</a></li><li id="b8aa" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated"><a class="ae jd" href="https://machinelearningmastery.com/gentle-introduction-autocorrelation-partial-autocorrelation/" rel="noopener ugc nofollow" target="_blank">自相关和偏自相关的简明介绍</a></li><li id="72fa" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated"><a class="ae jd" href="https://setosa.io/ev/principal-component-analysis/" rel="noopener ugc nofollow" target="_blank">主成分分析</a></li><li id="0344" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated"><a class="ae jd" rel="noopener" target="_blank" href="/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c">主成分分析的一站式商店</a></li><li id="1685" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated"><a class="ae jd" href="https://matteucci.faculty.polimi.it/Clustering/tutorial_html/kmeans.html" rel="noopener ugc nofollow" target="_blank">K-均值聚类</a></li><li id="cd68" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated"><a class="ae jd" href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html" rel="noopener ugc nofollow" target="_blank"> Sklearn K-Means文档</a></li><li id="8002" class="nh ni jg kj b kk nq ko nr lm ns ln nt lo nu le nm nn no np bi translated"><a class="ae jd" href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" rel="noopener ugc nofollow" target="_blank"> Sklearn隔离森林文件</a></li></ul></div></div>    
</body>
</html>