<html>
<head>
<title>Practical Machine Learning Tutorial: Part.3 (Model Evaluation-1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实用机器学习教程:第3部分(模型评估-1)</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/practical-machine-learning-tutorial-part-3-model-evaluation-1-5eefae18ec98?source=collection_archive---------37-----------------------#2020-11-04">https://towardsdatascience.com/practical-machine-learning-tutorial-part-3-model-evaluation-1-5eefae18ec98?source=collection_archive---------37-----------------------#2020-11-04</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6849" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">多类分类问题:地球科学示例(相)</h2></div><p id="297a" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在这一部分中，我们将详细阐述一些专门针对多类分类问题的模型评估度量。对于我们的相问题，下面讨论准确度、精确度、回忆和混淆矩阵。这篇文章是第一部分、<a class="ae lb" rel="noopener" target="_blank" href="/practical-machine-learning-tutorial-part-2-build-model-validate-c98c2ddad744">第二部分</a>的第三部分。你可以在这里找到这部分<a class="ae lb" href="https://github.com/mardani72/Practical_ML_Tutorial_Facies_examp" rel="noopener ugc nofollow" target="_blank">的jupyter笔记本文件。</a></p><p id="5a43" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">当我刚接触机器学习时，我一直认为构建模型是ML任务中最重要的一步，而现在，我有了另一个概念；模型评估技巧是建模成功的关键。我们需要确保我们的模型能够很好地处理新数据。另一方面，我们必须能够解释各种评估指标，以了解我们的模型的优点和缺点，引导我们对模型进行改进。因为我们在本教程中处理多类问题，所以我们将关注相关的评估指标，但在此之前，我们需要熟悉一些定义。</p><h2 id="6c40" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated"><strong class="ak">3–1模型指标</strong></h2><p id="f0e7" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">当我们处理分类问题时，我们将有4种可能的模型结果:</p><p id="a7b8" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> A) </strong> <strong class="kh ir">真正</strong> ( <strong class="kh ir"> TP </strong>)是模型的结果<em class="ma">正确</em>预测了<em class="ma">正</em>类。在我们的数据集中，正类是我们专门为标签预测寻找的标签。例如，如果我们正在分析“白云石”类预测，TP是模型测试数据的真实预测白云石样本的数量。</p><p id="0f8c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> B)真阴性</strong> ( <strong class="kh ir"> TN </strong>)是模型<em class="ma">正确</em>预测<em class="ma">阴性</em>类的结果。白云石预测数据集中的负类是那些真正预测为非白云石的相类(预测为其余类，且确实不是白云石)。</p><p id="2eaa" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> C) </strong> <strong class="kh ir">假阳性</strong> ( <strong class="kh ir"> FP </strong>)是模型<em class="ma">错误地</em>预测<em class="ma">阳性</em>类别的结果。在我们的数据集中，当我们评估白云岩类预测时，所有被错误预测为白云岩的相类。</p><p id="7b15" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> D </strong> ) <strong class="kh ir">假阴性</strong> ( <strong class="kh ir"> FN </strong>)是模型<em class="ma">错误地</em>预测<em class="ma">阴性</em>类的结果。同样对于白云石预测，FN是将白云石预测为非白云石类。</p><p id="2741" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 1。准确度</strong>:它只是被计算为正确预测占预测总数的百分比。</p><p id="c597" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">准确度= (TP+TN) / (TP+TN+FP+FN)</p><p id="7e6f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 2。精度</strong>:这个指标回答了这个问题:<em class="ma">完全正确的正面预测比例是多少？</em></p><p id="65e0" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">Precision = TP / (TP+FP) <br/>看等式，我们可以看到，如果一个模型的假阳性预测为零，那么精度将为1。同样，在白云石预测中，该指标显示了所预测的白云石真正是白云石的比例(而不是其他相被归类为白云石)。</p><p id="bbfd" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 3。回忆</strong>:回忆回答这个问题:<em class="ma">实际阳性有多少比例是正确分类的？</em></p><p id="b862" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">召回率= TP / (TP+FN) <br/>看等式，我们可以看到，如果一个模型的假阴性预测为零，那么召回率将为1。在我们的例子中，回忆显示了被模型正确识别的白云石类的比例。</p><p id="bf5c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">注</strong>:评估模型效率需要同时考虑精度和召回率。不幸的是，这两个参数相互作用，提高一个会导致降低另一个。理想的情况是两者都显示接近1的值。</p><p id="b34f" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir"> 4。f1 _ score:</strong>F1分数可以解释为精度和召回率的加权平均值，其中F1分数在1处达到其最佳值，在0处达到其最差分数。精确度和召回率对F1分数的相对贡献是相等的。F1分数的公式为:</p><p id="becc" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">F1 = 2 *(精度*召回)/(精度+召回)</p><p id="fd1e" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们看一个逻辑回归分类器性能的例子:</p><p id="b42c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">运行:</p><pre class="mb mc md me gt mf mg mh mi aw mj bi"><span id="210e" class="lc ld iq mg b gy mk ml l mm mn">from sklearn.metrics import precision_recall_fscore_support<br/>model_log=LogisticRegression(C = 10, solver = ‘lbfgs’, max_iter= 200 ) <br/>model_log.fit(X_train, y_train)<br/>y_pred_log = model_log.predict(X_test)<br/>print(classification_report(y_test, y_pred_log, target_names= facies_labels))</span></pre><figure class="mb mc md me gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mo"><img src="../Images/db2ed65b69d50a69ff58093a07cfc060.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BFHCbJi71d7UTYcbseNT2A.png"/></div></div></figure><p id="f35c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">为了评估逻辑回归分类器的性能，让我们看看第一相类砂岩(ss)。当这个模型预测一个相为SS时，它在75%的时间内是正确的(精度)。另一方面，该模型正确识别了所有SS相成员的89%(回忆)。我们可以猜测f1_score介于这两个指标之间。支持是指用于测试的单个类成员。</p><p id="ec7c" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">让我们用一些代码块来实现上述步骤，以便对所有模型进行排序，并绘制出结果的平均值。到第15行，我们用已经从网格搜索方法中获得的超参数定义了模型对象。然后(第16行到第25行)模型被添加到一个列表中，当我们想要按顺序拟合和交叉验证时，这个列表是可迭代的。在交叉验证之后，我们将每个模型的度量结果存储在列表中。第37到52行，我们建立了一个for循环来计算每个模型的每个指标的平均值。代码的其余部分是一个绘图任务。</p><figure class="mb mc md me gt mp"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="mb mc md me gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi my"><img src="../Images/9439eb6d4dcd8664e9775e46cef14b19.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mc8Es5nkhM23QQIyjnx8Ww.png"/></div></div></figure><p id="6aa3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">该图显示了各个采用模型的每个评估指标(y轴)的平均值。在这里，我们想从整体上比较所有型号的性能。看起来额外树和随机森林做了最好的预测，而高斯朴素贝叶斯不是那么有效的预测模型。</p><p id="6225" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果我们关心一个单独的相预测，我们应该考虑从“结果”列表中删除剩余的指标，并再次运行程序。</p><h2 id="8645" class="lc ld iq bd le lf lg dn lh li lj dp lk ko ll lm ln ks lo lp lq kw lr ls lt lu bi translated">3–2混淆矩阵</h2><p id="788a" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">混淆矩阵显示了相对于原始真实标签数据的预测类别标签。这是一个奇妙的可视化工具，我们可以看到每一类相被正确或错误地预测到其他类中。</p><p id="7988" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的一行代码中，我们首先定义了一个函数，来花式利用sklearn开发的混淆矩阵函数。在函数定义之后，我们拟合并运行逻辑回归分类器。现在，我们已经用测试数据的真实相标签预测了相标签。使用所需的输入参数调用函数将创建混淆矩阵图。</p><figure class="mb mc md me gt mp"><div class="bz fp l di"><div class="mw mx l"/></div></figure><figure class="mb mc md me gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mz"><img src="../Images/0ae3e96505b47335ead161caffacba10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KT4R_bsI_tAj3_jtdwMEJw.png"/></div></div></figure><p id="5500" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">看一下图(第一行)，我们认识到该算法可以正确地预测151个ss类别，而18个真实SS被错误地分类为CSI。从上一节中，我们熟悉了召回的概念。从SS(169)的所有真实类成员中，分类器可以正确地识别151；151/169是89%(上图我们在班级报告里看到过这个数字)。因此，我们可以得出结论，如果我们在行的方向上移动我们的评估(真实标签),我们正在处理召回。<br/>你可能会猜测，如果我们走列方向，我们将处理精度。对于SS，精度为149/201的75%。</p><p id="8521" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">在下面的图片中，我们看到朴素贝叶斯分类器如何表现不佳的预测。这个分类器在预测上完全高估了BS类。</p><figure class="mb mc md me gt mp gh gi paragraph-image"><div role="button" tabindex="0" class="mq mr di ms bf mt"><div class="gh gi mz"><img src="../Images/e23c85aad6feb5fac7ecd950eeef101b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*qhIOXFDpockYwFRiLbjU8Q.png"/></div></div></figure><p id="18ea" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">到目前为止，我们有一些帮助我们评估模型性能的指标，但是我们仍然不能保证哪一个是最好的。由于一些模型可以记忆训练数据，并严格遵循数据复杂性，当它面对一个新的数据集时，它的性能将会很差。这就是所谓的<strong class="kh ir">过拟合</strong>(高方差模型)。具有高方差的模型会随着训练数据集的小变化而发生很大变化。<br/>另一方面，当模型过于一般化预测时，它将无法捕捉数据集的复杂性，这被称为<strong class="kh ir">欠拟合</strong>(高偏差模型)。我们的理想模型介于这两个模型之间，让我们进行偏差-方差权衡。</p><p id="fcc7" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><em class="ma">问题是</em>:我们如何识别我们的模型是过拟合还是欠拟合？<br/>我们将在本教程的下一部分讨论。</p><h1 id="dd7a" class="na ld iq bd le nb nc nd lh ne nf ng lk jw nh jx ln jz ni ka lq kc nj kd lt nk bi translated">结论:</h1><p id="c94f" class="pw-post-body-paragraph kf kg iq kh b ki lv jr kk kl lw ju kn ko lx kq kr ks ly ku kv kw lz ky kz la ij bi translated">模型评估是ML模型制作中最重要的任务。我们主要从简单的评估指标开始，然后缩小到具体和更详细的指标，以了解我们模型的优势和劣势。</p><p id="6127" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated">如果您有任何问题，请通过我的LinkedIn联系我:<a class="ae lb" href="https://www.linkedin.com/in/amardani/" rel="noopener ugc nofollow" target="_blank"> Ryan A. Mardani </a></p><p id="ebe3" class="pw-post-body-paragraph kf kg iq kh b ki kj jr kk kl km ju kn ko kp kq kr ks kt ku kv kw kx ky kz la ij bi translated"><strong class="kh ir">参考资料:</strong><br/>1)<a class="ae lb" href="https://jakevdp.github.io/PythonDataScienceHandbook/index.html" rel="noopener ugc nofollow" target="_blank">https://jakevdp . github . io/python datascience handbook/index . html</a><br/>2)<a class="ae lb" href="https://scikit-learn.org/stable/supervised_learning.html#supervised-learning" rel="noopener ugc nofollow" target="_blank">https://scikit-learn.org/stable</a><br/>3)<a class="ae lb" href="https://machinelearningmastery.com/" rel="noopener ugc nofollow" target="_blank">https://machinelearningmastery.com</a><br/>4)<a class="ae lb" href="https://github.com/brendonhall/facies_classification/blob/master/Facies%20Classification%20-%20SVM.ipynb" rel="noopener ugc nofollow" target="_blank">布伦顿霍尔</a></p></div></div>    
</body>
</html>