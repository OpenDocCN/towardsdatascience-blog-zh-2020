<html>
<head>
<title>Are You Ready for Vision Transformer (ViT)?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">你准备好接受视觉变形器(ViT)了吗？</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/are-you-ready-for-vision-transformer-vit-c9e11862c539?source=collection_archive---------4-----------------------#2020-10-11">https://towardsdatascience.com/are-you-ready-for-vision-transformer-vit-c9e11862c539?source=collection_archive---------4-----------------------#2020-10-11</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="ddb6" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">“一幅图像相当于16x16个字:大规模图像识别的变形金刚”可能会给计算机视觉带来又一次突破</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/32ed09b6b44ea10ceca0ca7eb9d36a88.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bvmqc150E4u8mh_WGD0p6g.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">达里娅·谢夫索娃在<a class="ae kv" href="https://unsplash.com/s/photos/death?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="2a97" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">地球上的生命面临着兴衰循环。它不仅适用于生物，也适用于技术。数据科学中的技术充满了炒作和有偏见的成功故事。说到这里，有一些技术导致了数据科学的发展:<strong class="ky ir">卷积神经网络(CNN) </strong>。自2012年AlexNet 以来，不同架构的细胞神经网络已经为实际的商业运作和学术研究带来了巨大的贡献。<a class="ae kv" href="https://arxiv.org/abs/1512.03385" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">【ResNet】</strong></a>由微软研究院在2015年带来了构建“深度”CNN的真正突破；然而，这项技术即将光荣退休。神经网络之父、2018年图灵奖得主之一杰弗里·辛顿(Geoffrey Hinton)多年来一直在提及CNN的缺陷。可以找他的一个研讨会“<a class="ae kv" href="https://www.youtube.com/watch?v=Jv1VDdI4vy4" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">卷积神经网络</strong> </a> <strong class="ky ir">怎么了？</strong>“2017年。CNN的一个主要缺陷存在于合并图层中，因为它丢失了许多有价值的信息，并且它忽略了图像的局部与整体之间的关系。代替CNN，Geoffrey Hinton和他的团队在2018年发表了一篇关于<a class="ae kv" href="https://openreview.net/forum?id=HJWLfGWRb" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">胶囊网</strong> </a>的论文；然而，它还没有取代CNN。</p><h1 id="e302" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">目录</h1><ol class=""><li id="f7b5" class="mk ml iq ky b kz mm lc mn lf mo lj mp ln mq lr mr ms mt mu bi translated">一幅图像的简介相当于16x16个字:大规模图像识别的变形金刚</li><li id="83e6" class="mk ml iq ky b kz mv lc mw lf mx lj my ln mz lr mr ms mt mu bi translated">为什么视觉转换器(ViT)很重要？</li><li id="b05c" class="mk ml iq ky b kz mv lc mw lf mx lj my ln mz lr mr ms mt mu bi translated">关闭</li><li id="1a77" class="mk ml iq ky b kz mv lc mw lf mx lj my ln mz lr mr ms mt mu bi translated">进一步研究的材料</li></ol><h1 id="e44e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">一幅图像的简介相当于16x16个字:大规模图像识别的变形金刚</h1><p id="0f81" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我是从安德烈·卡帕西2020年10月3日的推特上得知这篇论文的。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nd"><img src="../Images/d5525e036902e91af757aaeaf98f892d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/format:webp/1*XFg7Y7WGtEWJzDheX2DzMw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图。这条推文是由Andrej Karpathy创作的。</p></figure><p id="3048" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">安德烈·卡帕西(Andrej Karpathy)是特斯拉人工智能的高级主管，他曾在2016年教过一堂课<a class="ae kv" href="https://www.youtube.com/watch?v=LxfUGhug-iQ" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir"> CS231n </strong> </a>，内容涵盖了斯坦福大学计算机视觉方面的主题。尽管内容已经过时，他还是表现出了用简单的语言表达复杂概念的高超技巧。我从他的课上学到了很多东西。</p><p id="5761" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的目的是给那些不了解Transformer的机器学习工程师和数据科学家提个醒，让他们在“创新科技公司”为Vision Transformer推出GitHub知识库之前做好准备。</p><p id="342f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ne">这篇论文是谁写的？</em> </strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/774f1133f8ca34e08dd229ff46cc1c97.png" data-original-src="https://miro.medium.com/v2/resize:fit:1146/format:webp/1*UZZDiTBpy95os3m17S0TAQ.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图。出处是论文上的扉页“一个图像抵得上16x16个字。”</p></figure><p id="d4af" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我一般会在阅读前查看作者/机构的名字，以鉴别论文的可信度。这篇名为<a class="ae kv" href="https://openreview.net/forum?id=YicbFdNTTy" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">一幅图像抵得上16x16个字:图像识别的变形金刚</strong> </a>的论文于2020年9月28日提交，由于论文正在进行双盲评审，作者姓名尚未透露。我不会明确提到公司的名字。然而，你可以做出一个有根据的猜测，谁能花得起2500个TPU日来训练一个模型(下面突出显示)，还有另一个线索表明，该模型是在JFT-300M上训练的，这是一个拥有3亿张图像的私人数据集。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi ng"><img src="../Images/5d0e29ac7186c9253b30b4f9d2b4db5f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1084/format:webp/1*wxyjIVJ2cWpGVqr5YZad6g.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图。来源是“一幅图像相当于16x16个单词”这篇论文中的表2</p></figure><h1 id="e0e6" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated"><strong class="ak"> <em class="nh">为什么视觉转换器(ViT)很重要？</em>T15】</strong></h1><p id="6c7c" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">这不是第一篇将Transformer应用于计算机视觉的论文。脸书2020年5月发布<a class="ae kv" href="https://ai.facebook.com/blog/end-to-end-object-detection-with-transformers/" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir">【DETR】</strong></a>；然而，DETR与CNN联合使用了《变形金刚》。ViT是Transformer对于计算机视觉最成功的应用，这项研究被认为做出了三点贡献。</p><p id="60d6" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ne">训练精度高，计算时间少</em> </strong></p><p id="bf7e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">与<a class="ae kv" href="https://arxiv.org/abs/1911.04252v4" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">吵闹的学生</strong> </a>(由谷歌于2020年6月发布)相比，ViT减少了80%的训练时间，尽管ViT已经达到了与论文(上图)中表2所示大致相同的准确度。Noisy Student采用了EfficientNet架构，我将写另一篇关于EfficientNet的博文，以帮助读者了解自ResNet以来，CNN在不久的将来走了多远。</p><p id="35ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ne">无卷积网络的模型架构</em> </strong></p><p id="64e1" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">变压器架构背后的核心机制是<strong class="ky ir">自我关注</strong>。它提供了理解输入之间的联系的能力。当变压器应用于NLP时，它以双向方式计算单词之间的关系，这意味着输入的顺序不像RNN那样重要。具有Transformer架构的模型使用自关注层的堆栈而不是CNN和rnn来处理可变大小的输入。你可以在我的上一篇文章中了解更多关于Transformer的知识，这篇文章是用通俗易懂的语言写给商务人士的，“假装你熟悉BERT的最低要求”。</p><p id="c97b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">将没有CNN的变形金刚应用到图像的一个主要挑战是在像素之间应用自我关注。如果输入图像的大小是640x640，那么模型需要计算409K个组合的自我关注度。此外，您可以想象，图像一个角上的像素不太可能与图像另一个角上的另一个像素有有意义的关系。ViT通过将图像分割成小块(如16x16)克服了这个问题。句子的原子是一个单词，这项研究将碎片定义为图像的原子，而不是像素，以有效地梳理模式。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ni"><img src="../Images/cddd2ef87ce3afc9c9740a42a860a0ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*nnp3dFzI-HL_nibwMl5GbQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">作者截图。来源是纸上的图1“一个图像抵得上16x16个字。”</p></figure><p id="88fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir"> <em class="ne">小贴片变压器的功效</em> </strong></p><p id="857f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">通过分析多头注意的中间结果，分析了ViT的内部表征。本文发现，该模型能够在位置嵌入的相似性中编码面片的距离。另一个发现是，论文发现ViT整合了整个图像的信息，甚至在《变形金刚》中的最低层。作为旁注，ViT-Large有24层，隐藏大小为1，024和16个注意头。该论文引用的内容是“我们发现一些头部已经注意到最底层的大部分图像，这表明模型确实使用了全局整合信息的能力。”</p><p id="22ff" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">定性分析模型性能通常与定量分析一样重要，以了解预测的稳健性。我通常使用<a class="ae kv" href="http://cnnlocalization.csail.mit.edu/" rel="noopener ugc nofollow" target="_blank"> <strong class="ky ir">类激活图</strong> </a>(麻省理工学院于2015年发布)来验证模型性能的稳健性，方法是查看来自具有正确预测、假阳性和假阴性的图像的类激活图，以创建和测试不同的假设。</p><h1 id="5e13" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">关闭</h1><p id="3c88" class="pw-post-body-paragraph kw kx iq ky b kz mm jr lb lc mn ju le lf na lh li lj nb ll lm ln nc lp lq lr ij bi translated">我很少阅读正在接受审查的论文，因为提交的论文内容会被修改，其中许多甚至会被期刊拒绝。但是，我写了这篇文章，因为内容真的很有创意，而且我也喜欢这篇论文富有诗意的标题！当论文正式发表时，我计划对这篇文章做一些更新。</p><p id="c84f" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">更新:2020年12月4日</strong></p><p id="68dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><a class="ae kv" href="https://github.com/google-research/vision_transformer" rel="noopener ugc nofollow" target="_blank">视觉变形金刚的官方仓库准备好了</a>。享受ViT的生活！</p><h1 id="dc66" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">进一步研究的材料</h1><ol class=""><li id="edf5" class="mk ml iq ky b kz mm lc mn lf mo lj mp ln mq lr mr ms mt mu bi translated">你可以阅读提交的论文，<a class="ae kv" href="https://openreview.net/forum?id=YicbFdNTTy" rel="noopener ugc nofollow" target="_blank">在OpenReivew.net，谷歌一幅图像值16x16字:大规模图像识别的变形金刚</a>。</li><li id="5ac1" class="mk ml iq ky b kz mv lc mw lf mx lj my ln mz lr mr ms mt mu bi translated">Jay Alamer的《变形金刚》插图是理解《变形金刚》如何一步一步工作的最佳材料，其中的图片非常有用。</li><li id="db46" class="mk ml iq ky b kz mv lc mw lf mx lj my ln mz lr mr ms mt mu bi translated">如果你想在没有数学的情况下理解Transformer的应用，我的博客文章<a class="ae kv" rel="noopener" target="_blank" href="/minimal-requirements-to-pretend-you-are-familiar-with-bert-3889023e4aa9">假装你熟悉BERT </a>的最低要求将会帮助你，因为我的读者是商务人士和初级数据科学家。</li><li id="3db1" class="mk ml iq ky b kz mv lc mw lf mx lj my ln mz lr mr ms mt mu bi translated">如果你对视觉变形器统治这个领域之前，谷歌大脑和研究团队(截至2021年2月)使用CNN的计算机视觉的艺术模型感兴趣，你可以在<a class="ae kv" rel="noopener" target="_blank" href="/simple-copy-paste-is-a-game-changer-for-computer-vision-5858a9445caa">中看到没有数学的解剖学简单的复制粘贴是计算机视觉问题的游戏改变者</a>。</li><li id="f076" class="mk ml iq ky b kz mv lc mw lf mx lj my ln mz lr mr ms mt mu bi translated">最后一个材料与学习Transformer的概念没有直接关系，但读者曾问我如何实现Transformer。如果你已经对变形金刚有了基本的了解，首先你可以从这篇文章中学习如何使用PyTorch，<a class="ae kv" rel="noopener" target="_blank" href="/understanding-pytorch-with-an-example-a-step-by-step-tutorial-81fc5f8c4e8e">通过一个例子了解PyTorch:一个分步教程</a>，然后你可以通过<a class="ae kv" href="https://huggingface.co/transformers/quickstart.html" rel="noopener ugc nofollow" target="_blank"> HuggingFace的快速入门</a>来创建你的第一个变形金刚模型。享受变形金刚！</li></ol></div></div>    
</body>
</html>