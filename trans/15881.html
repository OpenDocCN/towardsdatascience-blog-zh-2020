<html>
<head>
<title>Building an AI 8-Ball with RoBERTa</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">与罗伯塔一起建造人工智能8号球</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/building-an-ai-8-ball-with-roberta-2bfbf6f5519b?source=collection_archive---------39-----------------------#2020-11-01">https://towardsdatascience.com/building-an-ai-8-ball-with-roberta-2bfbf6f5519b?source=collection_archive---------39-----------------------#2020-11-01</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="839b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">人工神经网络能回答是/否问题吗？迹象表明是的。</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/c130876166bdbd4c9baad942e2935c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lzv5zRutA3s6-HrQw17Fyg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">ai8ball装置及作者照片</p></figure><h1 id="66ba" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">概观</h1><p id="d0f3" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">在这篇文章中，我将向你展示我如何利用互联网的力量和当前的机器学习技术构建一个可以回答是/否问题的人工智能8球。我将从系统的高级描述开始，然后进入组件的细节以及Python代码的摘录。我将展示如何获得否定回答的百分比和置信度的百分比作为输出。最后，我会给出如何运行AI 8球的说明，来回答大家自己的问题。</p><h1 id="93fd" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">背景</h1><p id="1fff" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">你用过神奇的8号球吗？这是美泰公司在50年代推出的玩具，至今仍在销售。这很简单。这是一个超大的8号球，回答是/不是问题。它有一个漂浮在黑暗液体中的20面骰子，使用随机选择的“魔法”来回答问题。在二十个可能的答案中，有五个表示没有，像“很值得怀疑”，五个表示可能，像“回复朦胧，再试一次”，十个表示有，像“是一定的”。</p><p id="972d" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">早在2007年，我就制作了一个AI 8球的早期原型，如上图，并在麻省理工学院Stata中心展示了它，作为名为COLLISIONcollective C11的群展的一部分。我的第一个版本使用了一个人工神经网络(ANN ),以今天的标准来看，它非常小，只有1056个神经连接。我的新版本使用了一个叫做大型罗伯塔模型的人工神经网络，它有3.55亿个神经连接。</p><h1 id="2ca2" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">人工智能8球</h1><p id="ed5f" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">AI 8-Ball是使用自然语言处理(NLP)的几个现有组件构建的。该系统的核心是大型的RoBERTa模型，我使用Google AI的BoolQ数据集对其进行了微调，以回答是/否问题[2]。</p><p id="b260" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">用户可以键入任何问题，系统从维基百科、纽约时报和BoolQ数据集收集支持文本段落。我使用了一个叫做PyTextRank的系统来从问题中提取关键词，这些关键词被用来查找维基百科和NYT的文章。我还使用Google的通用句子编码器[3]在BoolQ数据集中检查类似的问题。如果有非常接近的匹配，我使用相关的文本作为第三段。</p><p id="90b3" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">所有的段落和问题都被发送到罗伯塔模型中进行推理。每个推断返回三个百分比:是、否和置信度。将具有最高置信度的推断作为答案报告给用户。下图显示了包含一个示例问题和结果的组件。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi mr"><img src="../Images/e9d7d4e38afa4a1562603e0952e47470.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lsspb8Ew4LoJmCFp0RpGTA.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">AI 8球元件图</p></figure><h1 id="a48e" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">AI 8球组件和细节</h1><h2 id="ba0d" class="ms kz it bd la mt mu dn le mv mw dp li lz mx my lk md mz na lm mh nb nc lo nd bi translated">伯特和罗伯塔</h2><p id="ba33" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">BERT是由Google构建和训练的NLP模型的名称。该名称代表变压器的双向编码器表示。该系统设计用于执行常见的NLP任务，如机器翻译、文档摘要和文本生成。更多关于伯特的信息可以在Rani Horev的帖子<a class="ae ne" rel="noopener" target="_blank" href="/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270">这里</a>找到。</p><p id="5295" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">对于这个项目，我使用的是RoBERTa模型，这是对原始BERT的改进。它是由华盛顿大学和脸书大学的研究人员设计和训练的。RoBERTa的增强包括用更大的批次训练更长的模型，用更长的序列使用更多的数据，以及其他提高准确性的变化[4]。</p><h2 id="ca28" class="ms kz it bd la mt mu dn le mv mw dp li lz mx my lk md mz na lm mh nb nc lo nd bi translated">BoolQ数据集</h2><p id="439a" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">BoolQ是一个来自Google AI的数据集，包含大约16K个带有相应是/否问题的文本示例[3]。每个条目包含一个问题、标题、答案和一段文字。该数据集可用于训练和测试回答是/否问题的NLP系统。例如，下面是其中一个条目。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="761d" class="ms kz it ng b gy nk nl l nm nn">{"<strong class="ng iu">question</strong>": "did the cincinnati bengals ever win a superbowl", "<strong class="ng iu">title</strong>": "Cincinnati Bengals", "<strong class="ng iu">answer</strong>": false, "<strong class="ng iu">passage</strong>": "The Bengals are one of the 12 NFL teams to not have won a Super Bowl as of the 2017 season; however, they are also one of 8 NFL teams that have been to at least one Super Bowl, but have not won the game."}</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi no"><img src="../Images/240a36066aa829800c17b33415c71a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*euwxamTfdGMi56m9"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ne" href="https://unsplash.com/@ameliaspink?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">阿米莉娅·斯平克</a>在<a class="ae ne" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄</p></figure><h2 id="f277" class="ms kz it bd la mt mu dn le mv mw dp li lz mx my lk md mz na lm mh nb nc lo nd bi translated">微调人工智能8球</h2><p id="927d" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我使用BoolQ数据集对RoBERTa模型进行了微调，从Michael Vincent的帖子<a class="ae ne" href="https://medium.com/illuin/deep-learning-has-almost-all-the-answers-yes-no-question-answering-with-transformers-223bebb70189" rel="noopener">中的代码开始。我修改了他的代码，使用了一个更大的模型，并设置了超参数，如批量大小和时期数，以允许它在Google Colab中进行训练。我更新的训练代码是</a><a class="ae ne" href="https://colab.research.google.com/github/robgon-art/ai8ball/blob/main/AI_8_Ball_Training.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><h2 id="e856" class="ms kz it bd la mt mu dn le mv mw dp li lz mx my lk md mz na lm mh nb nc lo nd bi translated">运行推理</h2><p id="9843" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">下面的Python代码展示了如何使用RoBERTa来回答是/否问题。例如，Wikipedia文章中关于神奇8球的第一段与六个是/否问题一起被传递到模型中。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">运行推理的代码</p></figure><p id="5936" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">文本和问题都被标记化并传递到模型中。它返回一个包含是和否部分的向量。使用PyTorch中的softmax函数可以得出答案为是或否的概率。置信水平可以从向量的长度中导出。以下是六个问题的结果:</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">推理的结果</p></figure><p id="4e49" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">它似乎正确地回答了所有问题。请注意置信度是如何变化的，但并不总是与是/否的百分比一致。例如，文章的第一句话清楚地说明了神奇的8号球是一个球体，因此第一个问题的答案在是和置信度方面都得到了高分。然而，文章中关于库存的句子用代词“它”指代神奇的8号球，这就是为什么关于库存的问题的答案有点不确定。我们将在以后映射到经典魔术8球答案时使用此功能。</p><h2 id="c578" class="ms kz it bd la mt mu dn le mv mw dp li lz mx my lk md mz na lm mh nb nc lo nd bi translated">PyTextRank</h2><p id="fe47" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">该系统使用一种称为TextRank的算法从用户的问题中提取关键词和短语[5]。它基于著名的PageRank算法。为网络搜索而发明的。你传入一个文本块，它返回按相关性排序的关键短语。下面是一些示例代码，展示了如何从一个问题中提取关键词。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">提取关键字的代码</p></figure><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="033e" class="ms kz it ng b gy nk nl l nm nn">Question: <strong class="ng iu">Can a computer beat a grandmaster chess player?</strong><br/>Keywords: <strong class="ng iu">a grandmaster, chess player, a computer</strong></span></pre><p id="c0ed" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">你可以看到它在提取关键短语方面做得很好。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nr"><img src="../Images/f59e86161b19a863daecac7eb74fdfc6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*730Y6RckQgg0K8Y1"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">蒂莫西·埃伯利在<a class="ae ne" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><h2 id="891d" class="ms kz it bd la mt mu dn le mv mw dp li lz mx my lk md mz na lm mh nb nc lo nd bi translated">获取文本段落</h2><p id="6a51" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">现在我们有了关键词，我们可以使用它们来查询维基百科和纽约时报，看看是否有任何相关的文章可以用作该问题的文本段落。此外，我们将使用一种搜索算法，使用一种<em class="ns"> k </em> -d树，简称为<em class="ns"> k- </em>维树，一种用于快速搜索多维数据的数据结构，在BoolQ数据集中找到最近的问题[6]。如果匹配接近，我们将使用相应的文本作为第三段。下面是执行所有三个搜索并将它们传递给RoBERTa模型以获得结果的python代码。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">收集段落的代码</p></figure><p id="99eb" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">现在我们有了三个结果，我们将使用这段代码来看看哪一个具有最高的置信度。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">代码以找到最有把握的结果</p></figure><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nt"><img src="../Images/a53a2c9f36f8881353e99790fade1e7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pxkYAHKkrGH8uG3ihoq53g.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者根据<a class="ae ne" href="https://www.flickr.com/photos/9106303@N05" rel="noopener ugc nofollow" target="_blank">麦克·李希特</a>的<a class="ae ne" href="https://www.flickr.com/photos/9106303@N05/2403514661" rel="noopener ugc nofollow" target="_blank">“无视频魔术8号球”</a>在2.0 的<a class="ae ne" href="https://creativecommons.org/licenses/by/2.0/?ref=ccsearch&amp;atype=rich" rel="noopener ugc nofollow" target="_blank"> CC下授权的照片插图</a></p></figure><h1 id="5856" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">经典魔术8球答案</h1><p id="d818" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">上面的算法给了我们两个输出参数:百分比yes和百分比confidence。为了将这两个参数映射到最接近的经典魔术8球答案，我首先使用通用序列编码器将这20个答案映射到多维空间中。然后，我将维度减少到两个，并旋转这些点，使其与一个否定到肯定的水平轴和一个低到高置信度的垂直轴对齐。进行映射的代码是这里的<a class="ae ne" href="https://colab.research.google.com/github/robgon-art/ai8ball/blob/main/AI_8_Ball_Answers.ipynb" rel="noopener ugc nofollow" target="_blank">和</a>。下图显示了结果。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi nu"><img src="../Images/fe3e833ee8fe2e562c79ce4e70db7bd7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gil6954LO0_9Y9b2Y73D0A.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">神奇8球答案图表</p></figure><p id="0eed" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">使用此代码将最终答案的两个参数映射到经典的Magic 8-Ball。</p><figure class="kj kk kl km gt kn"><div class="bz fp l di"><div class="np nq l"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">将结果映射到经典8球答案的代码</p></figure><p id="c477" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">下面是AI 8-Ball对样题的输出。</p><pre class="kj kk kl km gt nf ng nh ni aw nj bi"><span id="9565" class="ms kz it ng b gy nk nl l nm nn">Question: <strong class="ng iu">Can a computer beat a grandmaster chess player?</strong></span><span id="5c89" class="ms kz it ng b gy nv nl l nm nn">Checking the Wikipedia.<br/>Checking the New York Times.<br/>Checking the BoolQ Dataset.</span><span id="3f4e" class="ms kz it ng b gy nv nl l nm nn">The AI 8-Ball's Answer: <strong class="ng iu">It is certain.</strong></span><span id="da43" class="ms kz it ng b gy nv nl l nm nn">Yes: 99.52%<br/>No: 0.48%<br/>Confidence: 100%<br/>Source: BoolQ Dataset<br/>Passage: Chess programs running on commercially-available desktop computers had convincing victories against human players in matches in 2005 and 2006. Since that time, chess programs running on commercial hardware - more recently including mobile phones - have been able to defeat even the strongest human players.</span></pre><p id="119a" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">以99.52%的肯定率和100%的置信度，映射到最接近的答案“肯定”。</p><h1 id="8cb8" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">运行人工智能8球</h1><p id="50c0" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">你可以在Google Colab上运行AI 8-Ball。请注意，你需要一个谷歌帐户来运行它。</p><ol class=""><li id="f8cf" class="nw nx it ls b lt mm lw mn lz ny md nz mh oa ml ob oc od oe bi translated">点击<a class="ae ne" href="https://colab.research.google.com/github/robgon-art/ai8ball/blob/main/AI_8_Ball.ipynb" rel="noopener ugc nofollow" target="_blank">链接，此处</a>。</li><li id="8e19" class="nw nx it ls b lt of lw og lz oh md oi mh oj ml ob oc od oe bi translated">登录您的<strong class="ls iu">谷歌账户，如果您尚未登录，请点击</strong>。</li><li id="d06e" class="nw nx it ls b lt of lw og lz oh md oi mh oj ml ob oc od oe bi translated">单击第一个<strong class="ls iu">运行单元格</strong>按钮(悬停在[ ]图标上并单击播放按钮)。将出现一条警告，指出此笔记本不是由Google创建的。</li><li id="2ffa" class="nw nx it ls b lt of lw og lz oh md oi mh oj ml ob oc od oe bi translated">点击<strong class="ls iu">无论如何都要运行</strong>初始化系统。下载数据集和配置微调的RoBERTa模型大约需要3到5分钟。</li><li id="7731" class="nw nx it ls b lt of lw og lz oh md oi mh oj ml ob oc od oe bi translated">选择一个问题或键入您自己的问题，然后点击第二个<strong class="ls iu"> Run cell </strong>按钮，查看AI 8-Ball如何回答。</li><li id="29ea" class="nw nx it ls b lt of lw og lz oh md oi mh oj ml ob oc od oe bi translated">重复步骤5，询问其他问题。</li></ol><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ok"><img src="../Images/e437c9ffda5b333ddc1e24073c88bd41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M3FCljPHQsZ-ND6Sx9CA3g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">AI 8-Ball在Google Colab上运行</p></figure><h1 id="5c25" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">未来的工作</h1><p id="4b27" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">对AI 8-Ball的可能改进包括使用语音到文本来提问，并添加动画来揭示答案。这些添加可能会给这个项目带来更多“神奇”的感觉。</p><h1 id="b8ae" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">感谢</h1><p id="2f96" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">我要感谢詹尼弗·林、奥利弗·斯特林佩尔、瓦伊德·呼罗珊·加萨布和马赫萨·梅斯加兰对这个项目的帮助。</p><h1 id="b6ac" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">源代码</h1><p id="74ef" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">这个项目的所有源代码都可以在<a class="ae ne" href="https://github.com/robgon-art/ai8ball" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上获得。源在<a class="ae ne" href="https://creativecommons.org/licenses/by-sa/4.0/" rel="noopener ugc nofollow" target="_blank"> CC BY-SA许可</a>下发布。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/3535242baa594d390b2b0e43b49e461e.png" data-original-src="https://miro.medium.com/v2/resize:fit:176/format:webp/1*7YsqlQ5dbUHzUk2zoh1ROw.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">归属共享相似</p></figure><h1 id="f72e" class="ky kz it bd la lb lc ld le lf lg lh li jz lj ka lk kc ll kd lm kf ln kg lo lp bi translated">参考</h1><p id="4abb" class="pw-post-body-paragraph lq lr it ls b lt lu ju lv lw lx jx ly lz ma mb mc md me mf mg mh mi mj mk ml im bi translated">[1]刘，迈勒奥特，纳曼戈亚尔，杜，曼达尔乔希，陈，奥梅尔利维，，卢克泽特勒莫耶，韦塞林斯托扬诺夫，“罗伯塔:稳健优化的贝特瑞训练方法”，2019，<a class="ae ne" href="https://arxiv.org/pdf/1907.11692.pdf" rel="noopener ugc nofollow" target="_blank">，</a></p><p id="b290" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[2] Christopher Clark，Kenton Lee，张明蔚，汤姆·科维亚特科夫斯基，迈克尔·科林斯，克里斯蒂娜·图坦诺娃，《BoolQ:探索自然是非问题的惊人难度》，2019年，【https://arxiv.org/pdf/1905.10044.pdf T2】</p><p id="b2f2" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[3]丹尼尔·瑟尔、·杨、孔胜义、南华、尼科尔·利姆蒂亚科、罗慕尼·圣约翰、诺亚·康斯坦、马里奥·瓜哈尔多-塞斯佩德斯、史蒂夫·袁、克里斯·塔尔、宋云轩、布赖恩·斯特罗普、雷·库兹韦尔，《通用句子编码器》，2018年，<a class="ae ne" href="https://arxiv.org/pdf/1803.11175.pdf" rel="noopener ugc nofollow" target="_blank"/></p><p id="2a16" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[4]雅各布·德夫林(Jacob Devlin)，张明蔚(Ming-Wei Chang)，肯顿·李(Kenton Lee)，克里斯蒂娜·图坦诺娃(Kristina Toutanova)，《伯特:用于语言理解的深度双向变形金刚的预训练》，2018年，<a class="ae ne" href="https://arxiv.org/pdf/1810.04805.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1810.04805.pdf</a></p><p id="237c" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[5] Rada Mihalcea，Paul Tarau，《文本等级:将秩序带入文本》，2004年，<a class="ae ne" href="https://web.eecs.umich.edu/~mihalcea/papers/mihalcea.emnlp04.pdf" rel="noopener ugc nofollow" target="_blank">https://web . eecs . umich . edu/~ Mihalcea/papers/Mihalcea . em NLP 04 . pdf</a></p><p id="66de" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">[6] Songrit Maneewongvatana，David M. Mount，“聚类点集的近似最近邻搜索分析”，1999年，<a class="ae ne" href="https://arxiv.org/pdf/cs/9901013.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/cs/9901013.pdf</a></p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><p id="e6bf" class="pw-post-body-paragraph lq lr it ls b lt mm ju lv lw mn jx ly lz mo mb mc md mp mf mg mh mq mj mk ml im bi translated">为了无限制地访问Medium上的所有文章，<a class="ae ne" href="https://robgon.medium.com/membership" rel="noopener">成为会员</a>，每月支付5美元。非会员每月只能看三个锁定的故事。</p></div></div>    
</body>
</html>