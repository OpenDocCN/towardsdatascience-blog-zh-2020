<html>
<head>
<title>Deploying a TensorFlow Model to Production made Easy.</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">轻松将TensorFlow模型部署到生产环境中。</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploying-a-tensorflow-model-to-production-made-easy-4736b2437103?source=collection_archive---------11-----------------------#2020-10-14">https://towardsdatascience.com/deploying-a-tensorflow-model-to-production-made-easy-4736b2437103?source=collection_archive---------11-----------------------#2020-10-14</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="5d2a" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">使用TensorFlow服务将深度学习模型部署到生产中。</h2></div><p id="fca5" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">学习使用TensorFlow服务将TensorFlow模型逐步部署到生产中。</em>T3】</strong></p><p id="b71d" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您使用Tensorflow创建了一个深度学习模型，对模型进行了微调以获得更好的准确性和精确度，现在想要将您的模型部署到生产中，供用户使用它来进行预测。</p><p id="45cb" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">将您的模型投入生产的最佳方式是什么？</em> </strong></p><blockquote class="lf"><p id="92e6" class="lg lh it bd li lj lk ll lm ln lo ld dk translated">快速、灵活地部署TensorFlow深度学习模型的方法是使用高性能和高度可扩展的服务系统——tensor flow服务</p></blockquote><p id="b95e" class="pw-post-body-paragraph ki kj it kk b kl lp ju kn ko lq jx kq kr lr kt ku kv ls kx ky kz lt lb lc ld im bi translated">TensorFlow服务使您能够</p><ul class=""><li id="4ac4" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated"><strong class="kk iu">轻松管理您的模型的多个版本，如实验版或稳定版。</strong></li><li id="1b54" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">保持您的服务器架构和API不变</strong></li><li id="1321" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">动态发现TensorFlow流模型的新版本，并使用一致的API结构</strong><a class="ae mi" href="https://www.grpc.io/" rel="noopener ugc nofollow" target="_blank"><strong class="kk iu">gRPC</strong></a><strong class="kk iu">(远程过程协议)为其服务</strong>。</li><li id="e8ee" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">所有客户通过集中模型位置进行推理的一致体验</strong></li></ul><p id="0893" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"><em class="le">tensor flow服务的哪些组件使部署到生产变得容易？</em>T25】</strong></p><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi mj"><img src="../Images/81f1fdff3f22596081890b247a48c682.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zkHC1-ayVTIkxNSwdFqJjg.png"/></div></div><p class="mv mw gj gh gi mx my bd b be z dk translated">张量流服务架构</p></figure><p id="4169" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">TF服务的主要组成部分包括</p><ul class=""><li id="fd72" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated"><strong class="kk iu">Servables</strong>:<strong class="kk iu">Servable是一个底层对象，客户端使用它来执行计算或推理</strong>。TensorFlow服务将深度学习模型表示为一个或多个服务对象。</li><li id="9c67" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">加载器</strong> : <strong class="kk iu">管理服务程序的生命周期</strong>，因为服务程序不能管理自己的生命周期。加载器<strong class="kk iu">标准化用于加载和卸载服务的API，</strong>独立于特定的学习算法。</li><li id="9988" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu"> Source </strong> : <strong class="kk iu">寻找并提供servable，然后为servable的每个版本提供一个Loader实例。</strong></li><li id="17d1" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">管理者</strong> : <strong class="kk iu">管理服务对象的整个生命周期:加载服务对象，服务服务对象，卸载服务对象</strong>。</li><li id="61fe" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu"> TensorFlow Core:通过将加载程序和可服务程序作为不透明对象来管理可服务程序的生命周期和指标</strong></li></ul><p id="9c5a" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">假设您有一个模型的两个不同版本，版本1和版本2。</p><ul class=""><li id="e3c2" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated">客户端通过显式地指定模型的版本或者仅仅请求模型的最新版本来进行API调用。</li><li id="bf01" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">管理器监听源代码，并跟踪Servable的所有版本；然后，它应用已配置的版本策略来确定应该加载或卸载哪个版本的模型，然后让我们加载适当的版本。</li><li id="b3e0" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">加载器包含加载Servable的所有元数据。</li><li id="2cce" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">源插件将为Servable的每个版本创建一个Loader实例。</li><li id="3a92" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">源对管理器进行回调，通知加载器的期望版本被加载，并将其提供给客户端。</li><li id="52ff" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">每当源检测到Servable的新版本时，它会创建一个加载器，指向磁盘上的Servable。</li></ul><p id="a7f4" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><strong class="kk iu"> <em class="le">如何在Windows 10上部署使用Tensorflow服务的深度学习模型？</em> </strong></p><p id="6236" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">对于Windows 10，我们将使用TensorFlow服务图像。</p><h2 id="4cce" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated">第一步:<a class="ae mi" href="https://docs.docker.com/docker-for-windows/install-windows-home/" rel="noopener ugc nofollow" target="_blank">安装Docker App </a></h2><h2 id="dcf4" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated">步骤2:提取TensorFlow服务图像</h2><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="4098" class="mz na it nt b gy nx ny l nz oa"><strong class="nt iu">docker pull tensorflow/serving</strong></span></pre><p id="a379" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">一旦你有了张量流服务图像</p><ul class=""><li id="1845" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated">端口8500对gRPC开放</li><li id="2d7c" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">端口8501是为REST API公开的</li><li id="29a8" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">可选环境变量<code class="fe ob oc od nt b"><strong class="kk iu">MODEL_NAME</strong></code>(默认为<code class="fe ob oc od nt b">model</code>)</li><li id="c0bc" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">可选环境变量<code class="fe ob oc od nt b"><strong class="kk iu">MODEL_BASE_PATH</strong></code>(默认为<code class="fe ob oc od nt b">/models</code>)</li></ul><h2 id="bc27" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated">步骤3:创建并训练模型</h2><p id="a4cd" class="pw-post-body-paragraph ki kj it kk b kl oe ju kn ko of jx kq kr og kt ku kv oh kx ky kz oi lb lc ld im bi translated">这里，我从张量流数据集中提取了MNIST数据集</p><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="8664" class="mz na it nt b gy nx ny l nz oa">#Importing required libraries<br/><strong class="nt iu">import os<br/>import json<br/>import tempfile<br/>import requests<br/>import numpy as np<br/>import tensorflow as tf<br/>import tensorflow_datasets as tfds</strong></span><span id="c298" class="mz na it nt b gy oj ny l nz oa">#Loading MNIST train and test dataset<br/>#<!-- -->as_supervised=True<!-- -->, will return <!-- -->tuple<!-- --> instead of a dictionary for <!-- -->image<!-- --> and <!-- -->label<br/><strong class="nt iu">(ds_train, ds_test), ds_info = tfds.load("mnist", split=['train','test'], with_info=True, as_supervised=True)</strong></span><span id="cb23" class="mz na it nt b gy oj ny l nz oa">#to select the 'image' and 'label' using indexing coverting train and test dataset to a <!-- -->numpy<!-- --> array<br/><strong class="nt iu">array = np.vstack(tfds.as_numpy(ds_train))<br/>X_train = np.array(list(map(lambda x: x[0], array)))<br/>y_train = np.array(list(map(lambda x: x[1], array)))<br/>X_test = np.array(list(map(lambda x: x[0], array)))<br/>y_test = np.array(list(map(lambda x: x[1], array)))</strong></span><span id="b167" class="mz na it nt b gy oj ny l nz oa">#setting batch_size and epochs<br/><strong class="nt iu">epoch=10<br/>batch_size=128</strong></span><span id="1590" class="mz na it nt b gy oj ny l nz oa">#Creating input data pipeline for train and test dataset<br/># Function to normalize the images</span><span id="522d" class="mz na it nt b gy oj ny l nz oa"><strong class="nt iu">def normalize_image(image, label):<br/>  #Normalizes images from uint8` to float32<br/>  return tf.cast(image, tf.float32) / 255., label</strong></span><span id="b1a7" class="mz na it nt b gy oj ny l nz oa"># Input data pipeline for test dataset<br/>#Normalize the image using map function then cache and shuffle the #train dataset <br/># Create a batch of the training dataset and then prefecth for #overlapiing image preprocessing(producer) and model execution work #(consumer)</span><span id="94d8" class="mz na it nt b gy oj ny l nz oa"><strong class="nt iu">ds_train = ds_train.map(<br/>    normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)<br/>ds_train = ds_train.cache()<br/>ds_train = ds_train.shuffle(ds_info.splits['train'].num_examples)<br/>ds_train = ds_train.batch(batch_size)<br/>ds_train = ds_train.prefetch(tf.data.experimental.AUTOTUNE)</strong></span><span id="af77" class="mz na it nt b gy oj ny l nz oa"># Input data pipeline for test dataset (No need to shuffle the test #dataset)<br/><strong class="nt iu">ds_test = ds_test.map(<br/>    normalize_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)<br/>ds_test = ds_test.batch(batch_size)<br/>ds_test = ds_test.cache()<br/>ds_test = ds_test.prefetch(tf.data.experimental.AUTOTUNE)</strong></span><span id="77e9" class="mz na it nt b gy oj ny l nz oa"># Build the model<br/><strong class="nt iu">model = tf.keras.models.Sequential([<br/>  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),<br/>  tf.keras.layers.Dense(128,activation='relu'),<br/>  tf.keras.layers.Dense(196, activation='softmax')<br/>])</strong></span><span id="62cf" class="mz na it nt b gy oj ny l nz oa">#Compile the model<br/><strong class="nt iu">model.compile(<br/>    loss='sparse_categorical_crossentropy',<br/>    optimizer=tf.keras.optimizers.Adam(0.001),<br/>    metrics=['accuracy'],)</strong></span><span id="86b8" class="mz na it nt b gy oj ny l nz oa">#Fit the model<br/><strong class="nt iu">model.fit(<br/>    ds_train,<br/>    epochs=epoch,<br/>    validation_data=ds_test,<br/>    verbose=2)</strong></span></pre><h2 id="31de" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated"><strong class="ak">第四步:保存模型</strong></h2><p id="e08c" class="pw-post-body-paragraph ki kj it kk b kl oe ju kn ko of jx kq kr og kt ku kv oh kx ky kz oi lb lc ld im bi translated">通过将save_format指定为“tf”将模型保存到协议缓冲文件中。</p><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="129f" class="mz na it nt b gy nx ny l nz oa"><strong class="nt iu">MODEL_DIR='tf_model'<br/>version = "1"<br/>export_path = os.path.join(MODEL_DIR, str(version))</strong></span><span id="fc1a" class="mz na it nt b gy oj ny l nz oa">#Save the model <br/><strong class="nt iu">model.save(export_path, save_format="tf")<br/>print('\nexport_path = {}'.format(export_path))<br/>!dir {export_path}</strong></span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/c5a7c42137873ed2e8dc8ba2cae0b775.png" data-original-src="https://miro.medium.com/v2/resize:fit:830/format:webp/1*Y3KMg7S-jWTw55EkBQ7kqg.png"/></div></figure><p id="6afe" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">当我们保存模型的一个版本时，我们可以看到包含文件的以下目录:</p><ul class=""><li id="9f78" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated"><strong class="kk iu"> Saved_model.pb </strong>:包含一个或多个模型的序列化图形定义，以及作为MetaGraphDef协议缓冲区的模型元数据。权重和变量存储在单独的检查点文件中。</li><li id="bd9f" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated"><strong class="kk iu">变量</strong>:保存标准训练检查点的文件</li></ul><p id="3117" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">您可以使用<strong class="kk iu"><em class="le">saved _ model _ CLI</em></strong>命令检查模型。</p><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="6497" class="mz na it nt b gy nx ny l nz oa"><strong class="nt iu">!saved_model_cli show --dir {export_path} --all</strong></span></pre><h2 id="b020" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated">步骤5:使用Tensorflow服务为模型提供服务</h2><p id="a1f3" class="pw-post-body-paragraph ki kj it kk b kl oe ju kn ko of jx kq kr og kt ku kv oh kx ky kz oi lb lc ld im bi translated">打开Windows Powershell并执行以下命令来启动TensorFlow服务容器，以便使用REST API端口为TensorFlow模型提供服务。</p><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="dd11" class="mz na it nt b gy nx ny l nz oa"><strong class="nt iu">docker run -p 8501:8501 --mount type=bind,source=C:\TF_serving\tf_model,target=/models/mnist/ -e MODEL_NAME=mnist -t tensorflow/serving</strong> </span></pre><p id="ac27" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">用Docker成功服务TensorFlow模型。</p><ul class=""><li id="b784" class="lu lv it kk b kl km ko kp kr lw kv lx kz ly ld lz ma mb mc bi translated">使用-p打开端口8501为模型提供服务</li><li id="c0c7" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">Mount将绑定模型基路径，该路径应该是保存模型的容器位置的绝对路径。</li><li id="1766" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">通过指定MODEL_NAME，客户端将用来调用的模型的名称</li><li id="d85f" class="lu lv it kk b kl md ko me kr mf kv mg kz mh ld lz ma mb mc bi translated">使用-t选项分配一个伪终端“tensorflow/serving”</li></ul><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi ol"><img src="../Images/d1ddf12869ba14bfc25d1ac11b9b4150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lkoOXcq0OvxEUt-vKRE7-w.png"/></div></div><p class="mv mw gj gh gi mx my bd b be z dk translated">docker run命令的输出</p></figure><h2 id="a219" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated">步骤6:请求模型预测一个REST</h2><p id="fb92" class="pw-post-body-paragraph ki kj it kk b kl oe ju kn ko of jx kq kr og kt ku kv oh kx ky kz oi lb lc ld im bi translated">我们将创建一个JSON对象来传递预测数据。</p><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="a7c1" class="mz na it nt b gy nx ny l nz oa">#Create JSON Object<br/><strong class="nt iu">data = json.dumps({“signature_name”: “serving_default”, “instances”: X_test[:20].tolist()})</strong></span></pre><p id="2088" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">请求模型的predict方法作为对服务器的REST端点的POST。</p><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="470e" class="mz na it nt b gy nx ny l nz oa"><strong class="nt iu">headers = {"content-type": "application/json"}<br/>json_response = requests.post('</strong><a class="ae mi" href="http://localhost:8501/v1/models/mnist:predict'" rel="noopener ugc nofollow" target="_blank"><strong class="nt iu">http://localhost:8501/v1/models/mnist:predict'</strong></a><strong class="nt iu">, data=data, headers=headers)</strong></span><span id="6e18" class="mz na it nt b gy oj ny l nz oa"><strong class="nt iu">predictions = json.loads(json_response.text)['predictions']</strong></span></pre><p id="f516" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">检验预测的准确性</p><pre class="mk ml mm mn gt ns nt nu nv aw nw bi"><span id="2e9a" class="mz na it nt b gy nx ny l nz oa"><strong class="nt iu">pred=[ np.argmax(predictions[p]) for p in range(len(predictions)) ]<br/>print("Predictions: ",pred)<br/>print("Actual:      ",y_test[:20].tolist())</strong></span></pre><figure class="mk ml mm mn gt mo gh gi paragraph-image"><div role="button" tabindex="0" class="mp mq di mr bf ms"><div class="gh gi om"><img src="../Images/a473d77a66a0a148bd79ec4ed34faea0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T6rMZNyGtWyileihh_XV-w.png"/></div></div></figure><p id="169f" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated">在下一篇文章中，我们将探索不同的模型服务器配置。</p><h2 id="2185" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated">结论:</h2><p id="aa12" class="pw-post-body-paragraph ki kj it kk b kl oe ju kn ko of jx kq kr og kt ku kv oh kx ky kz oi lb lc ld im bi translated">TensorFlow服务是一种快速、灵活、高度可扩展且易于使用的方式，使用一致的gRPC或REST APIs为您的生产模型提供服务。</p><h2 id="608a" class="mz na it bd nb nc nd dn ne nf ng dp nh kr ni nj nk kv nl nm nn kz no np nq nr bi translated">参考资料:</h2><div class="on oo gp gr op oq"><a href="https://www.tensorflow.org/tfx/guide/serving" rel="noopener  ugc nofollow" target="_blank"><div class="or ab fo"><div class="os ab ot cl cj ou"><h2 class="bd iu gy z fp ov fr fs ow fu fw is bi translated">服务模型| TFX | TensorFlow</h2><div class="ox l"><h3 class="bd b gy z fp ov fr fs ow fu fw dk translated">TensorFlow服务是一个灵活、高性能的机器学习模型服务系统，专为生产…</h3></div><div class="oy l"><p class="bd b dl z fp ov fr fs ow fu fw dk translated">www.tensorflow.org</p></div></div><div class="oz l"><div class="pa l pb pc pd oz pe mt oq"/></div></div></a></div><p id="7fa2" class="pw-post-body-paragraph ki kj it kk b kl km ju kn ko kp jx kq kr ks kt ku kv kw kx ky kz la lb lc ld im bi translated"><a class="ae mi" href="https://www.tensorflow.org/tfx/tutorials/serving/rest_simple#make_rest_requests" rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/tfx/tutorials/serving/rest _ simple # make _ rest _ requests</a></p></div></div>    
</body>
</html>