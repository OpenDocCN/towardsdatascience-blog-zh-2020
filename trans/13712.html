<html>
<head>
<title>Create A Simple Search Engine Using Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Python创建一个简单的搜索引擎</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/create-a-simple-search-engine-using-python-412587619ff5?source=collection_archive---------2-----------------------#2020-09-21">https://towardsdatascience.com/create-a-simple-search-engine-using-python-412587619ff5?source=collection_archive---------2-----------------------#2020-09-21</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><figure class="is it gp gr iu iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi ir"><img src="../Images/3fbb7ee6e196dd739172c4f3449cbcfd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2tC5dX-wI3fagApBeAFRnw.jpeg"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">由<a class="ae jg" href="https://unsplash.com/s/photos/information?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的<a class="ae jg" href="https://unsplash.com/@freegraphictoday?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank">absolute vision</a>拍摄</p></figure><div class=""/><div class=""><h2 id="8f0d" class="pw-subtitle-paragraph kg ji jj bd b kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx dk translated">基于余弦相似度和TF-IDF加权的术语-文档矩阵的信息检索。</h2></div><p id="c0a1" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们所有人每天都在使用搜索引擎，例如谷歌，来搜索一切，甚至是简单的东西。但是你有没有想过，搜索引擎是如何根据我们想要搜索(查询)的内容来检索我们所有的文档的？</p><p id="fe05" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">在本文中，我将向您展示如何使用Python及其支持库从头构建一个简单的搜索引擎。在你看完文章后，我希望你能明白如何根据自己的需要来构建自己的搜索引擎。没有进一步，我们走吧！</p><blockquote class="lu lv lw"><p id="fed5" class="ky kz lx la b lb lc kk ld le lf kn lg ly li lj lk lz lm ln lo ma lq lr ls lt im bi translated"><strong class="la jk">边注:</strong>我还创建了一个代码的笔记本，所以如果你想跟着我，你可以点击这个链接<a class="ae jg" href="https://colab.research.google.com/drive/1LNB053OAFBgK5xmMy9GwMxY77R9aqO-0#scrollTo=memATAT_6CtF" rel="noopener ugc nofollow" target="_blank">这里</a>。此外，我将使用的文件是在印度尼西亚。但是不用担心，你可以使用任何语言的文档。</p></blockquote></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="53ca" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">概述</h1><p id="60e4" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">在我们动手之前，让我告诉你如何实现它的步骤，在每一部分，我将解释如何构建它。他们是，</p><ul class=""><li id="abaf" class="nf ng jj la b lb lc le lf lh nh ll ni lp nj lt nk nl nm nn bi translated">准备文件</li><li id="7eac" class="nf ng jj la b lb no le np lh nq ll nr lp ns lt nk nl nm nn bi translated">使用TF-IDF权重创建术语-文档矩阵</li><li id="b6a4" class="nf ng jj la b lb no le np lh nq ll nr lp ns lt nk nl nm nn bi translated">使用余弦相似度计算查询和文档之间的相似度</li><li id="a8f2" class="nf ng jj la b lb no le np lh nq ll nr lp ns lt nk nl nm nn bi translated">检索相似度最高的文章。</li></ul></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="9949" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">该过程</h1><h2 id="dc3f" class="nt mj jj bd mk nu nv dn mo nw nx dp ms lh ny nz mu ll oa ob mw lp oc od my oe bi translated">取回文件</h2><p id="a2d3" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">我们要做的第一件事是从网上检索文件。在这种情况下，我们可以使用web抓取从网站中提取文档。我会从<a class="ae jg" href="https://colab.research.google.com/drive/1LNB053OAFBgK5xmMy9GwMxY77R9aqO-0#scrollTo=memATAT_6CtF" rel="noopener ugc nofollow" target="_blank">kompas.com</a>搜集体育类的文件，尤其是关于流行的文章。由于文档使用的是HTML格式，我们初始化了一个BeautifulSoup对象来解析HTML文件，这样我们就可以更容易地提取我们想要的每个元素。</p><p id="5ca2" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">根据下图，我展示了带有inspect元素的网站截图。在图1中，我已经展示了我们想要检索的标签，这是带有类“most__link”的突出显示的<a>标签的href属性。在图2中，我们将使用类“read__content”从<div>标签中检索<p>标签上的文本。</p></div></a></p><div class="of og oh oi gt ab cb"><figure class="oj iv ok ol om on oo paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/771d6264a6c0c3121ee27e6708ecdd57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*bGT4ejp_f_-7saaCtlWPCA.png"/></div></figure><figure class="oj iv op ol om on oo paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/0dbcc14f44d6759d5e770c3272f37ac6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*GJAP0mHFXc4JRG4Nn0gd6A.png"/></div><p class="jc jd gj gh gi je jf bd b be z dk oq di or os translated">图1，图2</p></figure></div><p id="7442" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">下面是我用来提取文档的代码以及每行的解释，</p><pre class="of og oh oi gt ot ou ov ow aw ox bi"><span id="abbe" class="nt mj jj ou b gy oy oz l pa pb">import requests<br/>from bs4 import BeautifulSoup</span><span id="d921" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Make a request to the website</strong><br/>r = requests.get('<a class="ae jg" href="https://bola.kompas.com/'" rel="noopener ugc nofollow" target="_blank">https://bola.kompas.com/'</a>)</span><span id="1b30" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Create an object to parse the HTML format</strong><br/>soup = BeautifulSoup(r.content, 'html.parser')</span><span id="7153" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Retrieve all popular news links (Fig. 1)</strong><br/>link = []<br/>for i in soup.find('div', {'class':'most__wrap'}).find_all('a'):<br/>    i['href'] = i['href'] + '?page=all'<br/>    link.append(i['href'])</span><span id="64fe" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># For each link, we retrieve paragraphs from it, combine each</strong> paragraph as one string, and save it to documents (Fig. 2)<br/>documents = []<br/>for i in link:<br/><strong class="ou jk">    # Make a request to the link</strong><br/>    r = requests.get(i)<br/>  <br/>    <strong class="ou jk"># Initialize BeautifulSoup object to parse the content</strong> <br/>    soup = BeautifulSoup(r.content, 'html.parser')<br/>  <br/>    <strong class="ou jk"># Retrieve all paragraphs and combine it as one</strong><br/>    sen = []<br/>    for i in soup.find('div', {'class':'read__content'}).find_all('p'):<br/>        sen.append(i.text)<br/>  <br/>    <strong class="ou jk"># Add the combined paragraphs to documents</strong><br/>    documents.append(' '.join(sen))</span></pre><h2 id="90d5" class="nt mj jj bd mk nu nv dn mo nw nx dp ms lh ny nz mu ll oa ob mw lp oc od my oe bi translated">清理文件</h2><p id="718a" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">就在我们提取文档之后，我们必须清理它，这样我们的检索过程就变得容易多了。对于每个文档，我们必须删除所有不必要的单词、数字和标点符号，将单词小写，并删除加倍的空格。这是它的代码，</p><pre class="of og oh oi gt ot ou ov ow aw ox bi"><span id="f0bd" class="nt mj jj ou b gy oy oz l pa pb">import re</span><span id="8736" class="nt mj jj ou b gy pc oz l pa pb">documents_clean = []<br/>for d in documents:<br/>    <strong class="ou jk"># Remove Unicode</strong><br/>    document_test = re.sub(r'[^\x00-\x7F]+', ' ', d)<br/>    <strong class="ou jk"># Remove Mentions</strong><br/>    document_test = re.sub(r'@\w+', '', document_test)<br/>    <strong class="ou jk"># Lowercase the document</strong><br/>    document_test = document_test.lower()<br/>    <strong class="ou jk"># Remove punctuations</strong><br/>    document_test = re.sub(r'[%s]' % re.escape(string.punctuation), ' ', document_test)<br/>    <strong class="ou jk"># Lowercase the numbers</strong><br/>    document_test = re.sub(r'[0-9]', '', document_test)<br/>    <strong class="ou jk"># Remove the doubled space</strong><br/>    document_test = re.sub(r'\s{2,}', ' ', document_test)<br/>    documents_clean.append(document_test)</span></pre><h2 id="e8d6" class="nt mj jj bd mk nu nv dn mo nw nx dp ms lh ny nz mu ll oa ob mw lp oc od my oe bi translated">使用TF-IDF权重创建术语-文档矩阵</h2><p id="2293" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">每个文档都清理干净后，就该创建一个矩阵了。谢天谢地，scikit-learn库已经为我们准备了它的代码，所以我们不必从头开始实现它。代码看起来像这样，</p><pre class="of og oh oi gt ot ou ov ow aw ox bi"><span id="b40d" class="nt mj jj ou b gy oy oz l pa pb">from sklearn.feature_extraction.text import TfidfVectorizer</span><span id="cbd0" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Instantiate a TfidfVectorizer object<br/></strong>vectorizer = TfidfVectorizer()</span><span id="91bb" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># It fits the data and transform it as a vector<br/></strong>X = vectorizer.fit_transform(docs)</span><span id="3c52" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Convert the X as transposed matrix<br/></strong>X = X.T.toarray()</span><span id="545e" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Create a DataFrame and set the vocabulary as the index<br/></strong>df = pd.DataFrame(X, index=vectorizer.get_feature_names())</span></pre><p id="d5ea" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">结果(矩阵)将成为文档的表示。通过使用这个矩阵，我们可以找到不同文档之间的相似性。矩阵看起来像这样，</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pd"><img src="../Images/dc887353c62b73b8f5c80a266bd59019.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SLZzBUOAaVCIRBfwA5YzpQ.png"/></div></div><p class="jc jd gj gh gi je jf bd b be z dk translated">术语-文档矩阵</p></figure><p id="1a70" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">上面的矩阵被称为术语-文档矩阵。它由所有文档中每个标记(术语)代表的行组成，列由文档的标识符组成。单元格内是每个词的频率数，用某个数字加权。</p><p id="624c" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">我们将使用列向量，这是一个表示每个文档的向量，用于计算与给定查询的相似性。我们可以称这个向量为<strong class="la jk">嵌入</strong>。</p><p id="a9d5" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">为了计算单元格值，代码使用TF-IDF方法来完成此操作。TF-IDF(术语频率-逆文档频率)是由IDF加权的词的频率。让我解释一下每一个，</p><p id="d7e3" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated"><strong class="la jk">术语频率(TF) </strong>是术语(t)在文档(d)上的频率。公式看起来像这样，</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="gh gi pe"><img src="../Images/11a30426d0992ddfe2ba0b5cc44c3de1.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/format:webp/1*p8jtFaKJuPCawI0pgnm8Wg.png"/></div></div></figure><p id="ce80" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">除此之外，我们可以使用基数为10的对数来计算TF，因此数字变得更小，计算过程变得更快。此外，请确保在它上面添加一个，因为我们不希望log 0存在。</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div class="gh gi pf"><img src="../Images/3f1d4d2fbf4ff668bd2529a20366645e.png" data-original-src="https://miro.medium.com/v2/resize:fit:664/format:webp/1*p7uI7EBIFMXoncaegK0TyA.png"/></div></figure><p id="e6e6" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">然后，就是<strong class="la jk">逆文档频率(IDF) </strong>。此公式将用于计算该单词在所有文档中的稀有度。它将被用作TF的权重。如果一个词比较频繁，那么IDF就会小一些。相反，如果这个词用得不频繁，那么IDF就会更大。公式看起来像这样，</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div class="gh gi pg"><img src="../Images/1e3d056c586d8033e5d8424b4058ecda.png" data-original-src="https://miro.medium.com/v2/resize:fit:436/format:webp/1*If2tWOjX4eWjwPhSv9T7mQ.png"/></div></figure><p id="4121" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">回想一下TF-IDF，我们可以看到它是如何影响每个单元格上的值的。它将删除文档中频繁出现但同时并不重要的所有单词，如and、or、even、actually等。基于此，我们用它作为矩阵中每个单元格的值。</p><h2 id="336f" class="nt mj jj bd mk nu nv dn mo nw nx dp ms lh ny nz mu ll oa ob mw lp oc od my oe bi translated">使用余弦相似度计算相似度。</h2><p id="ea2e" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">创建矩阵后，我们可以准备查询，根据文档和查询之间的最高相似度来查找文章。要计算相似度，我们可以使用余弦相似度公式来完成。它看起来像这样，</p><figure class="of og oh oi gt iv gh gi paragraph-image"><div class="gh gi ph"><img src="../Images/a43207d7f4c96f0e37a5b653407d7a4a.png" data-original-src="https://miro.medium.com/v2/resize:fit:488/format:webp/1*wvO7H35GJTcQ8xt4_IzXOg.png"/></div></figure><p id="5052" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">该公式计算点积除以每个向量上长度的乘积。该值的范围是从[1，0]，但一般来说，余弦值的范围是从[-1，1]。因为上面没有负值，所以我们可以忽略负值，因为它从来没有发生过。</p><p id="021b" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">现在，我们将实现代码来基于查询查找文档的相似性。我们要做的第一件事是将查询转换成矩阵上的向量。然后，我们计算它们之间的相似度。最后，我们检索相似度值大于0的所有文档。代码看起来像这样，</p><pre class="of og oh oi gt ot ou ov ow aw ox bi"><span id="5416" class="nt mj jj ou b gy oy oz l pa pb">def get_similar_articles(q, df):<br/>  print("query:", q)<br/>  print("Berikut artikel dengan nilai cosine similarity tertinggi: ")</span><span id="897e" class="nt mj jj ou b gy pc oz l pa pb">  <strong class="ou jk"># Convert the query become a vector</strong><br/>  q = [q]<br/>  q_vec = vectorizer.transform(q).toarray().reshape(df.shape[0],)<br/>  sim = {}</span><span id="a0dd" class="nt mj jj ou b gy pc oz l pa pb">  <strong class="ou jk"># Calculate the similarity</strong><br/>  for i in range(10):<br/>    sim[i] = np.dot(df.loc[:, i].values, q_vec) / np.linalg.norm(df.loc[:, i]) * np.linalg.norm(q_vec)<br/>  <br/>  <strong class="ou jk"># Sort the values </strong><br/>  sim_sorted = sorted(sim.items(), key=lambda x: x[1], reverse=True)</span><span id="ce43" class="nt mj jj ou b gy pc oz l pa pb">  <strong class="ou jk"># Print the articles and their similarity values</strong><br/>  for k, v in sim_sorted:<br/>    if v != 0.0:<br/>      print("Nilai Similaritas:", v)<br/>      print(docs[k])<br/>      print()</span><span id="9cba" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Add The Query</strong><br/>q1 = 'barcelona'</span><span id="7da5" class="nt mj jj ou b gy pc oz l pa pb"><strong class="ou jk"># Call the function</strong><br/>get_similar_articles(q1, df)</span></pre><p id="bd35" class="pw-post-body-paragraph ky kz jj la b lb lc kk ld le lf kn lg lh li lj lk ll lm ln lo lp lq lr ls lt im bi translated">假设我们想找到关于巴塞罗那的文章。如果我们基于此运行代码，我们会得到这样的结果，</p><pre class="of og oh oi gt ot ou ov ow aw ox bi"><span id="0918" class="nt mj jj ou b gy oy oz l pa pb">query: barcelona<br/>Berikut artikel dengan nilai cosine similarity tertinggi:<br/>Nilai Similaritas: 0.4641990113096689<br/> kompas com perombakan skuad yang dilakukan pelatih anyar barcelona ronald koeman memakan korban baru terkini ronald koeman dikabarkan akan mendepak bintang muda barcelona yang baru berusia tahun riqui puig menurut media spanyol rac koeman sudah meminta riqui puig mencari tim baru karena tidak masuk dalam rencananya di barcelona rumor itu semakin kuat karena puig....</span><span id="159a" class="nt mj jj ou b gy pc oz l pa pb">Nilai Similaritas: 0.4254860197361395<br/>kompas com pertandingan trofeo joan gamper mempertemukan barcelona dengan salah satu tim promosi liga spanyol elche laga barcelona vs elche usai digelar di camp nou pada minggu dini hari wib trofeo joan gamper merupakan laga tahunan yang diadakan oleh barca kali ini sudah memasuki edisi ke blaugrana julukan tuan rumah menang dengan skor gol kemenangan barcelona....</span></pre></div><div class="ab cl mb mc hx md" role="separator"><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg mh"/><span class="me bw bk mf mg"/></div><div class="im in io ip iq"><h1 id="a751" class="mi mj jj bd mk ml mm mn mo mp mq mr ms kp mt kq mu ks mv kt mw kv mx kw my mz bi translated">最后的想法</h1><p id="2e44" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">这就是我们如何使用Python及其依赖项创建一个简单的搜索引擎。它仍然非常基础，但我希望你能从这里学到一些东西，并能根据你的需要实现你自己的搜索引擎。谢谢你。</p><h2 id="69e4" class="nt mj jj bd mk nu nv dn mo nw nx dp ms lh ny nz mu ll oa ob mw lp oc od my oe bi translated">参考</h2><p id="b685" class="pw-post-body-paragraph ky kz jj la b lb na kk ld le nb kn lg lh nc lj lk ll nd ln lo lp ne lr ls lt im bi translated">[1] Jurafsky，D. &amp; Martin，j . h .<a class="ae jg" href="https://web.stanford.edu/~jurafsky/slp3/" rel="noopener ugc nofollow" target="_blank"><em class="lx"/></a><em class="lx"/>(2000)，普伦蒂斯霍尔。</p></div></div>    
</body>
</html>