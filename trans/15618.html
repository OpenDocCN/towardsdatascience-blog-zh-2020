<html>
<head>
<title>Combining tree based models with a linear baseline model to improve extrapolation</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">将基于树的模型与线性基线模型相结合以改进外推</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/combining-tree-based-models-with-a-linear-baseline-model-to-improve-extrapolation-c100bd448628?source=collection_archive---------38-----------------------#2020-10-27">https://towardsdatascience.com/combining-tree-based-models-with-a-linear-baseline-model-to-improve-extrapolation-c100bd448628?source=collection_archive---------38-----------------------#2020-10-27</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><h2 id="bfe6" class="io ip iq bd b dl ir is it iu iv iw dk ix translated" aria-label="kicker paragraph"><a class="ae ep" href="https://towardsdatascience.com/tagged/hands-on-tutorials" rel="noopener" target="_blank">实践教程</a></h2><div class=""/><div class=""><h2 id="0362" class="pw-subtitle-paragraph jw iz iq bd b jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn dk translated">编写自己的sklearn函数，第1部分</h2></div><p id="6a6f" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这篇文章是一个简短的介绍，介绍如何结合不同的机器学习模型以达到实用的目的，在它们的优缺点之间找到一个好的平衡。在我们的例子中，我们将集成一个随机森林，一个非常强大的非线性、非参数的基于树的全能者，一个经典的线性回归模型，一个非常容易解释并且可以使用领域知识验证的模型。</p><p id="22fe" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">对于许多问题来说，梯度推进或随机森林是最常用的模型。他们经常<a class="ae lk" href="http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/" rel="noopener ugc nofollow" target="_blank">胜过</a>许多其他模型，因为他们能够学习几乎任何线性或非线性关系。然而，树模型的一个缺点是，它们不能很好地处理新数据，它们通常推断得很差——<a class="ae lk" href="http://freerangestats.info/blog/2016/12/10/extrapolation" rel="noopener ugc nofollow" target="_blank">阅读更多关于这个</a>的内容。出于实际目的，这可能会导致不期望的行为，例如在预测时间、距离或成本时，稍后将对此进行概述。</p><p id="c9ee" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们可以快速验证随机森林模型的sklearn实现可以很好地学习给定范围(0到50)的标识，但是对于训练数据范围之外的值却很失败:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="08e5" class="lu lv iq lq b gy lw lx l ly lz">import numpy as np<br/>import matplotlib.pyplot as plt<br/>import seaborn as sns</span><span id="1b77" class="lu lv iq lq b gy ma lx l ly lz">from sklearn.ensemble import RandomForestRegressor</span><span id="5511" class="lu lv iq lq b gy ma lx l ly lz">model = RandomForestRegressor()</span><span id="f895" class="lu lv iq lq b gy ma lx l ly lz">X = np.arange(0, 100).reshape(-1, 1)<br/>y = np.arange(0, 100)</span><span id="84c8" class="lu lv iq lq b gy ma lx l ly lz"># train on [0, 50]<br/>model.fit(X[:50], y[:50]);</span><span id="737f" class="lu lv iq lq b gy ma lx l ly lz"># predict for [0, 100]<br/>## RandomForestRegressor()<br/>plt.ylim(0, 100);<br/>sns.lineplot(X.reshape(-1,), model.predict(X));<br/>plt.show()</span></pre><figure class="ll lm ln lo gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi mb"><img src="../Images/1f9d32031f11d9c9041ea1a295975793.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GlWZj4XHAh1rRY5F.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">树模型很难预测样本外的图像。</p></figure><p id="eb77" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">与树模型相比，线性模型以不同的方式处理新数据。他们可以很容易地推断预测，但当然也有只学习线性关系的缺点。此外，线性模型允许一个简单的解释，简单地通过查看回归系数，我们实际上可以将其与领域知识进行比较，并实际验证它。</p><p id="abb5" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">因此，对于一些回归问题，将这两种方法结合起来是有意义的，我们可以用一个例子来详细说明:假设我们想要使用历史数据(包含车辆类型、距离和行驶时间的数据集)来估计不同车辆相对于行驶距离的行驶时间。我们可能会考虑使用线性或非线性模型，这也取决于我们的预期。如果我们的目标是估计自行车的旅行时间，距离的增加会导致时间的比例变化(如果你骑自行车的时间增加一倍，你可能会旅行两倍的距离)。如果我们训练一个线性模型，它将是一个很好的拟合，并且系数表达了距离和时间之间的比例。</p><p id="5bd7" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">但是线性模型的一个缺点是，它可能很难了解其他车辆类型(如汽车)的时间与距离的关系。如果开车旅行的距离增加，我们可能会走高速公路，而不是更短的距离，所以旅行时间的增加可能不再是线性比例的。在这种情况下，非线性模型会表现得更好。然而，如果我们在观察到的行驶汽车距离上训练非线性树模型，它将在新数据上表现不佳，即看不见的距离:如果我们的训练数据仅包含100公里的汽车行程，则200公里的估计将非常糟糕，而线性模型仍将提供良好的外推估计。</p><p id="b46c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">为了解决这个问题，我们可以通过以下方式用线性模型支持树模型:如果树模型的预测离我们的基线线性模型的预测太远，我们默认使用线性模型预测。因此，对于我们的示例:如果200公里汽车行驶的非线性模型预测是2小时(因为它只看到了2小时的汽车行驶)，但线性模型预测是3小时，我们默认为3小时。然而，如果非线性模型的预测与线性模型的验证预测相差不太远(比如说小于25%)，我们就坚持它(因为我们预期它通常会表现得更好)。</p><h1 id="84b6" class="mn lv iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">编写您自己的组合估计器</h1><p id="90fc" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">在<code class="fe nj nk nl lq b">sklearn</code>中，我们可以通过创建<a class="ae lk" href="http://danielhnyk.cz/creating-your-own-estimator-scikit-learn/" rel="noopener ugc nofollow" target="_blank">我们自己的估计器</a>以下面的方式实现这一点。请注意，这第一个实现还不符合sklearn API标准——我们将在本文末尾根据<a class="ae lk" href="https://scikit-learn.org/stable/developers/develop.html" rel="noopener ugc nofollow" target="_blank">接口</a>改进这个版本。</p><figure class="ll lm ln lo gt mc"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="a957" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们简单地拟合两个估计量，并使用两个估计量进行预测。然后，我们可以比较两种预测，并相应地调整我们的预测。如果在线性预测的一定范围内，我们将采用树模型预测。除了比较两个模型并选择更合理的预测，我们还可以取两个预测的平均值或以不同方式混合它们。此外，我们可以使用网格搜索优化参数<code class="fe nj nk nl lq b">upper</code>和<code class="fe nj nk nl lq b">lower</code>(为此，我们将需要实现一些进一步的方法，如<code class="fe nj nk nl lq b">get_params</code>和<code class="fe nj nk nl lq b">set_params</code>)。</p><p id="c403" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">让我们使用非线性函数<code class="fe nj nk nl lq b">f(x)=x+sqrt(x)+rnorm(0, 3)</code>生成一些样本数据来评估模型:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="4663" class="lu lv iq lq b gy lw lx l ly lz">import pandas as pd</span><span id="ec1f" class="lu lv iq lq b gy ma lx l ly lz">def f(x):<br/>    if isinstance(x, int):<br/>        return np.sqrt(x) + np.random.normal(0, 3)<br/>    else:<br/>        return np.sqrt(x) + np.random.normal(0, 3, len(x))</span><span id="8d1a" class="lu lv iq lq b gy ma lx l ly lz">def generate_data(n=100, x_max=100):<br/>    x = np.random.uniform(0, x_max, n)<br/>    return pd.DataFrame.from_records({'x': x}), f(x)</span></pre><p id="8934" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们现在可以在我们的小样本数据集上训练三个不同的模型:<code class="fe nj nk nl lq b">RandomForestRegressor</code>、<code class="fe nj nk nl lq b">LinearRegression</code>和我们的定制<code class="fe nj nk nl lq b">CombinedRegressor</code>。</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="a14b" class="lu lv iq lq b gy lw lx l ly lz">from sklearn.metrics import mean_absolute_error</span><span id="c53b" class="lu lv iq lq b gy ma lx l ly lz">np.random.seed(100)<br/>X, y = generate_data(n=100)</span><span id="e9a3" class="lu lv iq lq b gy ma lx l ly lz">for model_name, model in models.items():<br/>    print(f'Training {model_name} model.')<br/>    model.fit(X, y);<br/>    print(f'Training score: {model.score(X, y)}')<br/>    print(f'In-sample MAE: {mean_absolute_error(y, model.predict(X))} \n')<br/>## Training tree model.<br/>## RandomForestRegressor()<br/>## Training score: 0.8620816087110539<br/>## In-sample MAE: 1.081361379476639 <br/>## <br/>## Training linear model.<br/>## LinearRegression()<br/>## Training score: 0.28917115492576073<br/>## In-sample MAE: 2.586843328406717 <br/>## <br/>## Training combined model.<br/>## CombinedRegressor()<br/>## Training score: 0.35418433030406293<br/>## In-sample MAE: 2.3593815648352554</span></pre><p id="b504" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">如果我们观察所有三个模型预测和真实值的图(见下文),我们可以很快看到最初讨论的问题:树模型不能真正外推</p><p id="c061" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">正如所料，随机森林模型在样本内平均绝对误差方面表现最佳。现在，如果我们评估样本外(150，而不是训练数据中的最大值100)，事情看起来会有所不同:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="dbe8" class="lu lv iq lq b gy lw lx l ly lz">np.random.seed(101)</span><span id="b10b" class="lu lv iq lq b gy ma lx l ly lz">x = [150]<br/>X_new, y_new = pd.DataFrame({'x': x}), f(x)</span><span id="76d2" class="lu lv iq lq b gy ma lx l ly lz">for model_name, model in models.items():<br/>    y_pred = model.predict(X_new)<br/>    print(f'Testing {model_name} model.')<br/>    print(f'y_new: {y_new}, y_pred: {y_pred}')<br/>    print(f'Test MAE: {mean_absolute_error(y_new, y_pred)} \n')<br/>## Testing tree model.<br/>## y_new: [20.36799823], y_pred: [7.81515835]<br/>## Test MAE: 12.552839880512696 <br/>## <br/>## Testing linear model.<br/>## y_new: [20.36799823], y_pred: [13.39757247]<br/>## Test MAE: 6.970425764867624 <br/>## <br/>## Testing combined model.<br/>## y_new: [20.36799823], y_pred: [13.39757247]<br/>## Test MAE: 6.970425764867624</span></pre><p id="0ed6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">由于不能外推，树模型做得不好，线性模型做得更好，因此由线性回归支持的集合模型做得更好。同时，它仍将在样本内表现良好，并且如果我们大幅增加范围，它将表现良好(仅比树模型好，比线性回归差):</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="efac" class="lu lv iq lq b gy lw lx l ly lz">np.random.seed(102)</span><span id="92c9" class="lu lv iq lq b gy ma lx l ly lz">X_new, y_new = generate_data(n=100, x_max=200)</span><span id="77f4" class="lu lv iq lq b gy ma lx l ly lz">for model_name, model in models.items():<br/>    y_pred = model.predict(X_new)<br/>    print(f'Testing {model_name} model.')<br/>    print(f'Test MAE: {mean_absolute_error(y_new, y_pred)} \n')<br/>## Testing tree model.<br/>## Test MAE: 3.67092130330585 <br/>## <br/>## Testing linear model.<br/>## Test MAE: 2.5770058863460985 <br/>## <br/>## Testing combined model.<br/>## Test MAE: 2.6143623109839984</span></pre><p id="cc8e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们还可以绘制一些随机数据(训练样本内外)的单个预测，并快速查看之前未看到的x值和树模型的初始讨论问题，该问题变平了。线性模型继续趋势，组合版本有不愉快的颠簸，但一旦树模型偏离太多，至少跟随趋势。</p><figure class="ll lm ln lo gt mc gh gi paragraph-image"><div role="button" tabindex="0" class="md me di mf bf mg"><div class="gh gi no"><img src="../Images/60937be33ce51f3981cdf197f2fe1eaf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GkfQ2Ua8eSrANp3o.png"/></div></div><p class="mj mk gj gh gi ml mm bd b be z dk translated">我们不同模型的外推行为——图片由作者完成。</p></figure><h1 id="142a" class="mn lv iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">Sklearn兼容性</h1><p id="9a7f" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">如果我们想实现<a class="ae lk" href="https://scikit-learn.org/stable/developers/develop.html" rel="noopener ugc nofollow" target="_blank">完全sklearn兼容性</a>(型号选择、管道等。)并使用sklearn的机载测试工具，我们必须对估计器进行一些修改:</p><ul class=""><li id="9d7f" class="np nq iq kq b kr ks ku kv kx nr lb ns lf nt lj nu nv nw nx bi translated">我们需要为参数添加setters和getters(我们使用sklearn的约定，用名称和两个下划线作为参数的前缀，即<code class="fe nj nk nl lq b">base_regressor__some_param</code>)</li><li id="96f8" class="np nq iq kq b kr ny ku nz kx oa lb ob lf oc lj nu nv nw nx bi translated">随机状态的一致处理</li></ul><p id="ec8b" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">这可以通过以下方式实现:</p><figure class="ll lm ln lo gt mc"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="8cc3" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">然后，我们可以在我们的自定义估计器上运行超参数网格搜索:</p><figure class="ll lm ln lo gt mc"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="6b3c" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">我们还可以使用<code class="fe nj nk nl lq b">sklearn.utils.estimator_checks</code>工具来检查我们的估计器:</p><figure class="ll lm ln lo gt mc"><div class="bz fp l di"><div class="nm nn l"/></div></figure><p id="94dd" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">在某些情况下，您可能无法满足特定的验证，例如，在这种情况下，您可以将特定检查的返回值伪造为true:</p><pre class="ll lm ln lo gt lp lq lr ls aw lt bi"><span id="758e" class="lu lv iq lq b gy lw lx l ly lz">import mock</span><span id="f8cd" class="lu lv iq lq b gy ma lx l ly lz">from sklearn.utils.estimator_checks import check_estimator</span><span id="4269" class="lu lv iq lq b gy ma lx l ly lz">with mock.patch('sklearn.utils.estimator_checks.check_estimators_data_not_an_array', return_value=True) as mock:<br/>    check_estimator(CombinedRegressor())</span></pre><h1 id="b764" class="mn lv iq bd mo mp mq mr ms mt mu mv mw kf mx kg my ki mz kj na kl nb km nc nd bi translated">包裹</h1><p id="5479" class="pw-post-body-paragraph ko kp iq kq b kr ne ka kt ku nf kd kw kx ng kz la lb nh ld le lf ni lh li lj ij bi translated">如果我们有一个模型，它对一组特定的输入非常有效，但是一旦输入变得更加奇特，我们就会失去信心，那么这种方法就非常有用。在这种情况下，我们可以通过使用更透明的(例如线性)方法，我们可以很容易地与领域知识同步，并保证特定的行为(例如外推、比例增量)。</p><p id="e12e" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated">除了使用组合估计器，我们还可以使用具有更好外推行为的非线性模型，如神经网络。另一种替代方法是向训练数据集添加一些人工样本，以增加支持的响应范围。</p></div><div class="ab cl od oe hu of" role="separator"><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi oj"/><span class="og bw bk oh oi"/></div><div class="ij ik il im in"><p id="42c6" class="pw-post-body-paragraph ko kp iq kq b kr ks ka kt ku kv kd kw kx ky kz la lb lc ld le lf lg lh li lj ij bi translated"><em class="ok">最初发表于</em><a class="ae lk" href="https://blog.telsemeyer.com/2019/10/30/combining-tree-based-modelss-with-a-linear-baseline-model-to-improve-extrapolation-writing-your-own-sklearn-functions-part-1/" rel="noopener ugc nofollow" target="_blank"><em class="ok">【https://blog.telsemeyer.com】</em></a><em class="ok">。</em></p></div></div>    
</body>
</html>