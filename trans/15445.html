<html>
<head>
<title>3 Simple Outlier/Anomaly Detection Algorithms every Data Scientist needs</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">每个数据科学家都需要的3种简单的异常值/异常检测算法</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/3-simple-outlier-anomaly-detection-algorithms-every-data-scientist-needs-e71b1304a932?source=collection_archive---------0-----------------------#2020-10-24">https://towardsdatascience.com/3-simple-outlier-anomaly-detection-algorithms-every-data-scientist-needs-e71b1304a932?source=collection_archive---------0-----------------------#2020-10-24</a></blockquote><div><div class="fc ih ii ij ik il"/><div class="im in io ip iq"><div class=""/><div class=""><h2 id="351b" class="pw-subtitle-paragraph jq is it bd b jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh dk translated">深入了解异常值检测，以及如何在Python中实现3种简单、直观且强大的异常值检测算法</h2></div><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/7cd39a29ff424d8fd576452525b06a03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_2lzJN_AOfAvi2kdhQy82w.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">斯科特拍摄的照片。在<a class="ae ky" href="https://www.flickr.com/photos/31673483@N00/39151353820/in/photolist-22DEVtJ-JK3N3j-73AeXk-WtscC8-awpTxE-MZx16D-bv51wM-pYJoVx-262n5CX-b7L1uH-uGu7nd-2dmbaVW-XFRM8N-2jKUw4v-d85XWy-2j5aTjR-WNNJAf-pdRgEy-N8MRV6-2j22H6Y-U3xQuk-XES3Zn-r9m7SS-TV1Fmf-2jJ1QFJ-cauLTY-ds31pR-qtMWbF-niZxTj-2hMkNCc-nKi4XA-DowBNs-5yKzFd-2bQqifH-qB9Nvk-oEQ9WG-CRNtRN-hQzL9o-JXxP5u-29Wj4Lj-dGz93P-JKjBGX-2j7NfDg-nDv1WE-8Q1mSc-seYDya-wVPBZN-oZdBXB-2g3uJeP-s6sqJm" rel="noopener ugc nofollow" target="_blank"> Flickr </a>上的T </p></figure><p id="88de" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我相信你已经遇到了以下几种情况:</p><ol class=""><li id="05ac" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">你的模型没有像你希望的那样运行。</li><li id="9af5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">你会不由自主地注意到，有些地方似乎与其他地方大相径庭。</li></ol><p id="dcdd" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">恭喜你，因为你的数据中可能有异常值！</p><h1 id="b180" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">什么是离群值？</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi nb"><img src="../Images/7cd73acc07670a73580c614ec8f35196.png" data-original-src="https://miro.medium.com/v2/resize:fit:638/format:webp/1*qF5JqaqfenZYB68pakIeUg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片可以在<a class="ae ky" href="https://stats.stackexchange.com/questions/328968/is-it-an-outlier/328986" rel="noopener ugc nofollow" target="_blank">证券交易所</a>找到</p></figure><p id="4842" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在统计学中，<strong class="lb iu">异常值</strong>是与其他观察值显著不同的数据点。从上图中，我们可以清楚地看到，虽然大多数点位于线性超平面中或其周围，但可以看到一个点与其他点有所不同。这个点是一个<em class="nc">离群点</em>。</p><p id="d33a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">例如，看看下面的列表:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="893f" class="ni mk it ne b gy nj nk l nl nm">[<strong class="ne iu">1</strong>,35,20,32,40,46,45,<strong class="ne iu">4500</strong>]</span></pre><p id="638f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，很容易看出1和4500是数据集中的异常值。</p><h2 id="6cae" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">为什么我的数据中有异常值？</h2><p id="0df4" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">通常，异常值可能发生在以下情况之一:</p><ol class=""><li id="9143" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">有时它们可能是偶然发生的，可能是因为测量误差。</li><li id="2a41" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">有时它们会出现在数据中，因为数据很少是100%干净的，没有任何异常值。</li></ol><h2 id="f8f0" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">为什么离群值是一个问题？</h2><p id="ea5f" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">以下是几个原因:</p><ol class=""><li id="0bfa" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">线性模型</li></ol><p id="ad2e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">假设你有一些数据，你想用线性回归来预测房价。一个可能的假设可能是这样的:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/114d5585da5d505685eab10c4db0bcb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QWrsxP3wpXLSO_PmDT21rg.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="acf9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这种情况下，我们实际上对数据拟合得太好了(<em class="nc">过拟合</em>)。然而，请注意所有的点是如何位于大致相同的范围。</p><p id="213c" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们看看当我们添加一个离群值时会发生什么。</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi od"><img src="../Images/cadef4f2a020c22bda278f72e35bfa65.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dJlfGmRwZR6-pE7qnBMm7g.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="d481" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">很明显，我们看到我们的假设是如何改变的，因此，推论会比没有异常值时更糟糕。线性模型包括:</p><ul class=""><li id="0601" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu oe mb mc md bi translated">感知器</li><li id="b265" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated">线性+逻辑回归</li><li id="0b98" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated">神经网络</li><li id="3c5c" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated">KNN</li></ul><p id="7b04" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.数据输入</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi of"><img src="../Images/1d7d999b72665721d519aa00263e0c7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Pn98uyPHjwUa0TE_4Fzrpg.jpeg"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated"><a class="ae ky" href="https://unsplash.com/@theeastlondonphotographer?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Ehimetalor Akhere Unuabona </a>在<a class="ae ky" href="https://unsplash.com/s/photos/missing?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>拍摄的照片</p></figure><p id="9cd0" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">一种常见的情况是丢失数据，可以采取以下两种方法之一:</p><ol class=""><li id="d8cc" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">删除缺少行的实例</li><li id="2811" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">使用统计方法估算数据</li></ol><p id="dc13" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">如果我们采用第二种选择，我们可能会有有问题的估算，因为异常值可以极大地改变统计方法的价值。例如，回到我们没有异常值的虚构数据:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="748d" class="ni mk it ne b gy nj nk l nl nm"># Data with no outliers<br/>np.array([35,20,32,40,46,45]).mean() = 36.333333333333336</span><span id="af5a" class="ni mk it ne b gy og nk l nl nm"># Data with 2 outliers<br/>np.array([1,35,20,32,40,46,45,4500]).mean() = 589.875</span></pre><p id="3b80" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">显然这个类比很极端，但是想法是一样的；数据中的异常值通常是一个问题，因为异常值会在统计分析和建模中导致严重的问题。然而，在这篇文章中，我们将研究一些方法来检测和对付它们。</p><h1 id="23d7" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">解决方案1: DBSCAN</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oh"><img src="../Images/87d33c1406a3562dfed5ff1dc46b19e4.png" data-original-src="https://miro.medium.com/v2/resize:fit:440/format:webp/1*h3nkFS_Cc0Lm0PtDNJKy3A.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://en.wikipedia.org/wiki/DBSCAN" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="9990" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">对有噪声的应用程序进行基于密度的空间聚类(或者更简单地说，DBSCAN)实际上是一种无监督的聚类算法，就像KMeans一样。然而，它的用途之一是能够检测数据中的异常值。</p><p id="9e71" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DBSCAN之所以受欢迎，是因为它可以找到非线性可分的聚类，而这是KMeans和高斯混合所做不到的。当集群足够密集并且被低密度区域分隔开时，它工作得很好。</p><h2 id="3314" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">DBSCAN如何工作的高级概述</h2><p id="d4c6" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">该算法将聚类定义为高密度的连续区域。算法非常简单:</p><ol class=""><li id="22fc" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">对于每个实例，它计算有多少实例位于距离它很小的距离ε (epsilon)内。这个区域被称为实例的<em class="nc"> ε-邻域。</em></li><li id="13ad" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">如果实例在其ε-邻域中有超过<strong class="lb iu">个min_samples </strong>实例，那么它被认为是一个<em class="nc">核心实例。</em>这意味着实例位于高密度区域(内部有许多实例的区域)。)</li><li id="473e" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">核心实例的ε-邻域内的所有实例都被分配到同一个集群。这可能包括其他核心实例，因此一长串相邻的核心实例构成一个集群。</li><li id="dab5" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">任何不是核心实例或者不位于任何核心实例的ε-邻域中的实例都是离群值。</li></ol><h2 id="9f6a" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">DBSCAN正在运行</h2><p id="f2db" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">由于Scikit-Learn的直观API，DBSCAN算法非常易于使用。让我们来看一个运行中的算法示例:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="fb06" class="ni mk it ne b gy nj nk l nl nm">from<strong class="ne iu"> </strong>sklearn.cluster import DBSCAN <br/>from sklearn.datasets import<strong class="ne iu"> </strong>make_moons</span><span id="c985" class="ni mk it ne b gy og nk l nl nm">X, y = make_moons(n_samples=1000, noise=0.05)<br/>dbscan = DBSCAN(eps=0.2, min_samples=5)<br/>dbscan.fit(X)</span></pre><p id="9dfe" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们将使用0.05的ε-邻域长度来实例化DBSCAN，5是将一个实例视为核心实例所需的最小样本数</p><p id="cc03" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">记住，我们不传递我们的标签，因为这是一个<em class="nc">无监督算法。</em>我们可以看到标签算法使用以下命令生成的标签:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="29f1" class="ni mk it ne b gy nj nk l nl nm">dbscan.labels_</span><span id="0013" class="ni mk it ne b gy og nk l nl nm">OUT:<br/>array([ 0,  2, -1, -1,  1,  0,  0,  0, ...,  3,  2,  3,  3,  4,  2,  6,  3])</span></pre><p id="499f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">注意一些标签的值等于-1:这些是异常值。</p><p id="b8ba" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">DBSCAN没有预测方法，只有fit_predict方法，这意味着它不能对新实例进行集群。相反，我们可以使用不同的分类器来训练和预测。对于这个例子，让我们使用一个KNN:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="8635" class="ni mk it ne b gy nj nk l nl nm">from sklearn.neighbors import KNeighborsClassifier</span><span id="e19e" class="ni mk it ne b gy og nk l nl nm">knn = KNeighborsClassifier(n_neighbors=50)<br/>knn.fit(dbscan.components_, dbscan.labels_[dbscan.core_sample_indices_])</span><span id="cfbf" class="ni mk it ne b gy og nk l nl nm">X_new = np.array([[-0.5, 0], [0, 0.5], [1, -0.1], [2, 1]])</span><span id="1a7c" class="ni mk it ne b gy og nk l nl nm">knn.predict(X_new)</span><span id="c071" class="ni mk it ne b gy og nk l nl nm">OUT:<br/>array([1, 0, 1, 0])</span></pre><p id="80e6" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里，我们在核心样本和它们各自的邻居上拟合KNN分类器。</p><p id="2a1a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，我们遇到了一个问题；我们给出了没有任何异常值的KNN数据。这是有问题的，因为它将迫使KNN为新实例选择一个集群，即使新实例确实是一个离群值。</p><p id="8407" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">为了解决这个问题，我们利用KNN分类器的杠杆kneighbors方法，该方法在给定一组实例的情况下，返回训练集的<em class="nc"> k </em>个最近邻居的距离和索引。然后我们可以设置一个最大距离，如果一个实例超过了这个距离，我们就把它定义为离群值:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="32c1" class="ni mk it ne b gy nj nk l nl nm">y_dist, y_pred_idx = knn.kneighbors(X_new, n_neighbors=1)<br/>y_pred = dbscan.labels_[dbscan.core_sample_indices_][y_pred_idx]<br/>y_pred[y_dist &gt; 0.2] = -1<br/>y_pred.ravel()</span><span id="58b4" class="ni mk it ne b gy og nk l nl nm">OUT:<br/>array([-1, 0, 1, -1])</span></pre><p id="4e75" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">这里我们讨论并实现了用于异常检测的DBSCAN。DBSCAN很棒，因为它很快，只有两个超参数，并且对异常值很鲁棒。</p><h1 id="9c26" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">解决方案2:隔离森林</h1><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/75b50702d4b989fed1fab13392d1eb64.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*Aau2Hbt-8nc69e5ujpWMgA.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://en.wikipedia.org/wiki/Isolation_forest" rel="noopener ugc nofollow" target="_blank">作者</a></p></figure><p id="1554" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">IsolationForest是一种集成学习异常检测算法，特别适用于检测高维数据集中的异常值。该算法基本上执行以下操作:</p><ol class=""><li id="42c5" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">它创建了一个随机森林，其中决策树随机生长:在每个节点上，随机选取特征，并选取一个随机阈值将数据集一分为二。</li><li id="c4a7" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">它继续切割数据集，直到所有实例都相互隔离。</li><li id="741d" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">异常通常远离其他实例，因此，平均而言(在所有决策树中)，它变得比正常实例孤立的步骤少。</li></ol><h1 id="2508" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">隔离森林在行动</h1><p id="880d" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">再次感谢Scikit-Learn的直观API，我们可以轻松实现IsolationForest类。让我们来看一个运行中的算法示例:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="a44e" class="ni mk it ne b gy nj nk l nl nm">from sklearn.ensemble import IsolationForest<br/>from sklearn.metrics import mean_absolute_error<br/>import pandas as pd</span></pre><p id="6411" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我们还将引入mean_absolute_error来度量我们的误差。对于数据，我们将使用可以从Jason Brownlee的<a class="ae ky" href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv" rel="noopener ugc nofollow" target="_blank"> GitHub </a>获得的数据集:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="e459" class="ni mk it ne b gy nj nk l nl nm">url='<a class="ae ky" href="https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'" rel="noopener ugc nofollow" target="_blank">https://raw.githubusercontent.com/jbrownlee/Datasets/master/housing.csv'</a></span><span id="3763" class="ni mk it ne b gy og nk l nl nm">df = pd.read_csv(url, header=None)</span><span id="7be1" class="ni mk it ne b gy og nk l nl nm">data = df.values<br/># split into input and output elements<br/>X, y = data[:, :-1], data[:, -1]</span></pre><p id="2263" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在拟合隔离森林之前，让我们尝试对数据拟合一个简单的线性回归模型，并获得我们的MAE:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="8ccd" class="ni mk it ne b gy nj nk l nl nm">from sklearn.linear_model import LinearRegression</span><span id="7f8e" class="ni mk it ne b gy og nk l nl nm">lr = LinearRegression()<br/>lr.fit(X,y)</span><span id="ff3c" class="ni mk it ne b gy og nk l nl nm">mean_absolute_error(lr.predict(X),y)</span><span id="81c8" class="ni mk it ne b gy og nk l nl nm">OUT:<br/>3.2708628109003177</span></pre><p id="043a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相对较好的分数。现在，让我们看看隔离林是否可以通过移除异常来提高分数！</p><p id="8c65" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">首先，我们将实例化我们的IsolationForest:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="b2bc" class="ni mk it ne b gy nj nk l nl nm">iso = IsolationForest(contamination='auto',random_state=42)</span></pre><p id="7d5e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">算法中最重要的超参数可能是<em class="nc">污染</em>参数，它用于帮助估计数据集中异常值的数量。这是一个介于0.0和0.5之间的值，默认设置为0.1</p><p id="8d3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">然而，它本质上是一个随机化的随机森林，因此随机森林的所有超参数也可以用在算法中。</p><p id="d3e9" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">接下来，我们将使数据符合算法:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="373c" class="ni mk it ne b gy nj nk l nl nm">y_pred = iso.fit_predict(X,y)<br/>mask = y_pred != -1</span></pre><p id="be4e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">请注意我们如何过滤掉预测值= -1，就像在DBSCAN中一样，这些预测值被视为异常值。</p><p id="ec11" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，我们将为X和Y重新分配异常值过滤后的数据:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="39bb" class="ni mk it ne b gy nj nk l nl nm">X,y = X[mask,:],y[mask]</span></pre><p id="88b4" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">现在，让我们尝试用线性回归模型来拟合数据，并测量MAE:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="6394" class="ni mk it ne b gy nj nk l nl nm">lr.fit(X,y)<br/>mean_absolute_error(lr.predict(X),y)</span><span id="abfc" class="ni mk it ne b gy og nk l nl nm">OUT:<br/>2.643367450077622</span></pre><p id="ae10" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">哇，成本大大降低了。这清楚地表明了隔离林的威力。</p><h1 id="32f1" class="mj mk it bd ml mm mn mo mp mq mr ms mt jz mu ka mv kc mw kd mx kf my kg mz na bi translated">解决方案3:箱线图+塔克法</h1><p id="75a2" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">虽然箱线图是识别异常值的一种非常常见的方法，但我真的发现后者可能是识别异常值最被低估的方法。但是在我们进入Tuckey方法之前，让我们谈谈箱线图:</p><h2 id="90ce" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">箱线图</h2><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi oj"><img src="../Images/abf172f019ff940b34d06e3887d5653a.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*vZQOzV6FWHF2PlkBUQScVw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://en.wikipedia.org/wiki/Box_plot" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><p id="a147" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">箱线图本质上提供了一种通过分位数显示数字数据的图形方式。这是一个非常简单而有效的方法来可视化离群值。</p><p id="76cb" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">上下须显示分布的边界，任何高于或低于的都被认为是异常值。在上图中，任何高于80和低于62的都被认为是异常值。</p><h2 id="065e" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">箱线图如何工作</h2><p id="9122" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">基本上，盒状图的工作原理是将数据集分成5个部分:</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ok"><img src="../Images/abfc872bee14ceae318ca9ac3f7b485b.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/format:webp/1*fgvbj0oSgv8otYNM6Ui2jg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片来自<a class="ae ky" href="https://stackoverflow.com/questions/48719873/how-to-get-median-and-quartiles-percentiles-of-an-array-in-javascript-or-php?rq=1" rel="noopener ugc nofollow" target="_blank"> StackOverflow </a></p></figure><ul class=""><li id="5f0f" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu oe mb mc md bi translated"><strong class="lb iu"> Min </strong>:分布中排除任何异常值的最低数据点。</li><li id="b422" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated"><strong class="lb iu"> Max </strong>:分布中排除任何异常值的最高数据点。</li><li id="8930" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated"><strong class="lb iu"> Median ( <em class="nc"> Q </em> 2 /第50百分位)</strong>:数据集的中间值。</li><li id="a526" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated"><strong class="lb iu">第一个四分位数(<em class="nc">Q</em>1/25个百分点)</strong>:是数据集下半部分的中位数。</li><li id="6c58" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated"><strong class="lb iu">三分位数(<em class="nc"> Q3 </em> /第75百分位)</strong>:数据集上半部分的中位数。</li></ul><p id="14da" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">四分位距(IQR)很重要，因为它定义了异常值。本质上，它如下:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="1fd3" class="ni mk it ne b gy nj nk l nl nm"><strong class="ne iu">IQR </strong>= Q3 - Q1</span><span id="3c8a" class="ni mk it ne b gy og nk l nl nm"><strong class="ne iu">Q3</strong>: third quartile<br/><strong class="ne iu">Q1</strong>: first quartile</span></pre><p id="8a89" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在箱线图中，测量出1.5 * IQR的距离，并包含数据集的较高观察点。类似地，在数据集的较低观察点上测量出1.5 * IQR的距离。任何超出这些距离的都是异常值。更具体地说:</p><ul class=""><li id="e124" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu oe mb mc md bi translated">如果观察点低于(Q1 1.5 * IQR)或<em class="nc">箱线图下须线</em>，则被视为异常值。</li><li id="e427" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated">类似地，如果观察点高于(Q3 + 1.5 * IQR)或<em class="nc">箱线图上须，</em>，那么它们也被视为异常值。</li></ul><figure class="kj kk kl km gt kn gh gi paragraph-image"><div role="button" tabindex="0" class="ko kp di kq bf kr"><div class="gh gi ki"><img src="../Images/836606b2c40f85e968ef5ded399eee7a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*VDPJfQLeXS4dtcw4xFxxXw.png"/></div></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">图片来自<a class="ae ky" href="https://en.wikipedia.org/wiki/Box_plot#Example(s)" rel="noopener ugc nofollow" target="_blank">维基百科</a></p></figure><h2 id="0ad9" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">行动中的箱线图</h2><p id="72ba" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">让我们看看如何使用Python中的箱线图来检测异常值！</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="d3cc" class="ni mk it ne b gy nj nk l nl nm">import matplotlib.pyplot as plt<br/>import seaborn as sns<br/>import numpy as np</span><span id="731a" class="ni mk it ne b gy og nk l nl nm">X = np.array([45,56,78,34,1,2,67,68,87,203,-200,-150])<br/>y = np.array([1,1,0,0,1,0,1,1,0,0,1,1])</span></pre><p id="4048" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">让我们绘制一个数据的箱线图:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="acb5" class="ni mk it ne b gy nj nk l nl nm">sns.boxplot(X)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/7c2d1018ebe9e1d02ca7e051d158d323.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*dZnyaPP45IRCzavNiiyRkg.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="db18" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">根据我们的箱线图，我们看到我们的数据中有50个中值和3个异常值。让我们去掉这几点:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="1969" class="ni mk it ne b gy nj nk l nl nm">X = X[(X &lt; 150) &amp; (X &gt; -50)]</span><span id="163f" class="ni mk it ne b gy og nk l nl nm">sns.boxplot(X)<br/>plt.show()</span></pre><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi ol"><img src="../Images/337cda7922180850683d698275465188.png" data-original-src="https://miro.medium.com/v2/resize:fit:704/format:webp/1*yFfkyful8kKGMC7Vt5uZ0g.png"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">作者照片</p></figure><p id="364a" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">在这里，我基本上设置了一个门槛，所有小于-50大于150的点都会被排除在外。而结果；平均分配！</p><h2 id="665c" class="ni mk it bd ml nn no dn mp np nq dp mt li nr ns mv lm nt nu mx lq nv nw mz nx bi translated">Tuckey方法异常检测</h2><p id="5017" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">tuckey方法异常值检测实际上是盒图的非可视化方法；方法是一样的，除了没有观想。</p><p id="1a3f" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我有时更喜欢这种方法，而不是箱线图的原因是，有时看一看可视化并粗略估计阈值应该设置为什么并不真正有效。</p><p id="f7ea" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">相反，我们可以编写一个算法，它实际上可以返回它定义为离群值的实例。</p><p id="b7ef" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">实现的代码如下:</p><pre class="kj kk kl km gt nd ne nf ng aw nh bi"><span id="40ca" class="ni mk it ne b gy nj nk l nl nm">import numpy as np<br/>from collections import Counter</span><span id="743b" class="ni mk it ne b gy og nk l nl nm">def detect_outliers(df, n, features):<br/>    # list to store outlier indices<br/>    outlier_indices = []</span><span id="1b77" class="ni mk it ne b gy og nk l nl nm">    # iterate over features(columns)</span><span id="b5e4" class="ni mk it ne b gy og nk l nl nm">    for col in features:<br/>        # Get the 1st quartile (25%)<br/>        Q1 = np.percentile(df[col], 25)<br/>        # Get the 3rd quartile (75%)<br/>        Q3 = np.percentile(df[col], 75)<br/>        # Get the Interquartile range (IQR)<br/>        IQR = Q3 - Q1</span><span id="766b" class="ni mk it ne b gy og nk l nl nm">        # Define our outlier step<br/>        outlier_step = 1.5 * IQR</span><span id="b24f" class="ni mk it ne b gy og nk l nl nm">       # Determine a list of indices of outliers</span><span id="48cb" class="ni mk it ne b gy og nk l nl nm">       outlier_list_col = df[(df[col] &lt; Q1 - outlier_step) |     (df[col] &gt; Q3 + outlier_step)].index</span><span id="08a2" class="ni mk it ne b gy og nk l nl nm">   # append outlier indices for column to the list of outlier indices <br/>        outlier_indices.extend(outlier_list_col)</span><span id="e8f6" class="ni mk it ne b gy og nk l nl nm">   # select observations containing more than 2 outliers<br/>    outlier_indices = Counter(outlier_indices)        <br/>    multiple_outliers = list(k for k, v in outlier_indices.items() if v &gt; n)</span><span id="586f" class="ni mk it ne b gy og nk l nl nm">return multiple_outliers</span><span id="2803" class="ni mk it ne b gy og nk l nl nm"># detect outliers from list of features<br/>list_of_features = ['x1', 'x2']<br/># params dataset, number of outliers for rejection, list of features Outliers_to_drop = detect_outliers(dataset, 2, list_of_features)</span></pre><p id="1968" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">基本上，该代码执行以下操作:</p><ol class=""><li id="8142" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">对于每个特征，它获得:</li></ol><ul class=""><li id="8d47" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu oe mb mc md bi translated">第一个四分位数</li><li id="234f" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated">第三个四分位数</li><li id="c64a" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated">IQR</li></ul><p id="06c5" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">2.接下来，它定义了<em class="nc">异常值步长</em>，就像在箱线图中一样，它是1.5 * IQR</p><p id="d34e" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">3.它通过以下方式检测异常值:</p><ul class=""><li id="1d3d" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu oe mb mc md bi translated">查看观察点是否为&lt; Q1 — outlier step</li><li id="438b" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu oe mb mc md bi translated">Seeing if the observed point is Q3 + outlier step</li></ul><p id="4bab" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">4. It then checks selects observations that have <em class="nc"> k </em>异常值(在这种情况下，k = 2)</p></div><div class="ab cl om on hx oo" role="separator"><span class="op bw bk oq or os"/><span class="op bw bk oq or os"/><span class="op bw bk oq or"/></div><div class="im in io ip iq"><h1 id="d14e" class="mj mk it bd ml mm ot mo mp mq ou ms mt jz ov ka mv kc ow kd mx kf ox kg mz na bi translated">结论</h1><p id="e58f" class="pw-post-body-paragraph kz la it lb b lc ny ju le lf nz jx lh li oa lk ll lm ob lo lp lq oc ls lt lu im bi translated">总之，有许多离群点检测算法，但我们通过3个最常见的:DBSCAN，IsolationForest和Boxplots。我鼓励你:</p><ol class=""><li id="5692" class="lv lw it lb b lc ld lf lg li lx lm ly lq lz lu ma mb mc md bi translated">在Titanic数据集上尝试这些方法。哪一个检测异常值最好？</li><li id="6b73" class="lv lw it lb b lc me lf mf li mg lm mh lq mi lu ma mb mc md bi translated">寻找其他异常值检测方法，看看它们的性能比您最初尝试的方法更好还是更差。</li></ol><p id="4379" class="pw-post-body-paragraph kz la it lb b lc ld ju le lf lg jx lh li lj lk ll lm ln lo lp lq lr ls lt lu im bi translated">我真的很感激我的追随者，我也希望不断地写作，给每个人提供很好的精神食粮。然而现在，我必须说再见；}</p><figure class="kj kk kl km gt kn gh gi paragraph-image"><div class="gh gi oy"><img src="../Images/fba9e950d449df1296f3f6dc868729f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:534/format:webp/1*av2nRLZyEK6uYxfIGbuPew.jpeg"/></div><p class="ku kv gj gh gi kw kx bd b be z dk translated">照片由<a class="ae ky" href="https://www.flickr.com/photos/hit-thepineapple/3740510520/in/photolist-6Gx6sG-3BRTT-aKGUWR-vfmAbJ-2jQXvsu-2jbxm87-8RdPJ-8b7L44-27Bpxnx-6Zk8FP-eMsWsS-3RFHy-smyjPc-8veeS2-2e9yDYX-Wu5D6r-bnCWXg-55QKEB-TnH85D-6jfenr-4TYH1T-2e9yDZi-5Bq4G1-2cKFWDr-6CCPBy-2icpZMn-2gvGVpQ-2hutLvF-U76bvn-2inoGCK-4uqPt7-72LKqn-7txdM-67hfDv-2cKFWDM-Nb3XAw-6t9gHx-8AUJY4-CyuTL-e12QP-Lewuc-W5RM2o-2hztpRp-4ZKnuV-nLC7gh-6wN132-Wfh7FH-2abfTG-a3RyD7-2cKFWDX" rel="noopener ugc nofollow" target="_blank"> ZoeyMoey </a>在<a class="ae ky" href="https://www.flickr.com/photos/hit-thepineapple/" rel="noopener ugc nofollow" target="_blank"> Flickr </a>上拍摄</p></figure></div></div>    
</body>
</html>