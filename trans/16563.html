<html>
<head>
<title>Linear Regression Analysis on House Price in Python</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Python中房价的线性回归分析</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/linear-regression-analysis-on-house-price-in-python-55bbe2cd3fd9?source=collection_archive---------29-----------------------#2020-11-15">https://towardsdatascience.com/linear-regression-analysis-on-house-price-in-python-55bbe2cd3fd9?source=collection_archive---------29-----------------------#2020-11-15</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><blockquote class="jn jo jp"><p id="1466" class="jq jr js jt b ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko ij bi translated">如今，我们都变得如此习惯于谈论深度学习、大数据、神经网络……我们似乎忘记了，即使这些大话题正在蓬勃发展，但不是每个企业都需要它们，至少现在是这样。因此，我想分享一点我在常见统计话题上的经验。在这篇和下一篇博客中，我将分别演示如何用Python和R进行线性回归分析。</p></blockquote><h1 id="0e97" class="kp kq iq bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">项目摘要</h1><p id="3c12" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">这个由Kaggle提供的项目包括一个由79个解释变量组成的数据集，描述了爱荷华州Ames住宅的各个方面。你可以在这里找到项目<a class="ae lv" href="https://www.kaggle.com/c/house-prices-advanced-regression-techniques" rel="noopener ugc nofollow" target="_blank">的所有数据来源和描述。</a></p><p id="301d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">这项竞赛的目标是预测每所挂牌房屋的最终销售价格。我们做这个问题是因为我们希望应用我们的回归技术和数据探索性分析技巧。这个习题集允许我们使用以上所有的练习。此外，数据集包含许多缺失值，这使我们能够获得处理缺失数据的经验。</p><p id="c63b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们运行了多重回归技术，如<em class="js"> XGB回归器</em>、<em class="js"> SGD回归器</em>、<em class="js"> MLP回归器</em>、<em class="js">决策树回归器</em>、<em class="js">随机森林回归器</em>、<em class="js"> CatBoost回归器</em>、<em class="js">轻型GBM </em>和<em class="js"> SVR </em>。我们把一些放在一起，实验看哪一个的均方根误差最小。</p><p id="5d7c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们提交的预测有两列(图1.1)。第一列是房子的ID，第二列是我们预测的销售价格。根据预测值对数和观察到的销售价格日志之间的均方根误差对预测进行评分。最小的RMSE是最好的预测。在运行基础模型和优化模型后，我们发现我们的tubed CatBoost回归模型为我们获得了最低的RMSE分数0.12392，在我们提交时，它在排行榜上排名第863位(共4525位)。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi lw"><img src="../Images/90486389aed558c01c78b0d2d271de18.png" data-original-src="https://miro.medium.com/v2/resize:fit:260/format:webp/0*g4PEVZJrWuIBbUZt.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图1.1 —提交样本</em></p></figure><h1 id="bd2d" class="kp kq iq bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">数据</h1><h2 id="1919" class="mj kq iq bd kr mk ml dn kv mm mn dp kz lp mo mp ld lr mq mr lh lt ms mt ll mu bi translated">-概述</h2><p id="036b" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">竞赛为我们提供了两个数据集。其中之一是有1460个观察值和81列的训练数据，它包含每栋房子的ID和销售价格。另一个数据集是维持文件，它包含1459个观察值。</p><p id="6424" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们首先研究了训练数据集的特征类型。图2.1显示整个数据集有43个分类特征和36个数字变量，包括“ID”。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mv"><img src="../Images/fcdfcce4314b3c5ce0f9dd0b10e9c70c.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/0*sXoe3u0mflYRR-Lv.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.1 —数字的数量&amp;分类特征</em></p></figure><p id="ccc1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">然后，我们努力检测数据集中是否有任何丢失的值。在训练数据集中，有19个变量缺少值。维持数据集包含33个缺失值的要素。有些要素缺失值的百分比非常高。例如，PoolQC(池质量)特性的缺失值高达99.5%。像PoolQC这样的特性可能会损害预测模型的准确性，并导致我们得出无效的结论。因此，我们删除了至少有80%的值丢失的特征。详情见“数据处理”部分。</p><p id="7929" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">在我们开始处理数据之前，我们还研究了38个数字特征的必要统计信息。在图2.2中，我们发现一些特性的范围相对较大，比如销售价格。我们将要使用的许多回归模型需要我们在处理之前对这些特征进行某种类型的转换。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mw"><img src="../Images/9979006874b315dc3580ab1389744303.png" data-original-src="https://miro.medium.com/v2/resize:fit:1284/format:webp/0*BDykEjXZ3sdMGOVp.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.2 —所有数字变量的统计信息</em></p></figure><h2 id="0672" class="mj kq iq bd kr mk ml dn kv mm mn dp kz lp mo mp ld lr mq mr lh lt ms mt ll mu bi translated">-数据处理</h2><p id="009a" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">缺失值总是会损害预测模型的准确性。在进行任何转换之前，我们决定首先检查至少有80%的值丢失的列。根据图2.3，有四个变量有大量的缺失值，它们是“Alley”、“PoolQC”、“Fence”和“MiscFeature”。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi mx"><img src="../Images/e85e9cfea0c133493f1b673c86cd95bb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1302/format:webp/0*F6HDMKqsCOWdstJy.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.3——至少有80%缺失值的变量</em></p></figure><p id="1c2b" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">在处理数据时，确保对定型数据集和维持数据集进行相同的更改是至关重要的。每个数据集中列数的差异、不一致的数据格式以及分类变量中不匹配的值数目都可能给我们的模型带来麻烦。因此，为了更好地准备数据并确保任何转换都将反映在定型数据集和维持数据集上，我们使用图2.4中的代码将这两个数据集临时合并为标签0和1，并且还提供了将数据集拆分回原始数据集的代码。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi my"><img src="../Images/9afef780cb3a9f1740468efb56181233.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/format:webp/0*1ZmkI9jvoNlmeC0q.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.4 —合并和取消合并数据集的代码</em></p></figure><p id="0351" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">对于所有的分类变量，我们将它们转换成虚拟变量来处理缺失值。我们用数字变量中所有缺失值的当前变量的平均值来填充它们。</p><h2 id="0f0f" class="mj kq iq bd kr mk ml dn kv mm mn dp kz lp mo mp ld lr mq mr lh lt ms mt ll mu bi translated">-特征工程</h2><p id="4f70" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">我们还在现有变量的基础上创建了一些新变量。例如，我们使用关于房子何时装修和出售的数据，生成了一个名为“AgeofHouse”的新变量，这有助于我们直观地了解房价和房子质量之间的关系。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi mz"><img src="../Images/7633ad62f51fa0aa8122a24669c1ba10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*pYp4Gy3vutuY9VfL.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.5 —新功能“房屋时代”</em></p></figure><p id="a498" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们想知道是否需要对“销售价格”进行对数转换，因为它包含一些相对较大的值，这些值会对模型的准确性产生负面影响。对数变换前后的残差与拟合图(图2.6和图2.7)证实了我们的假设，即变换使模型更加线性。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi ne"><img src="../Images/a9a650455613624d9940dcc8caada918.png" data-original-src="https://miro.medium.com/v2/resize:fit:1262/format:webp/0*IrfKWIqX937oclTy.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.6——对数变换前的残差与拟合值</em></p></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nf"><img src="../Images/e6d2170ebfb38d9eefacc2e50f232ab6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1184/format:webp/0*w-K0_3NwIi8KiSsR.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.7——对数变换后的残差与拟合值</em></p></figure><h2 id="d7be" class="mj kq iq bd kr mk ml dn kv mm mn dp kz lp mo mp ld lr mq mr lh lt ms mt ll mu bi translated">-相关图</h2><p id="791c" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">我们创建了一些图表来研究数据。我们首先查看目标变量和其余变量之间的相关性。图2.8显示了与房屋销售价格绝对相关的前30个特征。深色表示变量与销售价格负相关。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi ng"><img src="../Images/6ff48582bebb4de43b2709ec400dbfee.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*VVSeXHYUHO3M01kf.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.8 —前30个“最”相关变量</em></p></figure><p id="1a66" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们还详细研究了“销售价格”和个体变量之间的关系。我们选择了几个有趣的图表来呈现在这份报告中。例如，我们制作了一个散点图(图2.9)关于“销售价格”和“房屋年龄”，这是我们在上一步中创建的特征。我们可以看到，房子越新，房子越有可能以更高的价格出售。因此，我们确信价格超过50万美元的房屋是在最近15年内建造或翻新的。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nh"><img src="../Images/359aff49a490aa08d32d301cba8f1d33.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/0*m4NTT7wfk9RtJAD9.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.9——房龄与销售价格</em></p></figure><p id="fd5c" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">另一个例子是“总体平等”和“销售价格”的情节。“总体质量”是与“销售价格”最正相关的变量，该图(图2.10)清楚地表明，评级越高，价格越高。</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi ni"><img src="../Images/966ce79312a4b38c23ead53b1c7aaf41.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/0*ptphhGI0qXhhF_6g.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图2.10 —总体质量与销售价格</em></p></figure><p id="7644" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们的最终训练数据集有1460个观察值和289个变量，而维持数据集有1459个观察值和289个变量。</p><h1 id="3351" class="kp kq iq bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">建模</h1><h2 id="2db5" class="mj kq iq bd kr mk ml dn kv mm mn dp kz lp mo mp ld lr mq mr lh lt ms mt ll mu bi translated">-单个型号的性能(基本型号与调整型号)</h2><p id="be84" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">在这种情况下，选择了九个回归模型:</p><p id="9b5d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated"><strong class="jt ir"> <em class="js"> OLS，XGBRegressor，SGD regressor</em></strong><br/><strong class="jt ir"><em class="js">DecisionTreeRegressor，RandomForestRegressor，SVR</em></strong><br/><strong class="jt ir"><em class="js">CatBoostRegressor，LightGBM，MLPRegressor </em> </strong> <em class="js">。</em></p><p id="ddf1" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们使用OLS作为基础模型，并生成了图3.1中模型的回归结果:</p><pre class="lx ly lz ma gt nj nk nl nm aw nn bi"><span id="7ce6" class="mj kq iq nk b gy no np l nq nr">#original <br/>#generate OLS model<br/>sm_model = sm.OLS(y_train, sm.add_constant(X_train))<br/>sm_model_fit = sm_model.fit()</span><span id="db9f" class="mj kq iq nk b gy ns np l nq nr">print(sm_model_fit.summary())</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nt"><img src="../Images/c1e2191e6171f966c974039a29621b78.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*aO9xXLX_Ded4jcQ5.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图3.1 — OLS回归结果</em></p></figure><p id="3eff" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">根据OLS报告，我们了解到R平方为0.943，这意味着该模型可以解释94.3%的“销售价格”。该模型的kaggle得分为0.15569。</p><p id="d95d" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">下表(图3.2)列出了所有模型的kaggle分数，包括未调整和调整的参数。在所有其他模型中，具有调谐参数的CatBoostRegressor具有最佳性能，<strong class="jt ir"> 0.12392 </strong>。在我们撰写本报告时，这个分数使我们在4525个团队中排名第863位(相当于前19%)。</p><pre class="lx ly lz ma gt nj nk nl nm aw nn bi"><span id="3001" class="mj kq iq nk b gy no np l nq nr"># Example code</span><span id="47ff" class="mj kq iq nk b gy ns np l nq nr">mlp=MLPRegressor(random_state=42)</span><span id="6de3" class="mj kq iq nk b gy ns np l nq nr">#paramters for gridsearch<br/>mlp_param = {<br/>    'hidden_layer_sizes': [(273,230,30), (273,230,20), (273,230,50)],<br/>    'activation': ['tanh'],<br/>    'solver': ['sgd'],  #, 'adam'<br/>    'alpha': [0.0001],<br/>    'learning_rate': ['adaptive'],    #'constant',<br/>}<br/>----------------------</span><span id="5314" class="mj kq iq nk b gy ns np l nq nr">#Apply GridSearchCV<br/>mlp_grid = GridSearchCV(mlp,<br/>                        mlp_param,<br/>                        cv = 5,<br/>                        n_jobs = 3,<br/>                        verbose=True)</span><span id="7c3b" class="mj kq iq nk b gy ns np l nq nr">mlp_grid.fit(X_train,y_train)<br/>print(mlp_grid.best_score_)<br/>print(mlp_grid.best_params_)</span><span id="8763" class="mj kq iq nk b gy ns np l nq nr">output:<br/>0.8218847474014372<br/>{'activation': 'tanh', 'alpha': 0.0001, 'hidden_layer_sizes': (273, 230, 30), 'learning_rate': 'adaptive', 'solver': 'sgd'}<br/>----------------------</span><span id="d3de" class="mj kq iq nk b gy ns np l nq nr">#Fit the model with bets paramters<br/>mlp_best_model=MLPRegressor(activation= 'tanh',<br/>                 alpha=0.0001, <br/>                 hidden_layer_sizes=(273, 230, 30),<br/>                 learning_rate= 'adaptive', <br/>                 solver= 'sgd')<br/>mlp_best_model.fit(X_train,y_train)<br/>----------------------</span><span id="67d1" class="mj kq iq nk b gy ns np l nq nr">#Make Predictions and submit files<br/>mlp_prediction = mlp_best_model.predict(test.drop(["Id"],1))<br/>mlp_DATA = pd.DataFrame({"ID":holdout["Id"],<br/>                         "SalePrice":np.exp(mlp_prediction)})<br/>mlp_DATA.to_csv("mlpstandard1.csv",index=False)</span></pre><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div role="button" tabindex="0" class="na nb di nc bf nd"><div class="gh gi nu"><img src="../Images/e9fb3f19c0ba3ce32d8ca92e6d026e07.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6aywmnWgEZ78GgNtbIpYJw.png"/></div></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图3.2——卡格尔得分表</em></p></figure><h2 id="b08d" class="mj kq iq bd kr mk ml dn kv mm mn dp kz lp mo mp ld lr mq mr lh lt ms mt ll mu bi translated">-堆叠模型和平均系综</h2><p id="79a6" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">我们还创建了几个堆积模型和平均系综模型。这些类型的模型通常可以通过让多个模型一起工作来帮助减少误差。然而，这些模型都不能胜过CatboostRegressor。输出如图3.3所示:</p><figure class="lx ly lz ma gt mb gh gi paragraph-image"><div class="gh gi nv"><img src="../Images/1793050f1cb312856145c4f9c2f3ca15.png" data-original-src="https://miro.medium.com/v2/resize:fit:608/format:webp/0*A3vy-u6n-wVAPk0a.png"/></div><p class="me mf gj gh gi mg mh bd b be z dk translated"><em class="mi">图3.3——叠加和平均系综模型的Kaggle得分</em></p></figure><h1 id="5f35" class="kp kq iq bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">结论</h1><p id="c9ca" class="pw-post-body-paragraph jq jr iq jt b ju ln jw jx jy lo ka kb lp lq ke kf lr ls ki kj lt lu km kn ko ij bi translated">总的来说，我们在“房价高级回归技术”问题上的主要挑战是有大量的缺失数据。我们用多种解决方案测试了数据的缺失值，但是仍然很难找到一种方法来显著提高模型的准确性。此外，我们认为，如果我们可以有一个更大的训练数据集，它也可能有助于改进模型。</p><p id="4b48" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">在提交了各种模型之后，我们注意到我们调整的CatBoost回归模型是房价的最佳预测器。我们还运行了由三个或更多调整的回归模型组成的四个堆叠和平均集成模型，但没有一个比CatBoost回归器得分更高。</p><p id="04b9" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">我们发现这个项目很有趣，因为我们使用许多不同的解释变量来预测单一价格。这也很有趣，因为我们可以在其他城市或州的数据集上使用相同的方法来预测房价，并比较不同位置的平均价格。我们也可以使用这样的预测模型来帮助预测未来的房屋市场销售价格。</p><p id="c6c6" class="pw-post-body-paragraph jq jr iq jt b ju jv jw jx jy jz ka kb lp kd ke kf lr kh ki kj lt kl km kn ko ij bi translated">本博客来源于蒋金航和马人·奥尔森的班级项目报告。感谢安德鲁阿比莱斯和张子萱的贡献。最初的报告发布在我的<a class="ae lv" href="https://jinhangjiang.github.io/Regression-Analysis-on-House-Price/" rel="noopener ugc nofollow" target="_blank">网站</a>上，我写这篇博客时做了一些小改动。你可以在这里找到建模<a class="ae lv" href="https://github.com/jinhangjiang/ASU_CIS508_TeamProject1/tree/main/Script" rel="noopener ugc nofollow" target="_blank">的代码脚本。</a></p><h1 id="6309" class="kp kq iq bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm bi translated">以前的文章:</h1><figure class="lx ly lz ma gt mb gh gi paragraph-image"><a href="https://towardsdatascience.com/lol-match-prediction-using-early-laning-phase-data-machine-learning-4c13c12852fa"><div class="gh gi nw"><img src="../Images/a385ad5323e496d349c3e5a23bae818c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7Dn4feptpJXZHOCjgrVG5A.png"/></div></a></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><a href="https://medium.com/analytics-vidhya/analyzing-disease-co-occurrence-using-networkx-gephi-and-node2vec-53941da35a0f"><div class="gh gi nx"><img src="../Images/24f4353b4d17de61895e8ae88e32723f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*krEREho_h3B8ctLc.png"/></div></a></figure><figure class="lx ly lz ma gt mb gh gi paragraph-image"><a href="https://towardsdatascience.com/integrate-text-content-into-classification-project-eddd8e18a7e9"><div class="gh gi ny"><img src="../Images/61495867e80902838ccbde4278e032fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mzm53GNGk7UYC0dgJfADIg.png"/></div></a></figure></div></div>    
</body>
</html>