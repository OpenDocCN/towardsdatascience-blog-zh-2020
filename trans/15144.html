<html>
<head>
<title>Arabic Topic Classification On The Hespress News Dataset</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Hespress新闻数据集上的阿拉伯语主题分类</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/arabic-topic-classification-on-the-hespress-news-dataset-7adceef12bed?source=collection_archive---------23-----------------------#2020-10-18">https://towardsdatascience.com/arabic-topic-classification-on-the-hespress-news-dataset-7adceef12bed?source=collection_archive---------23-----------------------#2020-10-18</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="db2c" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">如何正确分类阿拉伯文本</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/bb2c7c8a7a0b0552e8beeba0c632dad5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-MNlm46aQfTjdCpp"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">马库斯·温克勒在<a class="ae kv" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上的照片</p></figure><p id="b1f9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">本文是一个系列的第一篇，在这个系列中，我将介绍对Hespress数据集的分析。</p><p id="f3f7" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">根据“alexa.com”的统计，Hespress在摩洛哥排名第四，是该国最大的新闻网站，平均每个摩洛哥人每天在该网站上花费大约6分钟。</p><p id="622e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Hespress数据集是11万篇新闻文章和30万条评论的集合，每篇文章都有相关用户的评分，可以把这些评分想象成脸书邮报上的赞。这个数据集可以用于新闻文章分类，这将是我们在本文中的重点，也可以用于对摩洛哥舆论的情感分析。您可以使用以下链接下载数据集:</p><div class="ls lt gp gr lu lv"><a href="https://www.kaggle.com/tariqmassaoudi/hespress" rel="noopener  ugc nofollow" target="_blank"><div class="lw ab fo"><div class="lx ab ly cl cj lz"><h2 class="bd ir gy z fp ma fr fs mb fu fw ip bi translated">赫斯普雷斯</h2><div class="mc l"><h3 class="bd b gy z fp ma fr fs mb fu fw dk translated">Kaggle是世界上最大的数据科学社区，拥有强大的工具和资源来帮助您实现您的数据…</h3></div><div class="md l"><p class="bd b dl z fp ma fr fs mb fu fw dk translated">www.kaggle.com</p></div></div><div class="me l"><div class="mf l mg mh mi me mj kp lv"/></div></div></a></div><p id="45d3" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这篇文章的目标读者是对机器学习有一点了解的人，例如分类和回归之间有什么区别，什么是交叉验证。然而，我将对这个项目的步骤做一个简单的解释。</p><h1 id="4560" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">问题介绍:</strong></h1><p id="abc3" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">幸运的是，我们的数据集包含文章及其标签，因此我们正在处理一个有监督的学习问题，这将使我们的生活更加容易，因为如果不是这样，我们将不得不手动标记每篇文章或采用无监督的方法。</p><p id="e698" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">简而言之，我们的目标是在给定文本的情况下预测文章的主题。我们总共有11个主题:</p><ul class=""><li id="9807" class="nh ni iq ky b kz la lc ld lf nj lj nk ln nl lr nm nn no np bi translated">塔马塞特语(一种摩洛哥语言)</li><li id="752c" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">运动(运动)</li><li id="f560" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">社会团体</li><li id="0f5d" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">区域(地区)</li><li id="4fdf" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">政治</li><li id="6140" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">轨道(世界新闻)</li><li id="bb1a" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">媒体(当地报纸的新闻)</li><li id="6d1d" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">世界摩洛哥人</li><li id="17aa" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">Faits Divers(杂项)</li><li id="bd92" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">经济学家</li><li id="7d56" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">艺术与文化(艺术与文化)</li></ul><h1 id="ee0c" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">探索性数据分析:</strong></h1><p id="f82f" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">我们将使用seaborn进行数据可视化，使用pandas进行数据操作。</p><p id="a4a8" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让我们从加载数据开始:</p><p id="4344" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">因为数据存储在不同的文件中，每个文件包含特定主题的数据，所以我们必须循环遍历主题并连接结果。</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="1ebc" class="oa ml iq nw b gy ob oc l od oe">import pandas as pd<br/>stories=pd.DataFrame()<br/>topics["tamazight","sport","societe","regions","politique","orbites","medias","marocains-du-monde","faits-divers","economie","art-et-culture"]</span><span id="b57d" class="oa ml iq nw b gy of oc l od oe">for topic in topics:<br/>  stories=pd.concat([stories,pd.read_csv("stories_"+topic+".csv")])</span><span id="d448" class="oa ml iq nw b gy of oc l od oe">stories.drop(columns=["Unnamed: 0"],axis=1,inplace=True)</span></pre><p id="4233" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">接下来让我们从数据中获取一个样本:</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="bf15" class="oa ml iq nw b gy ob oc l od oe">stories.sample(5)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi og"><img src="../Images/e1ede0a8f5e3f19de4b150690b19903d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_uM4fxYgLH_PrQ_zWbZHcg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">stories数据集中的示例列</p></figure><p id="c9fc" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到我们有5个专栏，对于这篇文章，我们只对故事和主题特性感兴趣。</p><p id="6cc0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">现在，让我们检查一下每个主题中有多少故事，这对于分类极其重要，因为如果我们有一个<strong class="ky ir">不平衡的数据集</strong>，即(我们在一个主题中有比其他主题多得多的数据点)，我们的模型将会有偏差，也不会工作。如果我们有这个问题，一个常见的解决方案是应用一个<strong class="ky ir">欠采样</strong>或<strong class="ky ir">过采样</strong>方法，我们不会去查看细节，因为这不在我们的文章范围内。</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="ee24" class="oa ml iq nw b gy ob oc l od oe">import seaborn as sns<br/>storiesByTopic=stories.groupby(by="topic").count()["story"]<br/>sns.barplot(x=storiesByTopic.index,y=storiesByTopic)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/f8580c555ad5eec6b6e6b28e1a2680cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Tnrx36tYvfFLtTtInoyKCQ.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">按主题的故事计数</p></figure><p id="3719" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，每个主题几乎有1000个故事，我们的数据集非常平衡。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi oi"><img src="../Images/f63bedf0831709606b68213f49b8852e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qA46C2LjmtYma_wb.jpg"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">资料来源:memegenerator.net</p></figure><h1 id="1a96" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">数据清理:</strong></h1><p id="4ffc" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">我们正在处理阿拉伯文本数据。我们的数据清理流程将包括2个步骤:</p><p id="b283" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">删除停用词</strong>:一些词，如“و”、“كيف”，在所有阿拉伯文本中出现频率极高，并且不提供我们的模型可以用来预测的含义。移除它们将减少噪音，并让我们的模型只关注相关的单词。为此，我们将使用一个列表，循环遍历所有文章，删除列表中出现的所有单词。</p><p id="43c9" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我使用的停用词表可以在<a class="ae kv" href="https://github.com/mohataher/arabic-stop-words/blob/master/list.txt" rel="noopener ugc nofollow" target="_blank"> Github </a>上找到</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="a18c" class="oa ml iq nw b gy ob oc l od oe">from nltk.tokenize import word_tokenize</span><span id="49a7" class="oa ml iq nw b gy of oc l od oe">file1 = open('stopwordsarabic.txt', 'r', encoding='utf-8') <br/>stopwords_arabic = file1.read().splitlines()+["المغرب","المغربية","المغربي"]</span><span id="bedd" class="oa ml iq nw b gy of oc l od oe">def removeStopWords(text,stopwords):<br/>    text_tokens = word_tokenize(text)<br/>    return " ".join([word for word in text_tokens if not word in stopwords])</span></pre><p id="52a2" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">删除标点符号</strong>:出于同样的原因，我们将删除标点符号，为此我使用了一个正则表达式。</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="e7d8" class="oa ml iq nw b gy ob oc l od oe">from nltk.tokenize import RegexpTokenizer<br/>def removePunctuation(text):<br/>    tokenizer = RegexpTokenizer(r'\w+')<br/>    return " ".join(tokenizer.tokenize(text))</span></pre><h1 id="d026" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">绘制文字云:</strong></h1><p id="3c53" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">让我们找点乐子，我们将使用python " <strong class="ky ir"> WordCloud </strong>"库从我们的数据集中的所有故事中画出一个单词云</p><p id="f7ad" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在这样做之前，有一些额外的步骤需要特别为阿拉伯语，要了解更多关于他们访问这个<a class="ae kv" href="https://amueller.github.io/word_cloud/auto_examples/arabic.html" rel="noopener ugc nofollow" target="_blank">链接</a>。</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="6c68" class="oa ml iq nw b gy ob oc l od oe">import arabic_reshaper<br/>from bidi.algorithm import get_display<br/>import matplotlib.pyplot as plt<br/>%matplotlib inline</span><span id="778a" class="oa ml iq nw b gy of oc l od oe">def preprocessText(text,stopwords,wordcloud=False):<br/>    noStop=removeStopWords(text,stopwords)<br/>    noPunctuation=removePunctuation(noStop)<br/>    if wordcloud:<br/>        text=arabic_reshaper.reshape(noPunctuation)<br/>        text=get_display(text)<br/>        return text<br/>    return noPunctuation</span><span id="1aa3" class="oa ml iq nw b gy of oc l od oe">drawWordcloud(stories.story,stopwords_arabic)</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oj"><img src="../Images/bea766cdab2fb44d61bfba010e45fb98.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Uc9cBE2aEXJRMDAuLrFIKA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">西方新闻报道的文字云</p></figure><p id="3c17" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">由于这个数据集包含最近的新闻文章，我们认为“كورونا”(冠状病毒)是一个反复出现的词。还有“الامازيغية”是摩洛哥的主要语言，“محمد”是摩洛哥最流行的名字，也是摩洛哥国王的名字，“الحكومة”是政府的意思。</p><h1 id="97fc" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">特色工程:</strong></h1><p id="c2c6" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">机器学习模型本质上是数学方程，无法理解文本，所以在运行我们的模型之前，我们需要将文本转换为数字，有多种方法可以做到这一点，让我们来发现两种最流行的方法。</p><ul class=""><li id="423a" class="nh ni iq ky b kz la lc ld lf nj lj nk ln nl lr nm nn no np bi translated"><strong class="ky ir">字数:</strong></li></ul><p id="8b2c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这个非常简单，每一列代表整个故事语料库中的一个单词，每一行代表一个故事，单元格的值就是一个单词在故事中出现的频率！</p><ul class=""><li id="d2d0" class="nh ni iq ky b kz la lc ld lf nj lj nk ln nl lr nm nn no np bi translated"><strong class="ky ir"><em class="ok">TF–IDF:</em></strong></li></ul><p id="dcef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">TF-IDF代表“词频逆文档频率”,它使用一种稍微复杂一点的方法来惩罚在多个文档中出现的常见单词。</p><p id="4705" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将使用TF-IDF，因为它在大多数情况下会产生更好的性能！</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="1412" class="oa ml iq nw b gy ob oc l od oe">from sklearn.feature_extraction.text import TfidfVectorizer</span><span id="5dc3" class="oa ml iq nw b gy of oc l od oe">#Clean the stories <br/>stories["storyClean"]=stories["story"].apply(lambda s: preprocessText(s,stopwords_arabic))</span><span id="4df0" class="oa ml iq nw b gy of oc l od oe">#Vectorize the stories</span><span id="b734" class="oa ml iq nw b gy of oc l od oe">vectorizer = TfidfVectorizer()<br/>X = vectorizer.fit_transform(stories["storyClean"])<br/>y=stories.topic</span></pre><h1 id="bf1d" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">造型:</strong></h1><p id="4ad1" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">我们将尝试以下型号:</p><ul class=""><li id="5eda" class="nh ni iq ky b kz la lc ld lf nj lj nk ln nl lr nm nn no np bi translated">随机森林</li><li id="1fee" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">逻辑回归</li><li id="9240" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">SGD分类器</li><li id="2df1" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">多项式朴素贝叶斯</li></ul><p id="e461" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们将通过每个模型运行数据，并使用<strong class="ky ir">准确性</strong>作为我们的衡量标准，它是正确预测和总数据点的比率，为了获得更准确的结果，我们使用了5倍交叉验证进行评分，然后我们将绘制结果。</p><pre class="kg kh ki kj gt nv nw nx ny aw nz bi"><span id="e863" class="oa ml iq nw b gy ob oc l od oe">from sklearn.model_selection import train_test_split<br/>from sklearn.metrics import accuracy_score<br/>from sklearn.model_selection import cross_val_score<br/>import numpy as np<br/>from sklearn.metrics import classification_report<br/>def testModel(model,X,y):<br/>    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)<br/>    model.fit(X_train,y_train)<br/>    modelName = type(model).__name__<br/>    pred=model.predict(X_test)<br/>    print(modelName)<br/>    print(classification_report(y_test,model.predict(X_test)))<br/>    score=np.mean(cross_val_score(model, X, y, cv=5))<br/><br/>    return model,{"model":modelName,"score":score}</span></pre><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ol"><img src="../Images/b9ba74202680d993072fc831e8d45f25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0roKplrxJ6UXDwdAmaTxqg.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">模型准确性</p></figure><p id="95e0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们最好的模型是精确度为87 %的SDG分类器</p><h1 id="5ed7" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">模型解释:</strong></h1><p id="7dc3" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">现在我们有了一个工作模型，让我们试着了解更多的情况，因为我们将回答两个问题:</p><ul class=""><li id="edde" class="nh ni iq ky b kz la lc ld lf nj lj nk ln nl lr nm nn no np bi translated">我们的模型纠结于哪些话题？</li><li id="3f50" class="nh ni iq ky b kz nq lc nr lf ns lj nt ln nu lr nm nn no np bi translated">哪些词对预测不同话题最有影响力？</li></ul><p id="3798" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">对于第一个问题，我们可以查看最佳模型的分类报告:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi om"><img src="../Images/f0419dd5a367cc9df628697be39f22fa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1218/format:webp/1*1tZdFEDNUQrnkh171mZ8rw.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">分类报告SGD分类器</p></figure><p id="61ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们预测“体育”、“艺术”、“媒体”、“塔马塞特”的准确度极高。我们最纠结的是“<strong class="ky ir">orbits</strong>”(世界新闻)、<strong class="ky ir"> societe </strong>”(社会)这可能是因为这两个话题更为宽泛。</p><p id="cf64" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">为了回答第二个问题，我们将使用逻辑回归的一个有用属性，我们可以使用权重作为每个模型中单词重要性的度量。"<strong class="ky ir">Eli 5</strong>" python库让这一切变得简单:</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi on"><img src="../Images/af553885cfa5cc2673fccec9af5d641b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*N3olha4sCIs5S13IaFlwcQ.png"/></div></div></figure><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oo"><img src="../Images/1d7edeff41d7d838e27f45802960533e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GIJSoNquPJn7kyHQBHfy3Q.png"/></div></div></figure><p id="681b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们可以看到，大多数单词都是有意义的，并且与主题的主题相对应，例如对于“艺术”，顶部的单词是:“艺术家”、“电影”、“文化”、“书籍”。</p><h1 id="4388" class="mk ml iq bd mm mn mo mp mq mr ms mt mu jw mv jx mw jz mx ka my kc mz kd na nb bi translated"><strong class="ak">结论:</strong></h1><p id="b835" class="pw-post-body-paragraph kw kx iq ky b kz nc jr lb lc nd ju le lf ne lh li lj nf ll lm ln ng lp lq lr ij bi translated">在本文中，我们已经经历了为阿拉伯语设计文本分类系统所需的所有步骤，从数据探索到模型解释。然而，我们仍然可以通过调整超参数来提高精度。</p><p id="2031" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在下一篇文章中，我们将尝试使用<strong class="ky ir">情感分析来理解每篇文章的评论。</strong></p><p id="d99e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果你设法来到这里，恭喜你。感谢阅读，我希望你喜欢这篇文章。如需个人联系或讨论，请随时通过LinkedIn 联系我。</p></div></div>    
</body>
</html>