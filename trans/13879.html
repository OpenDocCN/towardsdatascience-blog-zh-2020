<html>
<head>
<title>Deploy Apache Airflow in Multiple Docker Containers</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">在多个Docker容器中部署Apache Airflow</h1>
<blockquote>原文：<a href="https://towardsdatascience.com/deploy-apache-airflow-in-multiple-docker-containers-7f17b8b3de58?source=collection_archive---------1-----------------------#2020-09-24">https://towardsdatascience.com/deploy-apache-airflow-in-multiple-docker-containers-7f17b8b3de58?source=collection_archive---------1-----------------------#2020-09-24</a></blockquote><div><div class="fc ie if ig ih ii"/><div class="ij ik il im in"><div class=""/><div class=""><h2 id="6cf4" class="pw-subtitle-paragraph jn ip iq bd b jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke dk translated">在Apache Airflow中编排数据科学模型，使用Celery Executor进行扩展，并使用Docker Compose部署在多个Docker容器中</h2></div><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi kf"><img src="../Images/f6e46cafa1a40d024ca6dd08d66835bd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w2K5gPw-KWKEECGxRoyWCQ.jpeg"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">约书亚·阿拉贡在<a class="ae kv" href="https://unsplash.com/s/photos/laptop-screens?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" rel="noopener ugc nofollow" target="_blank"> Unsplash </a>上拍摄的照片</p></figure><p id="f50b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">当涉及到数据科学模型时，它们会定期运行。例如，如果我们预测下个月的客户流失，模型必须在每个月的最后一天运行。每月手动运行该模型是不可取的。我们可以使用一个调度程序来自动化这个过程。Apache Airflow是一个理想的工具，因为它允许调度和监控您的工作流。在本文中，我们将讨论如何使用Docker部署Apache Airflow，并保留进一步扩展的空间。熟悉Apache Airflow和Docker概念将是阅读本文的一个优势。</p><h1 id="308e" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">阿帕奇气流简介</h1><p id="e25c" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">气流由3个主要部分组成；Web服务器、调度程序和元数据库。Web服务器负责用户与应用程序交互的用户界面。调度器负责作业调度，而元数据库存储调度细节。即使气流有几个执行器，芹菜执行器更适合可伸缩性。芹菜执行器3额外的组件添加到气流。它们是工作者、消息代理和工作者监视器。Worker负责执行由调度程序触发的作业。可以有多个工人。这些工作者可以分布在集群实例中。工人的数量可以根据系统的工作量和机器的能力来决定。消息经纪人帮芹菜操作。可以使用监控工具来监控芹菜工人。</p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi mp"><img src="../Images/c261f356233be33d4d270daa0e664c79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4rYC6Z9w4RmVn_kjiEePMA.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">阿帕奇气流与芹菜执行器(<em class="mq">图片由作者</em>)</p></figure><p id="d6fd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">使用Docker，我们计划将上述每个组件运行在一个单独的Docker容器中。Web服务器、调度程序和工作人员将使用一个公共的Docker映像。这个公共映像对于项目来说是唯一的，我们将讨论构建这个映像的Dockerfile文件。所有其他容器将直接使用公开可用的图像。</p><p id="c230" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">在本教程中，PostgreSQL被用作元数据库，Redis被用作消息代理，而芹菜花被用于监控工人。因为有多个容器，所以使用Docker Compose可以很容易地一次性部署所有的容器。</p><h1 id="3cb0" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">项目结构</h1><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div class="gh gi mr"><img src="../Images/f1830fee0d2fce854d87e4960c1813c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:652/format:webp/1*JyEEQAaq2_r-S1bHo96DVg.png"/></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">项目结构:<a class="ae kv" href="https://github.com/nishakanthiA/Airflow-Docker" rel="noopener ugc nofollow" target="_blank">https://github.com/nishakanthiA/Airflow-Docker</a>(作者<em class="mq">图片</em>)</p></figure><p id="650c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">该图像显示了我们的项目结构。所有与项目相关的文件都放在脚本文件夹中。所有与气流相关的文件都放在气流文件夹中。与部署相关的其他文件在最外面的目录中。<code class="fe ms mt mu mv b">env.list</code>包括分类模型所需的环境变量。<code class="fe ms mt mu mv b">requrements.txt</code>定义要在python环境中安装的包，以便运行模型。</p><p id="78db" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><code class="fe ms mt mu mv b">Dockerfile</code>用于创建供Airflow web服务器、调度程序和工作人员使用的图像。<code class="fe ms mt mu mv b">docker-compose.yml</code>用于定义和启动所有的容器。</p><p id="f835" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">提出了一个简单的模型来分类著名的虹膜数据集。我已经在dags文件夹中添加了两个带有<code class="fe ms mt mu mv b">PythonOperator</code>的DAGs。一个用于训练模型，另一个用于通过已训练的模型获得预测。DAG到列车模型的定义没有计划间隔。这意味着一旦需要模型训练，它就可以被触发。预测旨在每天检索。因此，生成预测的DAG被安排每天运行模型。文件<code class="fe ms mt mu mv b">airflow.cfg</code>包含气流的配置属性。</p><h1 id="03f7" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">创建Docker图像</h1><p id="79b8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">要使用docker展开气流，参考的最佳图像是<a class="ae kv" href="https://github.com/puckel/docker-airflow" rel="noopener ugc nofollow" target="_blank"><strong class="ky ir"><em class="mw">puck El/docker-air flow</em></strong></a><em class="mw">。(更新:气流现在有了它的官方Docker形象)</em>但是这个形象不能照原样使用；由于一些原因。一个原因是它没有安装我们在项目中使用的所有包。如果我们需要更改airflow.config文件中的属性，我们必须将它们作为环境变量传递。由于存在大量变量，这并不容易。因此，我们将使用<code class="fe ms mt mu mv b">puckel/docker-airflow</code>的基本映像编写一个定制的docker文件。除了message broker、元数据库和worker monitor之外，这个映像将用于我们的所有容器中。以下是Dockerfile文件。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="6e11" class="nb lt iq mv b gy nc nd l ne nf">FROM puckel/docker-airflow:1.10.9</span><span id="fd3c" class="nb lt iq mv b gy ng nd l ne nf">COPY airflow/airflow.cfg ${AIRFLOW_HOME}/airflow.cfg</span><span id="a4a8" class="nb lt iq mv b gy ng nd l ne nf">COPY requirements.txt /requirements.txt<br/>RUN pip install -r /requirements.txt</span></pre><h1 id="cca5" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">创建Docker容器</h1><h2 id="7ea1" class="nb lt iq bd lu nh ni dn ly nj nk dp mc lf nl nm me lj nn no mg ln np nq mi nr bi translated">元数据库</h2><p id="369a" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">让我们首先为元数据库容器定义服务。Docker image <code class="fe ms mt mu mv b">postgres:9.6</code>用于此。用户凭证和数据库名称应该作为环境变量给出。设置该容器时，数据库名称(POSTGRES_DB=airflow)应与airflow配置<code class="fe ms mt mu mv b">sql_alchemy_conn</code>中的数据库连接字符串兼容。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="6a07" class="nb lt iq mv b gy nc nd l ne nf">version: '3.7'<br/>services:<br/>    postgres:<br/>        image: postgres:9.6<br/>        environment:<br/>            - POSTGRES_USER=airflow<br/>            - POSTGRES_PASSWORD=airflow<br/>            - POSTGRES_DB=airflow<br/></span></pre><p id="01dd" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">如果您已经有一个现有的PostgreSQL服务器，并且希望使用它，则不需要为元数据库部署额外的容器。为服务器中的气流元数据创建专用数据库。Airflow将在启动时填充数据库，然后负责维护数据库。可以通过气流配置给出服务器的详细信息。设置服务器细节的一种方法是修改<code class="fe ms mt mu mv b">airflow.cfg</code>文件中的<code class="fe ms mt mu mv b">sql_alchemy_conn</code>。另一种方法是把它作为一个环境变量<code class="fe ms mt mu mv b">AIRFLOW__CORE__SQL_ALCHEMY_CONN</code>。下面是为PostgreSQL连接提供的连接字符串的格式。登录服务器的凭证用户名、密码、主机IP、数据库名应该作为环境变量传递。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="eaaf" class="nb lt iq mv b gy nc nd l ne nf">sql_alchemy_conn =postgresql+psycopg2://$PG_USER:$PG_PASSWORD@$PG_HOST:5432/$PG_DB_NAME</span></pre><p id="17c0" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这样，我们的第一个容器就变成可选的了。</p><h2 id="38a1" class="nb lt iq bd lu nh ni dn ly nj nk dp mc lf nl nm me lj nn no mg ln np nq mi nr bi translated">芹菜执行器的消息代理</h2><p id="af5e" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">在这个项目中，我们通过使用多个气流工作者来关注应用程序的可伸缩性。为此，我们可以使用芹菜执行器。在气流配置文件中设置<code class="fe ms mt mu mv b">executor = CeleryExecutor</code> <strong class="ky ir"> </strong>。环境变量是<code class="fe ms mt mu mv b">AIRFLOW__CORE__EXECUTOR</code>T11。</p><p id="df1d" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">Celery是一个任务队列实现，Airflow使用它在后台定期异步运行并行批处理作业。它需要一个像Redis和RabbitMQ这样的消息代理来传输消息。气流没有这部分，需要外部实现。这里我们用Redis。我们可以使用image Docker image <code class="fe ms mt mu mv b"><em class="mw">redis:5.0.5</em></code></p><p id="b948" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">用我们的第二个容器<code class="fe ms mt mu mv b">docker-compose.yml</code>会是这个样子。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="bbbf" class="nb lt iq mv b gy nc nd l ne nf">version: '3.7'<br/>services:<br/>    postgres:<br/>        image: postgres:9.6<br/>        environment:<br/>            - POSTGRES_USER=airflow<br/>            - POSTGRES_PASSWORD=airflow<br/>            - POSTGRES_DB=airflow<br/>   redis:<br/>        image: redis:5.0.5</span></pre><p id="cb1e" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">这里我们也可以使用一个外部Redis服务，而不需要创建这个容器。凭证应由气流配置文件中的<code class="fe ms mt mu mv b">broker_url</code>、<code class="fe ms mt mu mv b">celery_result_backend</code>给出。</p><h2 id="1e6d" class="nb lt iq bd lu nh ni dn ly nj nk dp mc lf nl nm me lj nn no mg ln np nq mi nr bi translated">Airflow Web服务器</h2><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi ns"><img src="../Images/3a41201438542fae20eae4f77b652cfc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Aoy3hbzSmvEd5qGS4_Lh3w.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">气流用户界面(<em class="mq">图片作者</em>)</p></figure><p id="843c" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">我们的第三个容器是Aiflow web服务器，它负责用户界面。对于这个容器，我们将使用以前创建的Docker图像。以下是服务“webserver”的docker容器配置。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="29e7" class="nb lt iq mv b gy nc nd l ne nf"><strong class="mv ir">webserver:<br/>    image: </strong>webserver:latest<br/>    <strong class="mv ir">build:<br/>      context: </strong>.<br/>    <strong class="mv ir">restart: </strong>always<br/>    <strong class="mv ir">depends_on:<br/>        </strong>- postgres<br/>        - redis<br/>    <strong class="mv ir">environment:<br/>        </strong>- LOAD_EX=n<br/>        - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=<br/>        - EXECUTOR=Celery<br/>        - PYTHONPATH=/usr/local/airflow<br/>    <strong class="mv ir">env_file:<br/>      </strong>- env.list<br/>    <strong class="mv ir">volumes:<br/>        </strong>- ./airflow/dags:/usr/local/airflow/dags<br/>        - ./scripts:/usr/local/airflow/scripts<br/>    <strong class="mv ir">ports:<br/>        </strong>- <strong class="mv ir">"8080:8080"<br/>    command: </strong>webserver<br/>    <strong class="mv ir">healthcheck:<br/>        test: </strong>[<strong class="mv ir">"CMD-SHELL"</strong>, <strong class="mv ir">"[ -f /usr/local/airflow/airflow-webserver.pid ]"</strong>]<br/>        <strong class="mv ir">interval: </strong>30s<br/>        <strong class="mv ir">timeout: </strong>30s<br/>        <strong class="mv ir">retries: </strong>3</span></pre><p id="de37" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">每个命令的用法解释如下。</p><ul class=""><li id="663b" class="nt nu iq ky b kz la lc ld lf nv lj nw ln nx lr ny nz oa ob bi translated">构建上下文:指向创建的Dockerfile。相应映像是在容器启动时构建的</li><li id="296a" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">重新启动:如果由于任何原因停止了，重新部署容器。</li><li id="8aa2" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">依赖于:web服务器需要与元数据库和消息代理容器通信</li><li id="134d" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">环境:这些是基本映像puckel/docker-airflow请求的列表环境变量。让它们保持原样。您可以自由地添加更多的环境变量，如“PYTHONPATH ”,这些变量将被您自己的程序脚本使用。</li><li id="6d31" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">env_file:可以使用file给出环境变量的列表</li><li id="1f80" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">卷:Dag和程序脚本可以作为卷挂载。这比将文件复制到Docker映像中更有效。文件更新后，更改将自动部署到web服务器中。不需要构建映像和重新部署容器。</li><li id="d7b3" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">端口:要部署的端口。web服务器正在端口8080上运行。</li><li id="8f2c" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">command : airflow命令启动web服务器。这是基础映像puckel/docker-airflow所要求的。不要修改它。</li><li id="b1a8" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">healthcheck:检查容器健康状况的测试</li></ul><h2 id="7138" class="nb lt iq bd lu nh ni dn ly nj nk dp mc lf nl nm me lj nn no mg ln np nq mi nr bi translated">气流调度程序</h2><p id="77ff" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">我们的第四个容器是Aiflow scheduler。除了命令和依赖关系之外，服务配置与Airflow web服务器非常相似。命令是启动调度程序的气流命令。调度程序依赖于web服务器容器。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="4878" class="nb lt iq mv b gy nc nd l ne nf"><strong class="mv ir">scheduler:<br/>    image: </strong>scheduler:latest<br/>    <strong class="mv ir">build:<br/>      context: </strong>.<br/>    <strong class="mv ir">restart: </strong>always<br/>    <strong class="mv ir">depends_on:<br/>        </strong>- webserver<br/>    <strong class="mv ir">volumes:<br/>        </strong>- ./airflow/dags:/usr/local/airflow/dags<br/>        - ./scripts:/usr/local/airflow/scripts<br/>    <strong class="mv ir">environment:<br/>        </strong>- LOAD_EX=n<br/>        - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=<br/>        - EXECUTOR=Celery<br/>        - PYTHONPATH=/usr/local/airflow<br/>    <strong class="mv ir">command: </strong>scheduler<br/>    <strong class="mv ir">env_file:<br/>      </strong>- env.list</span></pre><h2 id="79a2" class="nb lt iq bd lu nh ni dn ly nj nk dp mc lf nl nm me lj nn no mg ln np nq mi nr bi translated">气流工人</h2><p id="9740" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">下一个集装箱是气流工人。命令是启动工作机的气流命令。工作进程依赖于调度器容器。可以有多个工人。这里我加了两个。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="d96b" class="nb lt iq mv b gy nc nd l ne nf"><strong class="mv ir">worker1:<br/>    image: </strong>worker1:latest<br/>    <strong class="mv ir">build:<br/>      context: </strong>.<br/>    <strong class="mv ir">restart: </strong>always<br/>    <strong class="mv ir">depends_on:<br/>        </strong>- scheduler<br/>    <strong class="mv ir">volumes:<br/>        </strong>- ./airflow/dags:/usr/local/airflow/dags<br/>        - ./scripts:/usr/local/airflow/scripts<br/>    <strong class="mv ir">environment:<br/>        </strong>- FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=<br/>        - EXECUTOR=Celery<br/>        - PYTHONPATH=/usr/local/airflow<br/>    <strong class="mv ir">command: </strong>worker<br/>    <strong class="mv ir">env_file:<br/>      </strong>- env.list<br/><br/><strong class="mv ir">worker2:<br/>    image: </strong>worker2:latest<br/>    <strong class="mv ir">build:<br/>      context: </strong>.<br/>    <strong class="mv ir">restart: </strong>always<br/>    <strong class="mv ir">depends_on:<br/>        </strong>- scheduler<br/>    <strong class="mv ir">volumes:<br/>        </strong>- ./airflow/dags:/usr/local/airflow/dags<br/>        - ./scripts:/usr/local/airflow/scripts<br/>    <strong class="mv ir">environment:<br/>        </strong>- FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=<br/>        - EXECUTOR=Celery<br/>        - PYTHONPATH=/usr/local/airflow<br/>    <strong class="mv ir">command: </strong>worker<br/>    <strong class="mv ir">env_file:<br/>      </strong>- env.list</span></pre><p id="7fb5" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">让多个工人在同一台机器上还可以减少作业的执行时间。为了获得更有效和最佳的结果，气流配置文件中的属性<code class="fe ms mt mu mv b">parallelism </code>、<code class="fe ms mt mu mv b">dag_concurrency</code>、<code class="fe ms mt mu mv b">worker_concurrency</code>和<code class="fe ms mt mu mv b">max_threads</code>应根据工人数量进行调整。其中一些属性也可以在DAG级别进行调整。</p><p id="3144" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">工人可以分布在集群中的多台机器上。一台单独的机器将负责每个工人，而所有其他容器可以部署在一台公共机器上。我们可以保留一个单独的docker-compose文件来部署工人。主docker-compose文件将包含其余容器的服务。以下是ECS集群中AWS EC2实例中部署的worker容器的docker-compose文件示例。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="f017" class="nb lt iq mv b gy nc nd l ne nf">version: '3.7'<br/>services:<br/>    remote_worker_3:<br/>        image: remote_worker_3:latest<br/>        build:<br/>          context: .<br/>          args:<br/>            github_token: ${GITHUB_TOKEN}<br/>        restart: always<br/>        external_links:<br/>            - redis_1:redis<br/>        networks:<br/>            - sample_project_default<br/>        environment:<br/>            - FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=<br/>            - EXECUTOR=Celery<br/>        volumes:<br/>          - ./sample_project/airflow/dags:/usr/local/airflow/dags<br/>          - ./sample_project/src:/usr/local/airflow/dags/src<br/>        env_file:<br/>            - env.list<br/>        command: worker<br/>        stdin_open: true<br/>        tty: true</span><span id="196c" class="nb lt iq mv b gy ng nd l ne nf">networks:<br/>    sample_project_default:<br/>        external: true</span></pre><p id="80ca" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">网络名称可以通过<code class="fe ms mt mu mv b">docker network ls</code>命令找到。如果你有兴趣了解更多关于Docker网络搜索的信息。</p><p id="40ef" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated"><strong class="ky ir">工人监视器</strong></p><figure class="kg kh ki kj gt kk gh gi paragraph-image"><div role="button" tabindex="0" class="kl km di kn bf ko"><div class="gh gi oh"><img src="../Images/c0a52d586afdb4a3995fc87d84f9ce7b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*CXQkh-sg6mjR7PvoRciYsw.png"/></div></div><p class="kr ks gj gh gi kt ku bd b be z dk translated">芹菜花仪表板(<a class="ae kv" href="https://flower.readthedocs.io/en/latest/screenshots.html" rel="noopener ugc nofollow" target="_blank">https://flower.readthedocs.io/en/latest/screenshots.html</a>)</p></figure><p id="e01b" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">工人的行为可以通过芹菜花来监控。这也是一个可选的容器。以下是花卉容器的配置。</p><pre class="kg kh ki kj gt mx mv my mz aw na bi"><span id="26d3" class="nb lt iq mv b gy nc nd l ne nf"><strong class="mv ir">flower:<br/>    image: </strong>flower:latest<br/>    <strong class="mv ir">build:<br/>      context: </strong>.<br/>    <strong class="mv ir">restart: </strong>always<br/>    <strong class="mv ir">depends_on:<br/>        </strong>- redis<br/>    <strong class="mv ir">environment:<br/>        </strong>- EXECUTOR=Celery<br/>    <strong class="mv ir">ports:<br/>        </strong>- <strong class="mv ir">"5555:5555"<br/>    command: </strong>flower</span></pre><h1 id="1094" class="ls lt iq bd lu lv lw lx ly lz ma mb mc jw md jx me jz mf ka mg kc mh kd mi mj bi translated">部署</h1><p id="b6f8" class="pw-post-body-paragraph kw kx iq ky b kz mk jr lb lc ml ju le lf mm lh li lj mn ll lm ln mo lp lq lr ij bi translated">现在，我们准备用多个Docker容器部署我们的气流项目。我们可以使用docker-compose.yml文件一次性部署所有的容器。下面是一些有用的Docker命令。</p><ul class=""><li id="5a72" class="nt nu iq ky b kz la lc ld lf nv lj nw ln nx lr ny nz oa ob bi translated">开始容器:<code class="fe ms mt mu mv b">docker-compose up -d -- build</code></li><li id="8a86" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">停止容器:<code class="fe ms mt mu mv b"> docker-compose down</code></li><li id="b07d" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">查看容器:<code class="fe ms mt mu mv b">docker ps</code></li><li id="6e75" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">进入一个容器:<code class="fe ms mt mu mv b">docker exec -it &lt;container-id&gt; bash</code></li><li id="738a" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">查看一个容器的日志:<code class="fe ms mt mu mv b">docker logs &lt;container-id&gt;</code></li><li id="6d2c" class="nt nu iq ky b kz oc lc od lf oe lj of ln og lr ny nz oa ob bi translated">监控集装箱:<code class="fe ms mt mu mv b">docker stats</code></li></ul><p id="cc74" class="pw-post-body-paragraph kw kx iq ky b kz la jr lb lc ld ju le lf lg lh li lj lk ll lm ln lo lp lq lr ij bi translated">项目网址:<a class="ae kv" href="https://github.com/nishakanthiA/Airflow-Docker" rel="noopener ugc nofollow" target="_blank">https://github.com/nishakanthiA/Airflow-Docker</a></p></div></div>    
</body>
</html>